{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Software Complexity Simplicity is not the opposite of complexity. Simplicity is too often an excuse for being simplistic. The world doesn't need any more stupid software. The opposite of complexity is beautiful, elegant design. Hi, My name is Chris Lovett. I love writing code and starting new projects on small fast paced incubation teams and growing that to successful product. I\u2019ve done this several times in my career and had a blast in the process. I enjoy working with Microsoft Research and I am co-inventor on 16 patents. But while solving hard technical problems is fun, I\u2019ve also learned that in the end it is the people I work with that make all the difference. So my goal is to apply my talents on an amazing team and make the world a better place. Visual R\u00e9sum\u00e9 | Linked In Profile","title":"Home"},{"location":"apps/","text":"Apps MyFitness DgmlImage Secure Password Vault MyMoney.Net Magic LED Lights Fun Chores PX4 Log Viewer Firefly SensorTag for Windows Seismograph Table App Outlook Sync for PC XML Notepad RoboBackups Software Trails","title":"Apps"},{"location":"apps/#apps","text":"MyFitness DgmlImage Secure Password Vault MyMoney.Net Magic LED Lights Fun Chores PX4 Log Viewer Firefly SensorTag for Windows Seismograph Table App Outlook Sync for PC XML Notepad RoboBackups Software Trails","title":"Apps"},{"location":"code/","text":"Code The following is a list of git repos I\u2019m currently maintaining: https://github.com/lovettchris/IoTKeywordSpotter https://github.com/lovettchris/TelepromptEditor https://github.com/clovett/MyMoney.Net https://github.com/clovett/SensorTag-for-Windows https://github.com/clovett/FoscamExplorer https://github.com/clovett/firefly https://github.com/lovettchris/SgmlReader https://github.com/lovettchris/GivingTrivia https://github.com/lovettchris/xmldiff Work related: https://github.com/Microsoft/Coyote https://www.microsoft.com/artist-in-residence/collaborations/ada https://github.com/Microsoft/ELL https://github.com/Microsoft/AirSim https://www.microsoft.com/en-us/research/project/project-premonition/ https://github.com/p-org/P https://github.com/Microsoft/XmlNotepad","title":"Code"},{"location":"code/#code","text":"The following is a list of git repos I\u2019m currently maintaining: https://github.com/lovettchris/IoTKeywordSpotter https://github.com/lovettchris/TelepromptEditor https://github.com/clovett/MyMoney.Net https://github.com/clovett/SensorTag-for-Windows https://github.com/clovett/FoscamExplorer https://github.com/clovett/firefly https://github.com/lovettchris/SgmlReader https://github.com/lovettchris/GivingTrivia https://github.com/lovettchris/xmldiff Work related: https://github.com/Microsoft/Coyote https://www.microsoft.com/artist-in-residence/collaborations/ada https://github.com/Microsoft/ELL https://github.com/Microsoft/AirSim https://www.microsoft.com/en-us/research/project/project-premonition/ https://github.com/p-org/P https://github.com/Microsoft/XmlNotepad","title":"Code"},{"location":"posts/","text":"Microsoft Flight Simulator 2020\u201d Apple iCloud - please stop bugging me!\u201d Coyote is released into the wild!\u201d My Telsa Model S\u201d Using DGML to understand PX4\u201d Keyword Spotting\u201d DgmlImage\u201d Arduino controlled Remote Light Switch\u201d DGML Power Tools for Visual Studio 2017\u201d Fun with ELL\u201d Visual Studio\u2019s lesser-known Xml Schema features\u201d AirSim is \u2018live\u2019!!\u201d MyMoney.Net is now open source\u2026\u201d I love Mylio\u201d WinRT Extensions using RuntimeBroker\u201d Efergy Power Monitor\u201d Magic LED Lights Rock\u201d Update to XML Notepad\u201d Seismograph App\u201d Remote Control Phone\u201d FIRST Event Planner\u201d Model Based UI Testing using DGML\u201d Software Trails\u201d Secure Password Vault\u201d GraphModel Specification\u201d","title":"Index"},{"location":"posts/Coyote/","text":"Coyote - solving complexity of async code I\u2019m happy to announce the availability of a very cool new .NET Framework and testing tool from Microsoft Research called Coyote . I am super fortunate to be able to work with some of the smartest people in the world at Microsoft Research and Coyote is a perfect example of the kind of really cool projects I get to play with. Coyote (which started out as the P# programming language) is the result of a new incubation process in Microsoft Research that takes research work and moves it to the next level, like a startup company would, to turn research into useful product. We do this by pairing researchers with Software Engineers, Program Management, Design, Business Development, and Marketing, who all work together to deeply understand the research, how to present it to the world in a way that is easy to understand and use and how work with customers to improve it. Coyote already has customers inside the Azure team that are using it to improve the quality and reliability of Azure infrastructure. If you are drowning in the complexity of building asynchronous software, then you probably need to add Coyote to your toolbox. Check it out, it is free, open source on github, with a nuget package ready to use in your .NET projects! -Chris.","title":"Coyote is released into the wild!"},{"location":"posts/Coyote/#coyote-solving-complexity-of-async-code","text":"I\u2019m happy to announce the availability of a very cool new .NET Framework and testing tool from Microsoft Research called Coyote . I am super fortunate to be able to work with some of the smartest people in the world at Microsoft Research and Coyote is a perfect example of the kind of really cool projects I get to play with. Coyote (which started out as the P# programming language) is the result of a new incubation process in Microsoft Research that takes research work and moves it to the next level, like a startup company would, to turn research into useful product. We do this by pairing researchers with Software Engineers, Program Management, Design, Business Development, and Marketing, who all work together to deeply understand the research, how to present it to the world in a way that is easy to understand and use and how work with customers to improve it. Coyote already has customers inside the Azure team that are using it to improve the quality and reliability of Azure infrastructure. If you are drowning in the complexity of building asynchronous software, then you probably need to add Coyote to your toolbox. Check it out, it is free, open source on github, with a nuget package ready to use in your .NET projects! -Chris.","title":"Coyote - solving complexity of async code"},{"location":"posts/GraphModel/","text":"DGML Graph Model Specifications The Directed Graph Markup Language (.dgml) features of Visual Studio are built on a node/link graph data model. This data is persisted in DGML documents which is an XML format. While it is possible to edit the XML directly, it is not fun or productive. The Graph Model API provides an in-memory representation that is natural for manipulating directed graphs and has become the foundation of all the dependency analysis features in VS. For this reason the API has been made available anyone extending Visual Studio. Goals Performance: Being the platform for lots of features the model needs to be as fast as possible. Usability: Close behind however is the fact that the API needs to be simple to use Convenience: Where practical helper methods are provided for added convenience, but this is not the top priority of this API. Helper libraries can always be provided out of band or as sample code. Thread safe: Some amount of thread safety and thread isolation is nice for this level of API Non-Goals The API does not attempt to be the front end to a database. Design The Complete Graph Model API is available on MSDN. This spec just outlines the core concepts that must be understood in order to use this API. The Graph model can serialize itself to and from the DGML XML format. GraphNodeId In order to support first class serialization and decoupling of graph operations across components, or in databases, it is important to name the objects in a graph carefully. To this end the Graph Model does not use System.String to name things. The GraphNodeId class is used instead. GraphNodeId is a structured identifier that composes nested sets of Name=Value pairs, for example, you can create a GraphNodeId that points to an Assembly like this: GraphNodeId mscorlib = GraphNodeId.GetPartial(CodeNames.AssemblyName, new Uri(typeof(string).Assembly.Location)); This serializes to the following string format: (Assembly=file:///C:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll) Then you can name the System Namespace inside mscorlib by composing the following two names together: GraphNodeId system = mscorlib + GraphNodeId.GetPartial(CodeNames.NamespaceName, \"System\"); Then you can name the String Class by adding on to the name of the namespace: GraphNodeId str = system + GraphNodeId.GetPartial(CodeNames.TypeName, \"String\"); Then you can name the Join method by adding to the name of the class: GraphNodeId join = str + GraphNodeId.GetPartial(CodeNames.Name, \"Join\"); The result is an identifier that remembers the structure you used to build the name and this structure can also be serialized to and from the following string format: (Assembly=file:///C:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll Namespace=System Class=String Method=Join) This sort of composition of names allows the application to avoid having to do lots of expensive string parsing operations every time it needs a part of the name. It also provides hashing advantages so that comparing identifiers is a lot faster and the overall memory used is much less than using strings. As you can imagine, naming everything in mscorlib results in many redundant Assembly, Namespace, Class sub strings, so building up identifiers using string addition would be very expensive: string mscorlib = \u201cAssembly=file:///C:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll\u201d; string system = mscorlib + \u201c Namespace=System\u201d; string stringClass = system + \u201c Type=String\u201d; string joinMethod = stringClass + \u201cMethod=Join\u201d; The following table shows the comparison between System.String and GraphNodeId in construction time, comparison and total memory usage measured using all the identifiers in System.Xml.Linq.dll (about 2000 identifiers) and about 4 million comparisons (comparing every identifier against every other). The construction time for the GraphNodeId\u2019s here is the worst case and assumes no reuse of in memory ids. For example, it recreates the Assembly id over and over rather than holding onto one GraphNodeId pointer for that assembly. This is not typically how the product code will work, but it is the worst case. It is how Serialization would work, so it essentially measures serialization load time. For that reason strings are faster to load, but you can see that memory usage and comparison time, GraphNodeId wins considerably, this is because GraphNodeId is \u201catomized\u201d, so that comparison can be a simple object reference comparison. Note: string.Intern doesn\u2019t help the string case here because every identifier is different, and string.Intern would add substantial hit to load time, which would make it slower than GraphNodeId. GraphNodeId registration is static so they employ a WeakReference system to garbage collect ids that are not used. GraphNodeId Value Types The GraphNodeId values can be any type that can be converted to/from a string using TypeConverter. However, the following types are well supported: String: \u201cNamespace=System.Collections\u201d. Uri: \u201cAssembly=file://mscorlib.dll\u201d. GraphNodeIdCollection: \u201cParentType=(Assembly=file://mscorlib.dll Namespace=System.Collections Type=ArrayList)\u201d. GraphNodeIdName The name part is a static object called a GraphNodeIdName . The name also determines the type of value that the GraphNodeId can contain, and how a string should be parsed back during string serialization. For example, Namespace will be registered as string, but assembly as URI: class CodeNames { public static GraphNodeIdName AssemblyName = GraphNodeIdName.Get(\"Assembly\", \"Assembly\", typeof(Uri)); public static GraphNodeIdName NamespaceName = GraphNodeIdName.Get(\"Namespace\", \"Namespace\", typeof(string)); public static GraphNodeIdName TypeName = GraphNodeIdName.Get(\"Type\", \"Type\", typeof(object)); public static GraphNodeIdName NameName = GraphNodeIdName.Get(\"Name\", \"Name\", typeof(String)); public static GraphNodeIdName GenericParameterCountName = GraphNodeIdName.Get(\"GenericParameterCount\", \"GenericParameterCount\", typeof(int)); public static GraphNodeIdName MemberName = GraphNodeIdName.Get(\"Member\", \"Member\", typeof(Object)); public static GraphNodeIdName OverloadingParametersName = GraphNodeIdName.Get(\"OverloadingParameters\", \"OverloadingParameters\", typeof(GraphNodeIdCollection)); } Notice the GraphNodeIdName objects are usually static so they can be shared by the whole process. There are also 3 special names for qualified identifiers. These are non-printed names, and are inferred during parsing. GraphNodeIdName.Nested \u2013 a list of GraphNodeIds \u201c(Assembly=file://mscorlib.dll Namespace=System Type=String)\u201d. The data type of a Nested value is always GraphNodeIdCollection. In the above case, there are 3 nested identifiers: Assembly, Namespace and Type. GraphNodeIdName.Array \u2013 represents a list of GraphNodeId\u2019s where each item in the list has the same type. For example, the arguments to a method each have the same type \u201cMethodParameter\u201d, so think of the array as a way to lift the \u201cMethodParameter\u201d part out of the list, so instead of (MethodParameter=Value MethodParameter=Value MethodParameter=Value) you can say MethodParameter=[Value, Value, Value]. The data type of Array value is always GraphNodeIdCollection \u2013 with homogeneousItems =true. GraphNodeIdName.Literal - \u201cBing!\u201d. The data type of a Literal is a String. If a GraphNodeId is being constructed through parsing, and a name is not currently registered, a new name will be registered with a data type of System.Object. If you want to reuse the same GraphNodeIdName in some places with a string value and in other places with a nested GraphNodeIdCollection then type the GraphNodeIdName as System.Object. Parsing & standard form A standard GraphNodeId always has a Nested outer GraphNodeId, with one or more GraphNodeId inside. A GraphNodeId that\u2019s not part of a nested qualified identifier is said to be a partial qualified identifier. This is why the following method is called GetPartial: GraphNodeId.GetPartial(CodeNames.NamespaceName, \"System\"); returns \"Namespace=System\" To make this a standard identifier wrap it in a GetNested call: GraphNodeId id = GraphNodeId.GetNested( GraphNodeId.GetPartial(CodeNames.NamespaceName, \"System\") ); This results in the following well formed identifier: \"(Namespace=System)\" This is important during parsing. Although it is possible to build a partial GraphNodeId using the .GetPartial() API, it is not possible to construct one using .Parse(). Instead, GraphNodeId.Parse(\u201cNamespace=System\u201d)will instead be parsed as a Literal: - id2 {Namespace=System} Microsoft.VisualStudio.GraphModel.GraphNodeId - LiteralValue \"Namespace=System\" string - Name {Literal} Microsoft.VisualStudio.GraphModel.GraphNodeIdName - Value \"Namespace=System\" object {string} This is simply so that the parsing rules are simple, predictable, and as fast as possible. Any GraphNodeID that is malformed will also be parsed as: \u201cName=Literal, Value=whatever\u201d Nesting The following shows how GraphNodeId can be nested to full identify not only a method, but all the fully qualified types of all the parameters. The method we will describe is the following from mscorlib: System.IEquatable<T>.Equals(System.IEquatable<T> other); First we create some basic partial identifiers that can be reused: GraphNodeId mscorlib = GraphNodeId.GetPartial(CodeNames.AssemblyName, new Uri(typeof(string).Assembly.Location)); GraphNodeId system = GraphNodeId.GetPartial(CodeNames.NamespaceName, \"System\"); GraphNodeId iequatable = GraphNodeId.GetPartial(CodeNames.NameName, \"IEquatable\"); GraphNodeId equals = GraphNodeId.GetPartial(CodeNames.NameName, \"Equals\"); Next we build a nested identifier representing the generic type IEquatable<T> , which is represented by combining a GenericParameterCountName of 1 with the name \u201cIEquatable\u201d. The fact that the generic parameter is called T does not need to be remembered here: GraphNodeId iequatableGeneric = GraphNodeId.GetNested(new GraphNodeId[] {iequatable, GraphNodeId.GetPartial(CodeNames.GenericParameterCountName, 1) }); Now we can say TypeName=IEquatable<T> like this: GraphNodeId typeName = GraphNodeId.GetPartial(CodeNames.TypeName, iequatableGeneric); Now we can describe the method parameters using this nested name: GraphNodeId methodParameters = GraphNodeId.GetPartial(CodeNames.OverloadingParametersName, new GraphNodeIdCollection(true, GraphNodeId.GetNested(new GraphNodeId[] { mscorlib, system, typeName }))); Now we can describe the \u201cEquals\u201d method and it\u2019s parameters using this: GraphNodeId method = GraphNodeId.GetPartial(CodeNames.MemberName, GraphNodeId.GetNested(new GraphNodeId[] { equals, methodParameters })); Now we can fully type the method by adding assembly, namespace and type GraphNodeId result = GraphNodeId.GetNested(new GraphNodeId[] { mscorlib, system, typeName, method }); This results in the following serialized identifier: (Assembly=\"file://c:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll\" Namespace=System Type=(Name=IEquatable GenericParameterCount=1) Member=(Name=Equals OverloadingParameters=[(Assembly = \"file://c:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll\" Namespace = System Type = (Name = IEquatable GenericParameterCount = 1))]))} Notice how in the construction of the GraphNodeId that many sub-parts can be shared across many GraphNodeIds and this is how it can achieve performance and memory wins. Core Model The core graph model begins with the container called Graph. You can simply create a new empty Graph object as follows: Graph graph = new Graph(); This object can also be serialized to and from disk using the Load/Save methods (See Serialization for details): Graph graph = Graph.Load(dgmlFile); A graph can contain Nodes and Links which you can add using the Nodes and Links collections: GraphNode a = graph.Nodes.GetOrCreate(\"a\"); GraphNode b = graph.Nodes.GetOrCreate(\"b\"); GraphLink link = graph.Links.GetOrCreate(a, b); This could be visualized as the following: The Graph model is fully editable, you can insert or delete any node or link, and all expected ripple effects are taken care of. For example, when you add a Link, both end point nodes are added automatically if they are not there. If you Remove a node, all Links connected to that node are removed automatically. In this way the Graph is always left in a valid state after any editing operation. Graph nodes and links cannot belong to multiple Graph objects at the same time. If you add a node to a different Graph than it was created in, then that will become an \u201cimport\u201d operation and a new GraphNode instance will be created. To that end there are many helper methods dealing with copying subsets of a Graph to and from other Graph objects. See Copy, ImportSubset and Merge methods. For improved performance you should always wrap edit operations in a GraphTransactionScope . This will be covered in more detail below. Categories & Properties The root Graph , GraphNode and GraphLink can all contain properties and categories. There is a common base class called GraphObject . GraphObject has a collection of Properties and Categories. For example, the following node has the category \u201cVegetable\u201d and the \u201cBackground\u201d property with the value \u201cGreen\u201d: <Node Id=\"A\" Label=\"Tree\" Category=\"Vegetable\" Background=\"Green\"/> And the following node has the category \u201cElement\u201d and a \u201cFontStyle\u201d property with value \u201cItalic\u201d: <Node Id=\"B\" Label=\"Water\" Category=\"Element\" FontStyle=\"Italic\"/> The following link has the category \u201cDrinks\u201d with a \u201cWeight\u201d property with the value \u201c5\u201d. <Link Source=\"A\" Target=\"B\" Category=\"Drinks\" Weight=\"5\" /> In code you get and set properties using the GetValue/SetValue/ClearValue methods, and you get or set categories using HasCategory and AddCategory, and RemoveCategory. Properties and Categories can be used for all sorts of things. The GraphModel itself has some special built in properties and categories used to describe some things like grouping. GraphCategory and GraphProperty can also contain extra metadata describing what they are about. You could think of a GraphCategory as a property that has no value. But categories have one other feature, namely, GraphObject can inherit properties defined on the GraphCategory and categories can inherit properties from other categories via a BasedOn property. This allows you to setup loose taxonomies using this metadata system. For example, we can promote the Backgound and FontStyle properties to the GraphCategory and thereby every node that has the Category=\u201dVegetable\u201d will be italic and every node with the Category=\u201dElement\u201d will be blue. <Category Id=\"Element\" Background=\"Blue\" /> <Category Id=\"Plant\" FontStyle=\"Italic\" /> Now anything with the category Plant will have a tree icon, including anything that has the category Tree, since the Tree category is \u201cBasedOn\u201d the Plant category. <?xml version=\"1.0\" encoding=\"utf-8\"?> <DirectedGraph GraphDirection=\"LeftToRight\" xmlns=\"http://schemas.microsoft.com/vs/2009/dgml\"> <Nodes> <Node Id=\"A\" Category=\"Tree\" Label=\"Tree\" /> <Node Id=\"B\" Category=\"Element\" Label=\"Water\" /> </Nodes> <Links> <Link Source=\"A\" Target=\"B\" /> </Links> <Categories> <Category Id=\"Element\" Background=\"#FF0000FF\" /> <Category Id=\"Plant\" FontStyle=\"Italic\" /> <Category Id=\"Tree\" Icon=\"Tree.png\" BasedOn=\"Plant\" Shape=\"None\" /> </Categories> <Properties> <Property Id=\"Background\" Label=\"Background\" Description=\"The background color\" DataType=\"System.Windows.Media.Brush\" /> <Property Id=\"GraphDirection\" DataType=\"Microsoft.VisualStudio.Diagrams.Layout.LayoutOrientation\" /> <Property Id=\"Icon\" Label=\"Icon\" Description=\"Icon\" DataType=\"System.String\" /> <Property Id=\"Shape\" DataType=\"System.String\" /> <Property Id=\"FontStyle\" DataType=\"System.Windows.FontStyle\" /> </Properties> </DirectedGraph> Which could be visualized like this: Notice also that properties can have labels, datatypes and descriptions. A \u201cHasCategory\u201d method is provided which will return true if the given category is found on the GraphObject or in anyway in the BasedOn chain. To define your own properties and categories see Schemas. Grouping A Graph can model the concept of grouping by using GraphLink to establish \u201cContains\u201d relationships between two nodes and a \u201cGroup\u201d property on the container node, like this: <Nodes> <Node Id=\"Child\" /> <Node Id=\"Group\" Group=\"Expanded\" /> </Nodes> <Links> <Link Source=\"Group\" Target=\"Child\" Category=\"Contains\" /> </Links> This describes a Graph that could be visualized like this: Nested containments can be described the same way and the Graph model provides helper methods for finding ancestors and descendants along these \u201cContains\u201d link relationships. The GraphModel also allows any number of links between nodes, so you could model multiple containment relationships and create a Graph that could be visualized like this: Note : Visual Studio does not support visualizing multi-containment. The Graph Model even allows a child to contain a parent and a parent to contain a child. This is called circular containment. This can be tricky to program, so the Graph Model provides helper methods for searching for ancestors and descendants without getting stuck in infinite loops caused by circularity. The Graph Model also provides a helper class called GraphGroup which wraps each GraphNode that has a Group property and exposes additional properties like ChildNodes and ChildGroups and Parents to make it even easier to deal with groups. But it is important to note that GraphGroup is a helper class and just a wrapper object on GraphNode. These objects are not constructed unless you ask for them and can come and go as the inner GraphNode is edited. For additional convenience you can also set properties and categories on the GraphGroup object and that will be passed down to the inner GraphNode object. So the GraphGroup always reflects the same categories and properties as the node that it wraps. The Graph object then also provides the following helper methods for dealing with groups: - AllGroups \u2013 returns a list of all GraphGroup objects - Groups \u2013 returns a list of top level groups - VisibleTopLevelGroups \u2013 returns a list of visible top level groups - FindCommonAncestor - return the common ancestor of all the given nodes - FindGroup \u2013 return the GraphGroup wrapper for a node that has a Group property - GetGroupDescendants \u2013 provides a way to walk the group hierarchy. MultiLinks The Graph model can also support multiple links between the same two nodes: These are known as multigraphs and are useful in modeling state machines where multiple different transitions can take you from one state to another. GraphLinks are distinguished from each other by providing a unique \u201cIndex\u201d property on each one using the following API: public GraphLink GetOrCreate(string sourceId, string targetId, int index) public GraphLink GetOrCreate(GraphNodeId sourceId, GraphNodeId targetId, int index) The index property that becomes part of the unique identifier of this link, so the unique identifier of a link is the source node id + target node id + index. So the index only needs to be unique between the same two nodes. If you specify an index that already exists then you will not be creating a new link, instead you will get back the existing link, which is the normal semantics for all Graph Model \u201cGetOrCreate\u201d methods. You can find the link with specific index using the following new overloads: public GraphLink Get(string sourceId, string targetId, int index) public GraphLink Get(GraphNodeId sourceId, GraphNodeId targetId, int index) And you can find out what index a given link has using the following property on GraphLink: ```csharp public int Index { get; } This returns an optional Index of this link. Default is zero. This index can be specified when you create a link, providing different index values makes it possible to create multiple links between the same source and target nodes. The following graph is using multilinks where the \u201cReferences\u201d link has Index=1 and the \"Calls\" links has default index 0: ![](MultilinkDemo1.png) And if you copy & paste that into the following graph, where this link has been manually edited to have Index=3: ![](MultilinkDemo2.png) Then the link indexes will be preserved via serialization and you will get the following combined graph: ![](MultilinkDemo3.png) The idea is that the \"Index\" belongs to the end user, if they specify it, then they want it preserved. The GraphModel does not do any automatic re-writing of link indexes. ### Searching Graphs The following helper method makes navigating Graphs easier. ```csharp public IEnumerable<GraphNode> FindRelatedNodes(GraphSearchDirection searchDirection, Predicate<GraphLink> traverseLink, Predicate<GraphNode> traverseNode, Predicate<GraphNode> acceptNode) This method finds the dgml nodes that match the acceptNode predicate and are related in a way that matches the traverseLink and traverseNode predicates. Nodes are found by doing a breadth first search along links matching the traverseLink predicate, in the Source or Target direction designated by the searchDirection parameter. If the node matches the traverseNode predicate it keeps searching recursively through that node in the same direction and returns all nodes that match the acceptNode predicate. The search can handle circularity in the graph. The following example searches through all nodes reachable via all links from the start node and returns all nodes that have the Method category: node.FindRelatedNodes(GraphSearchDirection.Target, l => true, n => true, n => HasCategory(MethodCategory); Eventing (Change Tracking) All changes to the graph model can be tracked using the following change events on the Graph object: public event EventHandler<GraphUpdatedEventArgs> Updated; public event EventHandler<GraphUpdatedEventArgs> Updating; The Updating method happens while a transaction is being committed so you can see the old property values before they are changed. The Updated event happens after a successful Commit happens and the GraphUpdatedEventArgs contains all the changes that happened within that transaction. You can listen to these events by doing the following: Graph g = new Graph(); g.Updated += OnGraphUpdated; It is highly recommended that you use GraphTransactionScope when you change multiple objects in the Graph like this: using (var scope = g.BeginUpdate(Guid.NewGuid(), \"Add stuff\", UndoOption.Add)) { GraphNode foo = g.Nodes.GetOrCreate(\"foo\"); GraphNode bar = g.Nodes.GetOrCreate(\"bar\"); GraphLink calls = g.Links.GetOrCreate(foo.Id, bar.Id, 0); GraphLink references = g.Links.GetOrCreate(foo.Id, bar.Id, 1); scope.Complete(); } Notice the important scope.Complete() call at the end of this block. See the section on Transactions below. When the transaction scope is completed, all these edits are rolled up into one batch operation so your OnGraphUpdated method will be given a GraphUpdatedEventArgs that contains the added nodes and added links: static void OnGraphUpdated(object sender, GraphUpdatedEventArgs e) { var nodes = e.AddedNodes; var links = e.AddedLinks; } This style of batching up updates results in much more efficient processing in an application because UI objects can respond to graph changes in batch updates, rather than being evented to death with too many fine grained singleton events. This style of batching also makes it trivial to implement Undo/Redo. Note : there is an important rule that you must obey in your OnGraphUpdated events. You must not create another GraphTransactionScope inside that event handler on the same Graph object. If you do attempt to do this you will get an invalid operation exception. If you really want fine grained events, you can also listen to the lower level PropertyChanged and CategoryChanged events on GraphObject. This is useful for UI Data Binding scenarios. Undo/Redo Support The following classes can be used to build an Undo/Redo stack for graph operations using the change tracking events GraphUndoUnit GraphUndoManager UndoableGraphTransactionScope UndoOptions Transactions As mentioned above in Eventing, it is highly recommended that you use GraphTransactionScope . In fact, if you don\u2019t use GraphTransactionScope then implicit scopes will be created for every individual edit, which can end up being a lot more expensive. GraphTransactionScopes support the following features: 1. If your code throws an exception before the scope.Complete call then all the changes inside that scope are rolled back, leaving the Graph in a consistent state. 2. Other threads are isolated from your changes until scope.Complete . This allows other threads to \u201cread\u201d the graph and see a consistent state until and your changes then appear atomically to them. ( Note : the Graph is not thread safe for Write operations. See Threading Model). 3. GraphTransactionScope supports nesting. For example your could call a method and that method creates another GraphTransactionScope and completes it before returning back to you. In this case the inner transaction is not really completed until the outer most GraphTransactionScope is completed. Similarly, if the inner scope is aborted, it is not aborted until the outer GraphTransactionScope is completed. Note: abort can be tricky, because an inner scope can cause all the outer scopes to be aborted. This can be a source of bugs. See Trouble Shooting. Threading Model The Graph object model is thread safe for \u201cread\u201d but not for \u201cwrite\u201d, there can only be one writer at a time. The GraphTransactionScopes provide thread isolated storage, so each reader sees a consistent view of the Graph model until each transaction is committed or rolled back. During commit however, the readers are not isolated while the changes stored in isolated storage are being merged back into the real storage. GraphNodeId, GraphCategory and GraphProperty are thread-safe for read and write. Graph Metadata The metadata associated with properties and categories is not stored directly in the GraphProperty or GraphCategory. Instead the metadata is stored in the Graph. In this way different instances of Graph could have different metadata associated with the same category or property. Conversly two Graphs could share the same metadata and reduce the overhead of copying all that redundant information. For example, one Graph might want the Background color of anything with the Plant category to be Green, while another Graph might want the Background color of anything with the same category to be Brown. This is possible, because the \u201cmetadata is local to the Graph\u201d and it is not statically shared. To enable this, the construction of GraphMetadata properties is done lazily via a \u201cFactory Pattern\u201d, where you provide the factory for the metdata when you register your property or category as follows: GraphCategory Vegetable = Schema.Categories.AddNewCategory(\"Vegetable\", () => { GraphMetadata meta = new GraphMetadata(GraphMetadataOptions.Default); meta.SetValue(Background, Brushes.Green); return meta; }); One other advantage of this lazy metadata model is that this metadata is only created when someone actually asks for it. The GraphMetadataOptions provide the following additional semantics associated with your property or category: Immutable - The property cannot be changed once set. Removable - The property can be removed after it is set. Otherwise it can only be changed, and not removed. Browsable - The property is visible in the UI (such as in tool tips and the property grid Serializable - The property will be serialized to DGML when the graph is serialized. Substitutable - File path values will be replaced with aliases during serialization. Sharable - The property will be transferred along with the GraphObject when the GraphObject is being copied to another graph. Sometimes it is useful to have private properties for you app state only that are not shared across copy/paste operations. Undoable - The property might not be serializble, but it needs to be saved on the undo stack and made undoable. Serializable is automatically also undoable, but you might also want properties that are not serializable but are undoable. The default set of metadata options is Serializable | Removable | Browsable | Sharable . Schemas Typically applications will want to define a set of related properties and categories, give that set a name and be able to reference the set that way. This is called a GraphSchema . A Graph can contain multiple different GraphSchemas. Typically GraphSchemas are defined statically and hooked into the common schema so they are discoverable from anywhere in the process, this ensures that properties are typed the same way throughout the process which is important. The following shows an example schema that defines a Background property of type Brush and a Vegetable category that has a default typed value of Green for the Background property. using Microsoft.VisualStudio.GraphModel.Schemas; public static class MySchema { static GraphSchema Schema; public static GraphCategory Vegetable; public static GraphProperty Background; static MySchema() { Schema = new GraphSchema(\"MySchema\"); GraphCommonSchema.Schema.AddSchema(Schema); Background = Schema.Properties.AddNewProperty(\"Background\", typeof(Brush)); Vegetable = Schema.Categories.AddNewCategory(\"Vegetable\", () => { GraphMetadata meta = new GraphMetadata( \"Vegetable\", \"This is a description of the category\", \"Living Things\", GraphMetadataOptions.Default); meta.SetValue(Background, Brushes.Green); return meta; }); } } You can then use your category like this: Graph g = new Graph(); g.Nodes.GetOrCreate(\"foo\", null, MySchema.Vegetable); g.Save(@\"d:\\temp\\graph.dgml\"); And the result will be serialized to the following DGML: <?xml version=\"1.0\" encoding=\"utf-8\"?> <DirectedGraph xmlns=\"http://schemas.microsoft.com/vs/2009/dgml\"> <Nodes> <Node Id=\"foo\" Category=\"Vegetable\" /> </Nodes> <Links /> <Categories> <Category Id=\"Vegetable\" Background=\"#FF008000\" /> </Categories> <Properties> <Property Id=\"Background\" DataType=\"System.Windows.Media.Brush\" /> </Properties> </DirectedGraph> You can also fetch the metadata using the GetMetadata method on GraphProperty and GraphCategory : Graph g = new Graph(); var node = g.Nodes.GetOrCreate(\"foo\", null, MySchema.Vegetable); GraphCategory c = node.Categories.First(); GraphMetadata m = c.GetMetadata(g); Console.WriteLine(m.Description); This prints the message This is a description of the category . Notice that to get the metadata for a given category or property you need to provide the owing Graph object. GraphMetadata belongs to a graph instance, it is not static. This makes it easier to compose Graph objects in a large product like Visual Studio without without having to force every plugin to use a fixed common schema. Default Schema The following default schema is provided with every Graph by default. It defines categories and properties that are used by the Graph Model API itself and are common enough to be shared by all Graph instances. public static class GraphCommonSchema { public static GraphSchema Schema { get; } public static GraphProperty Visibility { get; } public static GraphProperty UniqueId { get; } public static GraphProperty TargetNode { get; } public static GraphProperty SourceNode { get; } public static GraphProperty Label { get; } public static GraphProperty IsTag { get; } public static GraphProperty IsPseudo { get; } public static GraphProperty IsContainment { get; } public static GraphProperty Group { get; } public static GraphProperty ValueLabel { get; } public static GraphCategory Contains { get; } public static GraphProperty GroupLabel { get; } public static GraphProperty Value { get; } public static GraphProperty TargetType { get; } public static GraphProperty Property { get; } public static GraphProperty Expression { get; } public static GraphProperty IsEnabled { get; } public static GraphProperty IsCursorContainingMethod { get; } public static GraphProperty IsDragSource { get; } public static GraphProperty DelayedCrossGroupLinksState { get; } public static GraphProperty DelayedChildNodesState { get; } public static GraphProperty BaseUri { get; } public static GraphProperty ToolTip { get; } public static GraphProperty Version { get; } } Styles The GraphModel provides a way to define GraphProperty values in a \u201cconditional\u201d way based on conditional expressions stored in Conditional Styles. While the name \u201cStyle\u201d has user interface connotations, this is not the only reason to use styles. You could also think of Styles as a system for generating \u201cComputed Property Values\u201d. You\u2019ll see the following classes in the Microsoft.VisualStudio.GraphModel.Styles namespace: Conditional styles look similar to WPF styles, but the expressions can be more powerful. The following is a conditional style serialized as DGML. <Style TargetType=\"Node\" GroupLabel=\"Class\" ValueLabel=\"Has category\"> <Condition Expression=\"HasCategory('Class')\" /> <Setter Property=\"Background\" Value=\"#D3DCEF\" /> <Setter Property=\"Icon\" Value=\"CodeSchema_Class\" /> </Style> This style defines a Background and Icon property value for all nodes that have the \u201cClass\u201d category. The side effect of having this style associated with the Graph object is that any time you call GetValue on a node that also has any category based on the \u201cClass\u201d category, you will get back the Background property value defined above. GraphNode foo = g.Nodes.GetOrCreate(\"foo\", null, MySchema.Class); Brush brush = foo.GetValue<Brush>(MySchema.Background); This example is the same as storing the Background property on the GraphCategory metadata, however the conditional style expression can be a lot richer. For example, the following expression will cause the style to be applied only if the class is public and has more than 10 outgoing links. <Condition Expression=\"IsPublic and OutgoingLinkCount > 10\" /> The property setters can also provide expressions instead of fixed values, so that you can have computed values. The following example shows how you can combine these ideas to produce interesting results: <Style TargetType=\"Node\" GroupLabel=\"Coverage\" ValueLabel=\"Good\"> <Condition Expression=\"Coverage &gt; 80\" /> <Setter Property=\"Background\" Value=\"Green\" /> </Style> <Style TargetType=\"Node\" GroupLabel=\"Coverage\" ValueLabel=\"Ok\"> <Condition Expression=\"Coverage &gt; 50\" /> <Setter Property=\"Background\" Expression=\"Color.FromRgb(180 * Math.Max(1, (80 - Coverage) / 30), 180, 0)\" /> </Style> <Style TargetType=\"Node\" GroupLabel=\"Coverage\" ValueLabel=\"Bad\"> <Setter Property=\"Background\" Expression=\"Color.FromRgb(180, 180 * Coverage / 50, 0)\" /> </Style> This set of styles breaks the nodes into groups. The first group has \u201cCoverage\u201d property > 80, the next has Coverage > 50, and the last one has all the others. Then a Background color property is computed based on the Coverage property values so that the result is a gradation of colors between green and red that illustrate the amount of Coverage that each node has: This shows that Styles are applied in a given order (they order in which they are added to the ConditionalStyleCollection ), and the style that matches first owns the properties it is setting. In other words, the following Styles that also match, will only be able to affect different properties on the nodes. Another way to say it is that the properties affected by matching styles are mututally exlusive. Styles can have a TargetType of Node, Link or Group. Style Compilation & Evaluation Styles will not automatically be applied to your Graph unless you Compile the style set using the Compile method on the GraphConditionalStyleCollection . Style Eventing Your application may want to receive PropertyChange events on nodes and links whenever the style is changed, or the property values on which they are conditionally evaluated change. For example, in the above example if I change the \u201cCoverage\u201d property from 50 to 80, then I expect the \u201cBackground\u201d property value to change in the user interface. But how does this work? A Graph \u201cUpdated\u201d event will not be fired automatically in this case and the GraphNode PropertyChange event will not be fired automatically when you set the Coverage property. Once you Compile your GraphConditionalStyleCollection , it will then start tracking changes to properties in the Graph and it will remember if it sees any property change that has a conditional expression or setter expression that references that property. Then at the time you want your user interface updated you must call the RaisePendingPropertyChangeEvents passing in the nodes you want updated. You might limit it to just the visible nodes in your user interface for example. This will then raise OnPropertyChange events for all the affected style setters, in this case the \u201cBackground\u201d properties change events are raised and it raises it only on graph objects that match the conditional expressions. See Data Binding for more information. Psuedo Nodes and Links Sometimes it is handy to generate fake nodes and links in your Graph object that you do not want serialized back to disk. In this case you can add the IsPseudo property to them and when you save the Graph they will disappear: GraphNode fake = g.Nodes.GetOrCreate(\"fake\"); fake.IsPseudo = true; Serialization The Graph model can serialize itself to and from the DGML XML format. The easiest way to serialize a graph is using the Load and Save methods: Graph graph = Graph.Load(dgmlFile); graph.Save(@\"d:\\temp\\graph.dgml\"); That is pretty much all you will ever need to know. There is a GraphSerializationSettings class that allows you to control sorting and do some error handling. You can also use it to re-write the GraphNodeIds during serialization which can be handy way to transform names. GraphDataObject Related to the topic of serialization is the GraphDataObject helper class which implements the WPF IDataObject interface and provides a way to exchange graph objects in copy/paste and/or drag/drop operations. In order to make this possible the Graph object itself is also ISerializable . It\u2019s implementation just uses it\u2019s built in DGML serialization abilities. When you create a GraphDataObject you can decide which clipboard formats you want it to publish using this method: public static IDataObject Create(IEnumerable<GraphNode> selection, Guid sourceGraphId, int levels, DataFormat[] formats) Or you can use the other method and get the default set AllDgmlFormats which include DGML, XML, Text and UnicodeText. The Text format is DGML, so some applications like to publish only DGML and XML and switch the Text format to something more readable. The GraphDataObject also provides helper methods for efficiently sniffing the clipboard to see if it contains something like valid DGML: public static bool IsClipboardDgml() and public static bool IsDgml(string markup) Merging Drag/Drop If you bring subsets of a Graph across in multiple drag/drop operations, you will probably want the \u201clinks\u201d to hook up. For example, suppose you have this graph: Now suppose you grab the \u201cFoo\u201d node and drag it or copy/paste it to a new graph. You will want this: Now go back to the original graph and bring over the comment. You will probably expect to see this: For this to work the GraphDataObject needs to contain more than just the selected nodes. Usually, you call GraphDataObject.Create with the selection, and pass the \u201clevels\u201d parameter value 1 so that it includes all nodes 1 link away from the selection. Then on the drop/paste side you want to \u201cMerge\u201d that GraphDataObject into your target Graph object, and delete the extra information that was not needed. For example, in the first drop operation you do not want the comment or the link. In the second drop operation you do want the link but you don\u2019t need Foo because you already have it, so you want it merged. To enable all this, the GraphDataObject.Create method does the following: 1. It marks the selected nodes with an GraphCommonSchema.IsDragSource property. 2. It marks all nodes that are not in the selection with : SetValue(GraphCommonSchema.Visibility, System.Windows.Visibility.Hidden) Then on the Merge side you can: 1. Make sure not to override Visibility on the target nodes 2. Do not create nodes or links if the dropped node is hidden and the target nodes didn\u2019t already exist 3. Select all nodes with IsDragSource property, then remove this temporary property. In this way you can get the above semantics in your application. Advanced Serialization You are welcome to read about advanced compression techniques below, but few people will need to know about this because the Graph Load and Save methods hide all this gory detail from you. If you look at a serialized DGML file, however, you may notice some of these things and wonder how they work. File Path Substitution You might have many repetitions of a long file path in your node ids or in property values. For example, a graph of mscorlib could contain thousands of copies of the string file:///C:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll . In this case it is possible to tell the Graph to give this path a name, let\u2019s call it \u201cFxUri\u201d and then everywhere this path is found it can write out the variable substitution instead which is much shorter: $(FxUri)/mscorlib.dll These path names are defined in the GraphPathSerializationDictionary which is available from the CommonPaths property on the Graph object. This property is static so you can define the common paths before you call Graph.Load. This makes it possible to also map these common paths to different locations on your machine, which can help to make DGML documents more \u201cportable\u201d. The Graph serializer sets up a bunch of common paths by default, basically all the Environment.GetSpecialFolders plus .NET frameworks, reference assemblies and your current directory. Your application can listen to the CommonPathsAdded event on the GraphPathSerializationDictionary to add any more paths that are not predefined that way. GraphNodeId aliasing GraphNodeIds can also contain many redundant sub-parts, as shown in the top section on GraphNodeId. Serializing all this back out can result in lots of redundant text. So the Graph serializer creates integer values for each unique GraphNodeId called \u201caliases\u201d and uses those instead of the long serialized text. Then it writes the aliases to disk in a special section of the DGML file as follows: <IdentifierAliases> <Alias n=\"1\" Uri=\"Assembly=$(fxUri)/mscorlib.dll\" /> <Alias n=\"2\" Id=\"Namespace=System\" /> <Alias n=\"3\" Id=\"(@1 @2)\" /> <Alias n=\"4\" Id=\"(@1 @2 Type=String)\" /> <Alias n=\"6\" Id=\"(@1 @2 Type= String Member=Join)\" /> </IdentifierAliases> Then the ids in the nodes and links can be very small like this: <Link Source=\"@3\" Target=\"@4\" Category=\"Contains\" /> <Link Source=\"@3\" Target=\"@5\" Category=\"Contains\" /> <Link Source=\"@4\" Target=\"@6\" Category=\"Contains\" /> <Link Source=\"@4\" Target=\"@7\" Category=\"IndirectlyContains\" /> <Link Source=\"@6\" Target=\"@7\" Category=\"Contains\"> Notice that the aliases can use the path substition as well. Note: you will never see path variables or aliases in memory after you do Graph.Load. Linq Extensions GraphEnumerable provides the following extension methods: - AsNodes \u2013 this method makes it easier to deal with heterogeneous collections of GraphNode and GraphGroup by unwrapping the GraphGroup objects, returning only GraphNodes. - GetGroups \u2013 this method returns only GraphGroup objects stripping out any objects that are not groups. - GetDescendants \u2013 this method returns all descendants of the given graph objects, independent of whether those objects are GraphNodes or GraphGroups. Data Binding In order to support dynamic languages and WPF data binding the GraphObject implements the following interfaces: IDynamicMetaObjectProvider INotifyPropertyChanged GraphNodeIdPropertyDescriptor The dynamic meta object provides BindGetMember and BindSetMember as a way to set properties on the graph. This makes it possible to interact with GraphProperties using dynamics like this: dynamic node = g.Nodes.GetOrCreate(\"Foo\"); node.Color = Colors.Red; This combined with INotifyPropertyChanged allows WPF to you to bind to the properties stored in a GraphObject to a visual element and WPF will know how to watch for property change events on those properties. The GraphNodeIdPropertyDescriptor is a specialized class that makes it possible to present a GraphNodeId in a property window in a structured way like this: Graph Providers Some interfaces are defined for those who want to create a plugin model that provides Graph subsets to other parts of the application. This is used in Visual Studio - it is how languages extend Solution Explorer with type information. Graph generators like to share common concepts in the form of graph schemas containing common GraphNodeIdNames, GraphCategories and GraphProperites. These shared classes are described in GraphProvider.docx spec. Data Virtualization Sometimes you might want a graph that represents only a portion of what is available in a data base. In this case it is handy to remember which groups are fully populated and which are not. The following GraphProperties helps with this: DelayedChildNodesState DelayedCrossGroupLinksState IsDelayedCrossGroupLink DelayedDataState No actual support for Data Virtualization is provided beyond just this convention for annotating where you are doing Data Virtualization in your Graph objects. This could help for example, in creating visuals that know how to represent this concept in a user interface, independent of the implementation behind it. Trouble Shooting One common source of bugs is when someone forgets to include a scope.Complete() at the end of their GraphTransactionScope using block. This will cause the transaction to roll back, along with any outer GraphTransactionScopes, and it will look like the graph edits didn\u2019t work, when in reality, they are being rolled back.","title":"GraphModel Specification"},{"location":"posts/GraphModel/#dgml-graph-model-specifications","text":"The Directed Graph Markup Language (.dgml) features of Visual Studio are built on a node/link graph data model. This data is persisted in DGML documents which is an XML format. While it is possible to edit the XML directly, it is not fun or productive. The Graph Model API provides an in-memory representation that is natural for manipulating directed graphs and has become the foundation of all the dependency analysis features in VS. For this reason the API has been made available anyone extending Visual Studio.","title":"DGML Graph Model Specifications"},{"location":"posts/GraphModel/#goals","text":"Performance: Being the platform for lots of features the model needs to be as fast as possible. Usability: Close behind however is the fact that the API needs to be simple to use Convenience: Where practical helper methods are provided for added convenience, but this is not the top priority of this API. Helper libraries can always be provided out of band or as sample code. Thread safe: Some amount of thread safety and thread isolation is nice for this level of API","title":"Goals"},{"location":"posts/GraphModel/#non-goals","text":"The API does not attempt to be the front end to a database.","title":"Non-Goals"},{"location":"posts/GraphModel/#design","text":"The Complete Graph Model API is available on MSDN. This spec just outlines the core concepts that must be understood in order to use this API. The Graph model can serialize itself to and from the DGML XML format.","title":"Design"},{"location":"posts/GraphModel/#graphnodeid","text":"In order to support first class serialization and decoupling of graph operations across components, or in databases, it is important to name the objects in a graph carefully. To this end the Graph Model does not use System.String to name things. The GraphNodeId class is used instead. GraphNodeId is a structured identifier that composes nested sets of Name=Value pairs, for example, you can create a GraphNodeId that points to an Assembly like this: GraphNodeId mscorlib = GraphNodeId.GetPartial(CodeNames.AssemblyName, new Uri(typeof(string).Assembly.Location)); This serializes to the following string format: (Assembly=file:///C:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll) Then you can name the System Namespace inside mscorlib by composing the following two names together: GraphNodeId system = mscorlib + GraphNodeId.GetPartial(CodeNames.NamespaceName, \"System\"); Then you can name the String Class by adding on to the name of the namespace: GraphNodeId str = system + GraphNodeId.GetPartial(CodeNames.TypeName, \"String\"); Then you can name the Join method by adding to the name of the class: GraphNodeId join = str + GraphNodeId.GetPartial(CodeNames.Name, \"Join\"); The result is an identifier that remembers the structure you used to build the name and this structure can also be serialized to and from the following string format: (Assembly=file:///C:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll Namespace=System Class=String Method=Join) This sort of composition of names allows the application to avoid having to do lots of expensive string parsing operations every time it needs a part of the name. It also provides hashing advantages so that comparing identifiers is a lot faster and the overall memory used is much less than using strings. As you can imagine, naming everything in mscorlib results in many redundant Assembly, Namespace, Class sub strings, so building up identifiers using string addition would be very expensive: string mscorlib = \u201cAssembly=file:///C:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll\u201d; string system = mscorlib + \u201c Namespace=System\u201d; string stringClass = system + \u201c Type=String\u201d; string joinMethod = stringClass + \u201cMethod=Join\u201d; The following table shows the comparison between System.String and GraphNodeId in construction time, comparison and total memory usage measured using all the identifiers in System.Xml.Linq.dll (about 2000 identifiers) and about 4 million comparisons (comparing every identifier against every other). The construction time for the GraphNodeId\u2019s here is the worst case and assumes no reuse of in memory ids. For example, it recreates the Assembly id over and over rather than holding onto one GraphNodeId pointer for that assembly. This is not typically how the product code will work, but it is the worst case. It is how Serialization would work, so it essentially measures serialization load time. For that reason strings are faster to load, but you can see that memory usage and comparison time, GraphNodeId wins considerably, this is because GraphNodeId is \u201catomized\u201d, so that comparison can be a simple object reference comparison. Note: string.Intern doesn\u2019t help the string case here because every identifier is different, and string.Intern would add substantial hit to load time, which would make it slower than GraphNodeId. GraphNodeId registration is static so they employ a WeakReference system to garbage collect ids that are not used.","title":"GraphNodeId"},{"location":"posts/GraphModel/#graphnodeid-value-types","text":"The GraphNodeId values can be any type that can be converted to/from a string using TypeConverter. However, the following types are well supported: String: \u201cNamespace=System.Collections\u201d. Uri: \u201cAssembly=file://mscorlib.dll\u201d. GraphNodeIdCollection: \u201cParentType=(Assembly=file://mscorlib.dll Namespace=System.Collections Type=ArrayList)\u201d.","title":"GraphNodeId Value Types"},{"location":"posts/GraphModel/#graphnodeidname","text":"The name part is a static object called a GraphNodeIdName . The name also determines the type of value that the GraphNodeId can contain, and how a string should be parsed back during string serialization. For example, Namespace will be registered as string, but assembly as URI: class CodeNames { public static GraphNodeIdName AssemblyName = GraphNodeIdName.Get(\"Assembly\", \"Assembly\", typeof(Uri)); public static GraphNodeIdName NamespaceName = GraphNodeIdName.Get(\"Namespace\", \"Namespace\", typeof(string)); public static GraphNodeIdName TypeName = GraphNodeIdName.Get(\"Type\", \"Type\", typeof(object)); public static GraphNodeIdName NameName = GraphNodeIdName.Get(\"Name\", \"Name\", typeof(String)); public static GraphNodeIdName GenericParameterCountName = GraphNodeIdName.Get(\"GenericParameterCount\", \"GenericParameterCount\", typeof(int)); public static GraphNodeIdName MemberName = GraphNodeIdName.Get(\"Member\", \"Member\", typeof(Object)); public static GraphNodeIdName OverloadingParametersName = GraphNodeIdName.Get(\"OverloadingParameters\", \"OverloadingParameters\", typeof(GraphNodeIdCollection)); } Notice the GraphNodeIdName objects are usually static so they can be shared by the whole process. There are also 3 special names for qualified identifiers. These are non-printed names, and are inferred during parsing. GraphNodeIdName.Nested \u2013 a list of GraphNodeIds \u201c(Assembly=file://mscorlib.dll Namespace=System Type=String)\u201d. The data type of a Nested value is always GraphNodeIdCollection. In the above case, there are 3 nested identifiers: Assembly, Namespace and Type. GraphNodeIdName.Array \u2013 represents a list of GraphNodeId\u2019s where each item in the list has the same type. For example, the arguments to a method each have the same type \u201cMethodParameter\u201d, so think of the array as a way to lift the \u201cMethodParameter\u201d part out of the list, so instead of (MethodParameter=Value MethodParameter=Value MethodParameter=Value) you can say MethodParameter=[Value, Value, Value]. The data type of Array value is always GraphNodeIdCollection \u2013 with homogeneousItems =true. GraphNodeIdName.Literal - \u201cBing!\u201d. The data type of a Literal is a String. If a GraphNodeId is being constructed through parsing, and a name is not currently registered, a new name will be registered with a data type of System.Object. If you want to reuse the same GraphNodeIdName in some places with a string value and in other places with a nested GraphNodeIdCollection then type the GraphNodeIdName as System.Object.","title":"GraphNodeIdName"},{"location":"posts/GraphModel/#parsing-standard-form","text":"A standard GraphNodeId always has a Nested outer GraphNodeId, with one or more GraphNodeId inside. A GraphNodeId that\u2019s not part of a nested qualified identifier is said to be a partial qualified identifier. This is why the following method is called GetPartial: GraphNodeId.GetPartial(CodeNames.NamespaceName, \"System\"); returns \"Namespace=System\" To make this a standard identifier wrap it in a GetNested call: GraphNodeId id = GraphNodeId.GetNested( GraphNodeId.GetPartial(CodeNames.NamespaceName, \"System\") ); This results in the following well formed identifier: \"(Namespace=System)\" This is important during parsing. Although it is possible to build a partial GraphNodeId using the .GetPartial() API, it is not possible to construct one using .Parse(). Instead, GraphNodeId.Parse(\u201cNamespace=System\u201d)will instead be parsed as a Literal: - id2 {Namespace=System} Microsoft.VisualStudio.GraphModel.GraphNodeId - LiteralValue \"Namespace=System\" string - Name {Literal} Microsoft.VisualStudio.GraphModel.GraphNodeIdName - Value \"Namespace=System\" object {string} This is simply so that the parsing rules are simple, predictable, and as fast as possible. Any GraphNodeID that is malformed will also be parsed as: \u201cName=Literal, Value=whatever\u201d","title":"Parsing &amp; standard form"},{"location":"posts/GraphModel/#nesting","text":"The following shows how GraphNodeId can be nested to full identify not only a method, but all the fully qualified types of all the parameters. The method we will describe is the following from mscorlib: System.IEquatable<T>.Equals(System.IEquatable<T> other); First we create some basic partial identifiers that can be reused: GraphNodeId mscorlib = GraphNodeId.GetPartial(CodeNames.AssemblyName, new Uri(typeof(string).Assembly.Location)); GraphNodeId system = GraphNodeId.GetPartial(CodeNames.NamespaceName, \"System\"); GraphNodeId iequatable = GraphNodeId.GetPartial(CodeNames.NameName, \"IEquatable\"); GraphNodeId equals = GraphNodeId.GetPartial(CodeNames.NameName, \"Equals\"); Next we build a nested identifier representing the generic type IEquatable<T> , which is represented by combining a GenericParameterCountName of 1 with the name \u201cIEquatable\u201d. The fact that the generic parameter is called T does not need to be remembered here: GraphNodeId iequatableGeneric = GraphNodeId.GetNested(new GraphNodeId[] {iequatable, GraphNodeId.GetPartial(CodeNames.GenericParameterCountName, 1) }); Now we can say TypeName=IEquatable<T> like this: GraphNodeId typeName = GraphNodeId.GetPartial(CodeNames.TypeName, iequatableGeneric); Now we can describe the method parameters using this nested name: GraphNodeId methodParameters = GraphNodeId.GetPartial(CodeNames.OverloadingParametersName, new GraphNodeIdCollection(true, GraphNodeId.GetNested(new GraphNodeId[] { mscorlib, system, typeName }))); Now we can describe the \u201cEquals\u201d method and it\u2019s parameters using this: GraphNodeId method = GraphNodeId.GetPartial(CodeNames.MemberName, GraphNodeId.GetNested(new GraphNodeId[] { equals, methodParameters })); Now we can fully type the method by adding assembly, namespace and type GraphNodeId result = GraphNodeId.GetNested(new GraphNodeId[] { mscorlib, system, typeName, method }); This results in the following serialized identifier: (Assembly=\"file://c:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll\" Namespace=System Type=(Name=IEquatable GenericParameterCount=1) Member=(Name=Equals OverloadingParameters=[(Assembly = \"file://c:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll\" Namespace = System Type = (Name = IEquatable GenericParameterCount = 1))]))} Notice how in the construction of the GraphNodeId that many sub-parts can be shared across many GraphNodeIds and this is how it can achieve performance and memory wins.","title":"Nesting"},{"location":"posts/GraphModel/#core-model","text":"The core graph model begins with the container called Graph. You can simply create a new empty Graph object as follows: Graph graph = new Graph(); This object can also be serialized to and from disk using the Load/Save methods (See Serialization for details): Graph graph = Graph.Load(dgmlFile); A graph can contain Nodes and Links which you can add using the Nodes and Links collections: GraphNode a = graph.Nodes.GetOrCreate(\"a\"); GraphNode b = graph.Nodes.GetOrCreate(\"b\"); GraphLink link = graph.Links.GetOrCreate(a, b); This could be visualized as the following: The Graph model is fully editable, you can insert or delete any node or link, and all expected ripple effects are taken care of. For example, when you add a Link, both end point nodes are added automatically if they are not there. If you Remove a node, all Links connected to that node are removed automatically. In this way the Graph is always left in a valid state after any editing operation. Graph nodes and links cannot belong to multiple Graph objects at the same time. If you add a node to a different Graph than it was created in, then that will become an \u201cimport\u201d operation and a new GraphNode instance will be created. To that end there are many helper methods dealing with copying subsets of a Graph to and from other Graph objects. See Copy, ImportSubset and Merge methods. For improved performance you should always wrap edit operations in a GraphTransactionScope . This will be covered in more detail below.","title":"Core Model"},{"location":"posts/GraphModel/#categories-properties","text":"The root Graph , GraphNode and GraphLink can all contain properties and categories. There is a common base class called GraphObject . GraphObject has a collection of Properties and Categories. For example, the following node has the category \u201cVegetable\u201d and the \u201cBackground\u201d property with the value \u201cGreen\u201d: <Node Id=\"A\" Label=\"Tree\" Category=\"Vegetable\" Background=\"Green\"/> And the following node has the category \u201cElement\u201d and a \u201cFontStyle\u201d property with value \u201cItalic\u201d: <Node Id=\"B\" Label=\"Water\" Category=\"Element\" FontStyle=\"Italic\"/> The following link has the category \u201cDrinks\u201d with a \u201cWeight\u201d property with the value \u201c5\u201d. <Link Source=\"A\" Target=\"B\" Category=\"Drinks\" Weight=\"5\" /> In code you get and set properties using the GetValue/SetValue/ClearValue methods, and you get or set categories using HasCategory and AddCategory, and RemoveCategory. Properties and Categories can be used for all sorts of things. The GraphModel itself has some special built in properties and categories used to describe some things like grouping. GraphCategory and GraphProperty can also contain extra metadata describing what they are about. You could think of a GraphCategory as a property that has no value. But categories have one other feature, namely, GraphObject can inherit properties defined on the GraphCategory and categories can inherit properties from other categories via a BasedOn property. This allows you to setup loose taxonomies using this metadata system. For example, we can promote the Backgound and FontStyle properties to the GraphCategory and thereby every node that has the Category=\u201dVegetable\u201d will be italic and every node with the Category=\u201dElement\u201d will be blue. <Category Id=\"Element\" Background=\"Blue\" /> <Category Id=\"Plant\" FontStyle=\"Italic\" /> Now anything with the category Plant will have a tree icon, including anything that has the category Tree, since the Tree category is \u201cBasedOn\u201d the Plant category. <?xml version=\"1.0\" encoding=\"utf-8\"?> <DirectedGraph GraphDirection=\"LeftToRight\" xmlns=\"http://schemas.microsoft.com/vs/2009/dgml\"> <Nodes> <Node Id=\"A\" Category=\"Tree\" Label=\"Tree\" /> <Node Id=\"B\" Category=\"Element\" Label=\"Water\" /> </Nodes> <Links> <Link Source=\"A\" Target=\"B\" /> </Links> <Categories> <Category Id=\"Element\" Background=\"#FF0000FF\" /> <Category Id=\"Plant\" FontStyle=\"Italic\" /> <Category Id=\"Tree\" Icon=\"Tree.png\" BasedOn=\"Plant\" Shape=\"None\" /> </Categories> <Properties> <Property Id=\"Background\" Label=\"Background\" Description=\"The background color\" DataType=\"System.Windows.Media.Brush\" /> <Property Id=\"GraphDirection\" DataType=\"Microsoft.VisualStudio.Diagrams.Layout.LayoutOrientation\" /> <Property Id=\"Icon\" Label=\"Icon\" Description=\"Icon\" DataType=\"System.String\" /> <Property Id=\"Shape\" DataType=\"System.String\" /> <Property Id=\"FontStyle\" DataType=\"System.Windows.FontStyle\" /> </Properties> </DirectedGraph> Which could be visualized like this: Notice also that properties can have labels, datatypes and descriptions. A \u201cHasCategory\u201d method is provided which will return true if the given category is found on the GraphObject or in anyway in the BasedOn chain. To define your own properties and categories see Schemas.","title":"Categories &amp; Properties"},{"location":"posts/GraphModel/#grouping","text":"A Graph can model the concept of grouping by using GraphLink to establish \u201cContains\u201d relationships between two nodes and a \u201cGroup\u201d property on the container node, like this: <Nodes> <Node Id=\"Child\" /> <Node Id=\"Group\" Group=\"Expanded\" /> </Nodes> <Links> <Link Source=\"Group\" Target=\"Child\" Category=\"Contains\" /> </Links> This describes a Graph that could be visualized like this: Nested containments can be described the same way and the Graph model provides helper methods for finding ancestors and descendants along these \u201cContains\u201d link relationships. The GraphModel also allows any number of links between nodes, so you could model multiple containment relationships and create a Graph that could be visualized like this: Note : Visual Studio does not support visualizing multi-containment. The Graph Model even allows a child to contain a parent and a parent to contain a child. This is called circular containment. This can be tricky to program, so the Graph Model provides helper methods for searching for ancestors and descendants without getting stuck in infinite loops caused by circularity. The Graph Model also provides a helper class called GraphGroup which wraps each GraphNode that has a Group property and exposes additional properties like ChildNodes and ChildGroups and Parents to make it even easier to deal with groups. But it is important to note that GraphGroup is a helper class and just a wrapper object on GraphNode. These objects are not constructed unless you ask for them and can come and go as the inner GraphNode is edited. For additional convenience you can also set properties and categories on the GraphGroup object and that will be passed down to the inner GraphNode object. So the GraphGroup always reflects the same categories and properties as the node that it wraps. The Graph object then also provides the following helper methods for dealing with groups: - AllGroups \u2013 returns a list of all GraphGroup objects - Groups \u2013 returns a list of top level groups - VisibleTopLevelGroups \u2013 returns a list of visible top level groups - FindCommonAncestor - return the common ancestor of all the given nodes - FindGroup \u2013 return the GraphGroup wrapper for a node that has a Group property - GetGroupDescendants \u2013 provides a way to walk the group hierarchy.","title":"Grouping"},{"location":"posts/GraphModel/#multilinks","text":"The Graph model can also support multiple links between the same two nodes: These are known as multigraphs and are useful in modeling state machines where multiple different transitions can take you from one state to another. GraphLinks are distinguished from each other by providing a unique \u201cIndex\u201d property on each one using the following API: public GraphLink GetOrCreate(string sourceId, string targetId, int index) public GraphLink GetOrCreate(GraphNodeId sourceId, GraphNodeId targetId, int index) The index property that becomes part of the unique identifier of this link, so the unique identifier of a link is the source node id + target node id + index. So the index only needs to be unique between the same two nodes. If you specify an index that already exists then you will not be creating a new link, instead you will get back the existing link, which is the normal semantics for all Graph Model \u201cGetOrCreate\u201d methods. You can find the link with specific index using the following new overloads: public GraphLink Get(string sourceId, string targetId, int index) public GraphLink Get(GraphNodeId sourceId, GraphNodeId targetId, int index) And you can find out what index a given link has using the following property on GraphLink: ```csharp public int Index { get; } This returns an optional Index of this link. Default is zero. This index can be specified when you create a link, providing different index values makes it possible to create multiple links between the same source and target nodes. The following graph is using multilinks where the \u201cReferences\u201d link has Index=1 and the \"Calls\" links has default index 0: ![](MultilinkDemo1.png) And if you copy & paste that into the following graph, where this link has been manually edited to have Index=3: ![](MultilinkDemo2.png) Then the link indexes will be preserved via serialization and you will get the following combined graph: ![](MultilinkDemo3.png) The idea is that the \"Index\" belongs to the end user, if they specify it, then they want it preserved. The GraphModel does not do any automatic re-writing of link indexes. ### Searching Graphs The following helper method makes navigating Graphs easier. ```csharp public IEnumerable<GraphNode> FindRelatedNodes(GraphSearchDirection searchDirection, Predicate<GraphLink> traverseLink, Predicate<GraphNode> traverseNode, Predicate<GraphNode> acceptNode) This method finds the dgml nodes that match the acceptNode predicate and are related in a way that matches the traverseLink and traverseNode predicates. Nodes are found by doing a breadth first search along links matching the traverseLink predicate, in the Source or Target direction designated by the searchDirection parameter. If the node matches the traverseNode predicate it keeps searching recursively through that node in the same direction and returns all nodes that match the acceptNode predicate. The search can handle circularity in the graph. The following example searches through all nodes reachable via all links from the start node and returns all nodes that have the Method category: node.FindRelatedNodes(GraphSearchDirection.Target, l => true, n => true, n => HasCategory(MethodCategory);","title":"MultiLinks"},{"location":"posts/GraphModel/#eventing-change-tracking","text":"All changes to the graph model can be tracked using the following change events on the Graph object: public event EventHandler<GraphUpdatedEventArgs> Updated; public event EventHandler<GraphUpdatedEventArgs> Updating; The Updating method happens while a transaction is being committed so you can see the old property values before they are changed. The Updated event happens after a successful Commit happens and the GraphUpdatedEventArgs contains all the changes that happened within that transaction. You can listen to these events by doing the following: Graph g = new Graph(); g.Updated += OnGraphUpdated; It is highly recommended that you use GraphTransactionScope when you change multiple objects in the Graph like this: using (var scope = g.BeginUpdate(Guid.NewGuid(), \"Add stuff\", UndoOption.Add)) { GraphNode foo = g.Nodes.GetOrCreate(\"foo\"); GraphNode bar = g.Nodes.GetOrCreate(\"bar\"); GraphLink calls = g.Links.GetOrCreate(foo.Id, bar.Id, 0); GraphLink references = g.Links.GetOrCreate(foo.Id, bar.Id, 1); scope.Complete(); } Notice the important scope.Complete() call at the end of this block. See the section on Transactions below. When the transaction scope is completed, all these edits are rolled up into one batch operation so your OnGraphUpdated method will be given a GraphUpdatedEventArgs that contains the added nodes and added links: static void OnGraphUpdated(object sender, GraphUpdatedEventArgs e) { var nodes = e.AddedNodes; var links = e.AddedLinks; } This style of batching up updates results in much more efficient processing in an application because UI objects can respond to graph changes in batch updates, rather than being evented to death with too many fine grained singleton events. This style of batching also makes it trivial to implement Undo/Redo. Note : there is an important rule that you must obey in your OnGraphUpdated events. You must not create another GraphTransactionScope inside that event handler on the same Graph object. If you do attempt to do this you will get an invalid operation exception. If you really want fine grained events, you can also listen to the lower level PropertyChanged and CategoryChanged events on GraphObject. This is useful for UI Data Binding scenarios.","title":"Eventing (Change Tracking)"},{"location":"posts/GraphModel/#undoredo-support","text":"The following classes can be used to build an Undo/Redo stack for graph operations using the change tracking events GraphUndoUnit GraphUndoManager UndoableGraphTransactionScope UndoOptions","title":"Undo/Redo Support"},{"location":"posts/GraphModel/#transactions","text":"As mentioned above in Eventing, it is highly recommended that you use GraphTransactionScope . In fact, if you don\u2019t use GraphTransactionScope then implicit scopes will be created for every individual edit, which can end up being a lot more expensive. GraphTransactionScopes support the following features: 1. If your code throws an exception before the scope.Complete call then all the changes inside that scope are rolled back, leaving the Graph in a consistent state. 2. Other threads are isolated from your changes until scope.Complete . This allows other threads to \u201cread\u201d the graph and see a consistent state until and your changes then appear atomically to them. ( Note : the Graph is not thread safe for Write operations. See Threading Model). 3. GraphTransactionScope supports nesting. For example your could call a method and that method creates another GraphTransactionScope and completes it before returning back to you. In this case the inner transaction is not really completed until the outer most GraphTransactionScope is completed. Similarly, if the inner scope is aborted, it is not aborted until the outer GraphTransactionScope is completed. Note: abort can be tricky, because an inner scope can cause all the outer scopes to be aborted. This can be a source of bugs. See Trouble Shooting.","title":"Transactions"},{"location":"posts/GraphModel/#threading-model","text":"The Graph object model is thread safe for \u201cread\u201d but not for \u201cwrite\u201d, there can only be one writer at a time. The GraphTransactionScopes provide thread isolated storage, so each reader sees a consistent view of the Graph model until each transaction is committed or rolled back. During commit however, the readers are not isolated while the changes stored in isolated storage are being merged back into the real storage. GraphNodeId, GraphCategory and GraphProperty are thread-safe for read and write.","title":"Threading Model"},{"location":"posts/GraphModel/#graph-metadata","text":"The metadata associated with properties and categories is not stored directly in the GraphProperty or GraphCategory. Instead the metadata is stored in the Graph. In this way different instances of Graph could have different metadata associated with the same category or property. Conversly two Graphs could share the same metadata and reduce the overhead of copying all that redundant information. For example, one Graph might want the Background color of anything with the Plant category to be Green, while another Graph might want the Background color of anything with the same category to be Brown. This is possible, because the \u201cmetadata is local to the Graph\u201d and it is not statically shared. To enable this, the construction of GraphMetadata properties is done lazily via a \u201cFactory Pattern\u201d, where you provide the factory for the metdata when you register your property or category as follows: GraphCategory Vegetable = Schema.Categories.AddNewCategory(\"Vegetable\", () => { GraphMetadata meta = new GraphMetadata(GraphMetadataOptions.Default); meta.SetValue(Background, Brushes.Green); return meta; }); One other advantage of this lazy metadata model is that this metadata is only created when someone actually asks for it. The GraphMetadataOptions provide the following additional semantics associated with your property or category: Immutable - The property cannot be changed once set. Removable - The property can be removed after it is set. Otherwise it can only be changed, and not removed. Browsable - The property is visible in the UI (such as in tool tips and the property grid Serializable - The property will be serialized to DGML when the graph is serialized. Substitutable - File path values will be replaced with aliases during serialization. Sharable - The property will be transferred along with the GraphObject when the GraphObject is being copied to another graph. Sometimes it is useful to have private properties for you app state only that are not shared across copy/paste operations. Undoable - The property might not be serializble, but it needs to be saved on the undo stack and made undoable. Serializable is automatically also undoable, but you might also want properties that are not serializable but are undoable. The default set of metadata options is Serializable | Removable | Browsable | Sharable .","title":"Graph Metadata"},{"location":"posts/GraphModel/#schemas","text":"Typically applications will want to define a set of related properties and categories, give that set a name and be able to reference the set that way. This is called a GraphSchema . A Graph can contain multiple different GraphSchemas. Typically GraphSchemas are defined statically and hooked into the common schema so they are discoverable from anywhere in the process, this ensures that properties are typed the same way throughout the process which is important. The following shows an example schema that defines a Background property of type Brush and a Vegetable category that has a default typed value of Green for the Background property. using Microsoft.VisualStudio.GraphModel.Schemas; public static class MySchema { static GraphSchema Schema; public static GraphCategory Vegetable; public static GraphProperty Background; static MySchema() { Schema = new GraphSchema(\"MySchema\"); GraphCommonSchema.Schema.AddSchema(Schema); Background = Schema.Properties.AddNewProperty(\"Background\", typeof(Brush)); Vegetable = Schema.Categories.AddNewCategory(\"Vegetable\", () => { GraphMetadata meta = new GraphMetadata( \"Vegetable\", \"This is a description of the category\", \"Living Things\", GraphMetadataOptions.Default); meta.SetValue(Background, Brushes.Green); return meta; }); } } You can then use your category like this: Graph g = new Graph(); g.Nodes.GetOrCreate(\"foo\", null, MySchema.Vegetable); g.Save(@\"d:\\temp\\graph.dgml\"); And the result will be serialized to the following DGML: <?xml version=\"1.0\" encoding=\"utf-8\"?> <DirectedGraph xmlns=\"http://schemas.microsoft.com/vs/2009/dgml\"> <Nodes> <Node Id=\"foo\" Category=\"Vegetable\" /> </Nodes> <Links /> <Categories> <Category Id=\"Vegetable\" Background=\"#FF008000\" /> </Categories> <Properties> <Property Id=\"Background\" DataType=\"System.Windows.Media.Brush\" /> </Properties> </DirectedGraph> You can also fetch the metadata using the GetMetadata method on GraphProperty and GraphCategory : Graph g = new Graph(); var node = g.Nodes.GetOrCreate(\"foo\", null, MySchema.Vegetable); GraphCategory c = node.Categories.First(); GraphMetadata m = c.GetMetadata(g); Console.WriteLine(m.Description); This prints the message This is a description of the category . Notice that to get the metadata for a given category or property you need to provide the owing Graph object. GraphMetadata belongs to a graph instance, it is not static. This makes it easier to compose Graph objects in a large product like Visual Studio without without having to force every plugin to use a fixed common schema.","title":"Schemas"},{"location":"posts/GraphModel/#default-schema","text":"The following default schema is provided with every Graph by default. It defines categories and properties that are used by the Graph Model API itself and are common enough to be shared by all Graph instances. public static class GraphCommonSchema { public static GraphSchema Schema { get; } public static GraphProperty Visibility { get; } public static GraphProperty UniqueId { get; } public static GraphProperty TargetNode { get; } public static GraphProperty SourceNode { get; } public static GraphProperty Label { get; } public static GraphProperty IsTag { get; } public static GraphProperty IsPseudo { get; } public static GraphProperty IsContainment { get; } public static GraphProperty Group { get; } public static GraphProperty ValueLabel { get; } public static GraphCategory Contains { get; } public static GraphProperty GroupLabel { get; } public static GraphProperty Value { get; } public static GraphProperty TargetType { get; } public static GraphProperty Property { get; } public static GraphProperty Expression { get; } public static GraphProperty IsEnabled { get; } public static GraphProperty IsCursorContainingMethod { get; } public static GraphProperty IsDragSource { get; } public static GraphProperty DelayedCrossGroupLinksState { get; } public static GraphProperty DelayedChildNodesState { get; } public static GraphProperty BaseUri { get; } public static GraphProperty ToolTip { get; } public static GraphProperty Version { get; } }","title":"Default Schema"},{"location":"posts/GraphModel/#styles","text":"The GraphModel provides a way to define GraphProperty values in a \u201cconditional\u201d way based on conditional expressions stored in Conditional Styles. While the name \u201cStyle\u201d has user interface connotations, this is not the only reason to use styles. You could also think of Styles as a system for generating \u201cComputed Property Values\u201d. You\u2019ll see the following classes in the Microsoft.VisualStudio.GraphModel.Styles namespace: Conditional styles look similar to WPF styles, but the expressions can be more powerful. The following is a conditional style serialized as DGML. <Style TargetType=\"Node\" GroupLabel=\"Class\" ValueLabel=\"Has category\"> <Condition Expression=\"HasCategory('Class')\" /> <Setter Property=\"Background\" Value=\"#D3DCEF\" /> <Setter Property=\"Icon\" Value=\"CodeSchema_Class\" /> </Style> This style defines a Background and Icon property value for all nodes that have the \u201cClass\u201d category. The side effect of having this style associated with the Graph object is that any time you call GetValue on a node that also has any category based on the \u201cClass\u201d category, you will get back the Background property value defined above. GraphNode foo = g.Nodes.GetOrCreate(\"foo\", null, MySchema.Class); Brush brush = foo.GetValue<Brush>(MySchema.Background); This example is the same as storing the Background property on the GraphCategory metadata, however the conditional style expression can be a lot richer. For example, the following expression will cause the style to be applied only if the class is public and has more than 10 outgoing links. <Condition Expression=\"IsPublic and OutgoingLinkCount > 10\" /> The property setters can also provide expressions instead of fixed values, so that you can have computed values. The following example shows how you can combine these ideas to produce interesting results: <Style TargetType=\"Node\" GroupLabel=\"Coverage\" ValueLabel=\"Good\"> <Condition Expression=\"Coverage &gt; 80\" /> <Setter Property=\"Background\" Value=\"Green\" /> </Style> <Style TargetType=\"Node\" GroupLabel=\"Coverage\" ValueLabel=\"Ok\"> <Condition Expression=\"Coverage &gt; 50\" /> <Setter Property=\"Background\" Expression=\"Color.FromRgb(180 * Math.Max(1, (80 - Coverage) / 30), 180, 0)\" /> </Style> <Style TargetType=\"Node\" GroupLabel=\"Coverage\" ValueLabel=\"Bad\"> <Setter Property=\"Background\" Expression=\"Color.FromRgb(180, 180 * Coverage / 50, 0)\" /> </Style> This set of styles breaks the nodes into groups. The first group has \u201cCoverage\u201d property > 80, the next has Coverage > 50, and the last one has all the others. Then a Background color property is computed based on the Coverage property values so that the result is a gradation of colors between green and red that illustrate the amount of Coverage that each node has: This shows that Styles are applied in a given order (they order in which they are added to the ConditionalStyleCollection ), and the style that matches first owns the properties it is setting. In other words, the following Styles that also match, will only be able to affect different properties on the nodes. Another way to say it is that the properties affected by matching styles are mututally exlusive. Styles can have a TargetType of Node, Link or Group.","title":"Styles"},{"location":"posts/GraphModel/#style-compilation-evaluation","text":"Styles will not automatically be applied to your Graph unless you Compile the style set using the Compile method on the GraphConditionalStyleCollection .","title":"Style Compilation &amp; Evaluation"},{"location":"posts/GraphModel/#style-eventing","text":"Your application may want to receive PropertyChange events on nodes and links whenever the style is changed, or the property values on which they are conditionally evaluated change. For example, in the above example if I change the \u201cCoverage\u201d property from 50 to 80, then I expect the \u201cBackground\u201d property value to change in the user interface. But how does this work? A Graph \u201cUpdated\u201d event will not be fired automatically in this case and the GraphNode PropertyChange event will not be fired automatically when you set the Coverage property. Once you Compile your GraphConditionalStyleCollection , it will then start tracking changes to properties in the Graph and it will remember if it sees any property change that has a conditional expression or setter expression that references that property. Then at the time you want your user interface updated you must call the RaisePendingPropertyChangeEvents passing in the nodes you want updated. You might limit it to just the visible nodes in your user interface for example. This will then raise OnPropertyChange events for all the affected style setters, in this case the \u201cBackground\u201d properties change events are raised and it raises it only on graph objects that match the conditional expressions. See Data Binding for more information.","title":"Style Eventing"},{"location":"posts/GraphModel/#psuedo-nodes-and-links","text":"Sometimes it is handy to generate fake nodes and links in your Graph object that you do not want serialized back to disk. In this case you can add the IsPseudo property to them and when you save the Graph they will disappear: GraphNode fake = g.Nodes.GetOrCreate(\"fake\"); fake.IsPseudo = true;","title":"Psuedo Nodes and Links"},{"location":"posts/GraphModel/#serialization","text":"The Graph model can serialize itself to and from the DGML XML format. The easiest way to serialize a graph is using the Load and Save methods: Graph graph = Graph.Load(dgmlFile); graph.Save(@\"d:\\temp\\graph.dgml\"); That is pretty much all you will ever need to know. There is a GraphSerializationSettings class that allows you to control sorting and do some error handling. You can also use it to re-write the GraphNodeIds during serialization which can be handy way to transform names.","title":"Serialization"},{"location":"posts/GraphModel/#graphdataobject","text":"Related to the topic of serialization is the GraphDataObject helper class which implements the WPF IDataObject interface and provides a way to exchange graph objects in copy/paste and/or drag/drop operations. In order to make this possible the Graph object itself is also ISerializable . It\u2019s implementation just uses it\u2019s built in DGML serialization abilities. When you create a GraphDataObject you can decide which clipboard formats you want it to publish using this method: public static IDataObject Create(IEnumerable<GraphNode> selection, Guid sourceGraphId, int levels, DataFormat[] formats) Or you can use the other method and get the default set AllDgmlFormats which include DGML, XML, Text and UnicodeText. The Text format is DGML, so some applications like to publish only DGML and XML and switch the Text format to something more readable. The GraphDataObject also provides helper methods for efficiently sniffing the clipboard to see if it contains something like valid DGML: public static bool IsClipboardDgml() and public static bool IsDgml(string markup)","title":"GraphDataObject"},{"location":"posts/GraphModel/#merging-dragdrop","text":"If you bring subsets of a Graph across in multiple drag/drop operations, you will probably want the \u201clinks\u201d to hook up. For example, suppose you have this graph: Now suppose you grab the \u201cFoo\u201d node and drag it or copy/paste it to a new graph. You will want this: Now go back to the original graph and bring over the comment. You will probably expect to see this: For this to work the GraphDataObject needs to contain more than just the selected nodes. Usually, you call GraphDataObject.Create with the selection, and pass the \u201clevels\u201d parameter value 1 so that it includes all nodes 1 link away from the selection. Then on the drop/paste side you want to \u201cMerge\u201d that GraphDataObject into your target Graph object, and delete the extra information that was not needed. For example, in the first drop operation you do not want the comment or the link. In the second drop operation you do want the link but you don\u2019t need Foo because you already have it, so you want it merged. To enable all this, the GraphDataObject.Create method does the following: 1. It marks the selected nodes with an GraphCommonSchema.IsDragSource property. 2. It marks all nodes that are not in the selection with : SetValue(GraphCommonSchema.Visibility, System.Windows.Visibility.Hidden) Then on the Merge side you can: 1. Make sure not to override Visibility on the target nodes 2. Do not create nodes or links if the dropped node is hidden and the target nodes didn\u2019t already exist 3. Select all nodes with IsDragSource property, then remove this temporary property. In this way you can get the above semantics in your application.","title":"Merging Drag/Drop"},{"location":"posts/GraphModel/#advanced-serialization","text":"You are welcome to read about advanced compression techniques below, but few people will need to know about this because the Graph Load and Save methods hide all this gory detail from you. If you look at a serialized DGML file, however, you may notice some of these things and wonder how they work.","title":"Advanced Serialization"},{"location":"posts/GraphModel/#file-path-substitution","text":"You might have many repetitions of a long file path in your node ids or in property values. For example, a graph of mscorlib could contain thousands of copies of the string file:///C:/Windows/Microsoft.NET/Framework/v4.0.30319/mscorlib.dll . In this case it is possible to tell the Graph to give this path a name, let\u2019s call it \u201cFxUri\u201d and then everywhere this path is found it can write out the variable substitution instead which is much shorter: $(FxUri)/mscorlib.dll These path names are defined in the GraphPathSerializationDictionary which is available from the CommonPaths property on the Graph object. This property is static so you can define the common paths before you call Graph.Load. This makes it possible to also map these common paths to different locations on your machine, which can help to make DGML documents more \u201cportable\u201d. The Graph serializer sets up a bunch of common paths by default, basically all the Environment.GetSpecialFolders plus .NET frameworks, reference assemblies and your current directory. Your application can listen to the CommonPathsAdded event on the GraphPathSerializationDictionary to add any more paths that are not predefined that way.","title":"File Path Substitution"},{"location":"posts/GraphModel/#graphnodeid-aliasing","text":"GraphNodeIds can also contain many redundant sub-parts, as shown in the top section on GraphNodeId. Serializing all this back out can result in lots of redundant text. So the Graph serializer creates integer values for each unique GraphNodeId called \u201caliases\u201d and uses those instead of the long serialized text. Then it writes the aliases to disk in a special section of the DGML file as follows: <IdentifierAliases> <Alias n=\"1\" Uri=\"Assembly=$(fxUri)/mscorlib.dll\" /> <Alias n=\"2\" Id=\"Namespace=System\" /> <Alias n=\"3\" Id=\"(@1 @2)\" /> <Alias n=\"4\" Id=\"(@1 @2 Type=String)\" /> <Alias n=\"6\" Id=\"(@1 @2 Type= String Member=Join)\" /> </IdentifierAliases> Then the ids in the nodes and links can be very small like this: <Link Source=\"@3\" Target=\"@4\" Category=\"Contains\" /> <Link Source=\"@3\" Target=\"@5\" Category=\"Contains\" /> <Link Source=\"@4\" Target=\"@6\" Category=\"Contains\" /> <Link Source=\"@4\" Target=\"@7\" Category=\"IndirectlyContains\" /> <Link Source=\"@6\" Target=\"@7\" Category=\"Contains\"> Notice that the aliases can use the path substition as well. Note: you will never see path variables or aliases in memory after you do Graph.Load.","title":"GraphNodeId aliasing"},{"location":"posts/GraphModel/#linq-extensions","text":"GraphEnumerable provides the following extension methods: - AsNodes \u2013 this method makes it easier to deal with heterogeneous collections of GraphNode and GraphGroup by unwrapping the GraphGroup objects, returning only GraphNodes. - GetGroups \u2013 this method returns only GraphGroup objects stripping out any objects that are not groups. - GetDescendants \u2013 this method returns all descendants of the given graph objects, independent of whether those objects are GraphNodes or GraphGroups.","title":"Linq Extensions"},{"location":"posts/GraphModel/#data-binding","text":"In order to support dynamic languages and WPF data binding the GraphObject implements the following interfaces: IDynamicMetaObjectProvider INotifyPropertyChanged GraphNodeIdPropertyDescriptor The dynamic meta object provides BindGetMember and BindSetMember as a way to set properties on the graph. This makes it possible to interact with GraphProperties using dynamics like this: dynamic node = g.Nodes.GetOrCreate(\"Foo\"); node.Color = Colors.Red; This combined with INotifyPropertyChanged allows WPF to you to bind to the properties stored in a GraphObject to a visual element and WPF will know how to watch for property change events on those properties. The GraphNodeIdPropertyDescriptor is a specialized class that makes it possible to present a GraphNodeId in a property window in a structured way like this:","title":"Data Binding"},{"location":"posts/GraphModel/#graph-providers","text":"Some interfaces are defined for those who want to create a plugin model that provides Graph subsets to other parts of the application. This is used in Visual Studio - it is how languages extend Solution Explorer with type information. Graph generators like to share common concepts in the form of graph schemas containing common GraphNodeIdNames, GraphCategories and GraphProperites. These shared classes are described in GraphProvider.docx spec.","title":"Graph Providers"},{"location":"posts/GraphModel/#data-virtualization","text":"Sometimes you might want a graph that represents only a portion of what is available in a data base. In this case it is handy to remember which groups are fully populated and which are not. The following GraphProperties helps with this: DelayedChildNodesState DelayedCrossGroupLinksState IsDelayedCrossGroupLink DelayedDataState No actual support for Data Virtualization is provided beyond just this convention for annotating where you are doing Data Virtualization in your Graph objects. This could help for example, in creating visuals that know how to represent this concept in a user interface, independent of the implementation behind it.","title":"Data Virtualization"},{"location":"posts/GraphModel/#trouble-shooting","text":"One common source of bugs is when someone forgets to include a scope.Complete() at the end of their GraphTransactionScope using block. This will cause the transaction to roll back, along with any outer GraphTransactionScopes, and it will look like the graph edits didn\u2019t work, when in reality, they are being rolled back.","title":"Trouble Shooting"},{"location":"posts/airsim_is_live/","text":"AirSim is \u201clive\u201d ! So if you love flying quadrocopters, as I do, then you\u2019ll probably also love flying them in a simulator. I recently worked on a cool new Simulator with a colleague in Microsoft Research and it was a blast. The Unreal Game engine is astounding, I love what it can do with rendering reflections, grass blowing in the wind, shadows created by leaves on the trees that also move as the wind blows. Amazing stuff. We built the AirSim simulator because we needed a research platform where we could safely test out reinforcement learning algorithms for vision based control of the drone. Well, obviously we don\u2019t want to have to crash a real drone while it is \u2018learning\u2019, but the problem with existing simulators is they didn\u2019t look real enough. So we built a new drone simulator using Unreal engine and it works great!","title":"AirSim is 'live'!!"},{"location":"posts/airsim_is_live/#airsim-is-live","text":"So if you love flying quadrocopters, as I do, then you\u2019ll probably also love flying them in a simulator. I recently worked on a cool new Simulator with a colleague in Microsoft Research and it was a blast. The Unreal Game engine is astounding, I love what it can do with rendering reflections, grass blowing in the wind, shadows created by leaves on the trees that also move as the wind blows. Amazing stuff. We built the AirSim simulator because we needed a research platform where we could safely test out reinforcement learning algorithms for vision based control of the drone. Well, obviously we don\u2019t want to have to crash a real drone while it is \u2018learning\u2019, but the problem with existing simulators is they didn\u2019t look real enough. So we built a new drone simulator using Unreal engine and it works great!","title":"AirSim is \"live\" !"},{"location":"posts/apple_upsell/","text":"Apple iCloud - please stop bugging me! Anyone else tired of these annoying popups? I\u2019m getting pretty tired of all this\u2026 I actually tried to find customer support for the PC installer popup, but no luck. Anyone know who owns this ugly little Windows app? I find it particularly devious that Apple uses language here that sounds like something is broken until I \u201cInstall\u201d their fix. This is not a fix, this is an upsell to get iCloud on my PC. The iPhone backup message is also annoying. I tried to tell my iPhone to stop backing up my photos, and yet I still get this backup failed warning every day. Perhaps Apple should find a more creative way to upsell my on iCloud because this is driving me nuts, and making it much less likely I\u2019ll ever checkout the benefits of paying Apple for cloud storage on stuff I\u2019ve backed up my self lots of other ways. Apple is world class on user experiences of everything else, so why are they so bad at this experience? I\u2019m guessing the part of the company that expertly squeezes every dime out of consumers is not so connected to the user experience gods at Apple\u2026 Here\u2019s hoping I can wake up some of those gods to go slap the accountants on the wrist for this naughty behavior. -Chris.","title":"Apple iCloud - please stop bugging me!"},{"location":"posts/apple_upsell/#apple-icloud-please-stop-bugging-me","text":"Anyone else tired of these annoying popups? I\u2019m getting pretty tired of all this\u2026 I actually tried to find customer support for the PC installer popup, but no luck. Anyone know who owns this ugly little Windows app? I find it particularly devious that Apple uses language here that sounds like something is broken until I \u201cInstall\u201d their fix. This is not a fix, this is an upsell to get iCloud on my PC. The iPhone backup message is also annoying. I tried to tell my iPhone to stop backing up my photos, and yet I still get this backup failed warning every day. Perhaps Apple should find a more creative way to upsell my on iCloud because this is driving me nuts, and making it much less likely I\u2019ll ever checkout the benefits of paying Apple for cloud storage on stuff I\u2019ve backed up my self lots of other ways. Apple is world class on user experiences of everything else, so why are they so bad at this experience? I\u2019m guessing the part of the company that expertly squeezes every dime out of consumers is not so connected to the user experience gods at Apple\u2026 Here\u2019s hoping I can wake up some of those gods to go slap the accountants on the wrist for this naughty behavior. -Chris.","title":"Apple iCloud - please stop bugging me!"},{"location":"posts/dgml_power_tools/","text":"DGML Power Tools for Visual Studio 2017 If you struggle with complex code dependencies then you might like my DGML Power Tools for Visual Studio 2017 . This addin makes it easy to slice and dice your DGML diagrams and share them with others via SVG. See my Demo Video . Save as SVG You will see the \u201cSave as SVG\u201d command in the Share menu on the Directed Graph Document toolbar. Neighborhood mode On the Directed Graph Document toolbar this command allows you to filter the graph to show only a specified number of degrees of freedom away from the selected node. If you move the selected node, click the button again to \u201crecenter\u201d the neighborhood on the new selection. To turn off neighborhood select the \u201cOff\u201d command inside the drop down menu next to the icon on the toolbar. Neighborhood mode can help when you have messy graphs like this one: In this case if you only care about one degree of freedom from the selected node then neighborhood mode will give you this nice clean subset: Butterfly mode On the Directed Graph Document toolbar this command removes cycles in the graph so that you see only the tree if incoming and outgoing dependencies around the selected node. This works nicely together with neighborhood mode. To recompute the butterfly simply click the toolbar button again after moving the selection. If you add butterfly mode to the above neighborhood example you get this even cleaner graph: Notice the difference between the two graphs is that butterfly mode removed the cycles so you can see a clean picture of incoming and outgoing dependencies relative to the selected node. Butterly also ensures that the arrows flow in the same direction which makes seeing the dependencies a lot easier. Just note that in removing cycles there may be some missing circular dependencies which you won\u2019t discover until you move the center of the butterfly. Windows Drag/Drop Simply drag images from Windows Explorer onto the canvas so you can wire them up with links and groups and quickly create some really nice looking diagrams. In fact you can drag any file on to the canvas to get a node with a Reference attribute pointing at that file (which is then handy for \u201cGoto->Reference\u201d command). Graph Diff You will see the graph compare command in the Directed Graph Document context menu: This command compares your current graph with another and then loads the result in a new window showing what was added or removed: DGML Filter View A new tool window that allows you to provide auto-grouping information. If you take the .NET Assemblies.dgml graph for example, and add the following grouping information in the DGML Filter View then click the \u201cApply Groups\u201d button in the toolbar you will see a nice grouped view of the data. Note : use the number pad +/- keys to re-order the list (use TAB key to make sure list has the keyboard focus). The following is the result when you apply this grouping information (see AutoGrouped.dgml ). Enjoy!!","title":"DGML Power Tools for Visual Studio 2017"},{"location":"posts/dgml_power_tools/#dgml-power-tools-for-visual-studio-2017","text":"If you struggle with complex code dependencies then you might like my DGML Power Tools for Visual Studio 2017 . This addin makes it easy to slice and dice your DGML diagrams and share them with others via SVG. See my Demo Video .","title":"DGML Power Tools for Visual Studio 2017"},{"location":"posts/dgml_power_tools/#save-as-svg","text":"You will see the \u201cSave as SVG\u201d command in the Share menu on the Directed Graph Document toolbar.","title":"Save as SVG"},{"location":"posts/dgml_power_tools/#neighborhood-mode","text":"On the Directed Graph Document toolbar this command allows you to filter the graph to show only a specified number of degrees of freedom away from the selected node. If you move the selected node, click the button again to \u201crecenter\u201d the neighborhood on the new selection. To turn off neighborhood select the \u201cOff\u201d command inside the drop down menu next to the icon on the toolbar. Neighborhood mode can help when you have messy graphs like this one: In this case if you only care about one degree of freedom from the selected node then neighborhood mode will give you this nice clean subset:","title":"Neighborhood mode"},{"location":"posts/dgml_power_tools/#butterfly-mode","text":"On the Directed Graph Document toolbar this command removes cycles in the graph so that you see only the tree if incoming and outgoing dependencies around the selected node. This works nicely together with neighborhood mode. To recompute the butterfly simply click the toolbar button again after moving the selection. If you add butterfly mode to the above neighborhood example you get this even cleaner graph: Notice the difference between the two graphs is that butterfly mode removed the cycles so you can see a clean picture of incoming and outgoing dependencies relative to the selected node. Butterly also ensures that the arrows flow in the same direction which makes seeing the dependencies a lot easier. Just note that in removing cycles there may be some missing circular dependencies which you won\u2019t discover until you move the center of the butterfly.","title":"Butterfly mode"},{"location":"posts/dgml_power_tools/#windows-dragdrop","text":"Simply drag images from Windows Explorer onto the canvas so you can wire them up with links and groups and quickly create some really nice looking diagrams. In fact you can drag any file on to the canvas to get a node with a Reference attribute pointing at that file (which is then handy for \u201cGoto->Reference\u201d command).","title":"Windows Drag/Drop"},{"location":"posts/dgml_power_tools/#graph-diff","text":"You will see the graph compare command in the Directed Graph Document context menu: This command compares your current graph with another and then loads the result in a new window showing what was added or removed:","title":"Graph Diff"},{"location":"posts/dgml_power_tools/#dgml-filter-view","text":"A new tool window that allows you to provide auto-grouping information. If you take the .NET Assemblies.dgml graph for example, and add the following grouping information in the DGML Filter View then click the \u201cApply Groups\u201d button in the toolbar you will see a nice grouped view of the data. Note : use the number pad +/- keys to re-order the list (use TAB key to make sure list has the keyboard focus). The following is the result when you apply this grouping information (see AutoGrouped.dgml ). Enjoy!!","title":"DGML Filter View"},{"location":"posts/dgmlimage/","text":"DgmlImage I\u2019m happy to announce the availability of a new command line tool for generating images from DGML graphs, called DgmlImage . While Visual Studio provides excellent support for viewing and editing DGML graphs, it is sometimes necessary to provide DGML graphs over the Web in HTML pages as static images so that the value of DGML visualizations can be shared with the entire world. An excellent example of this is the Reference Conflicts Analyzer by J\u00f3zsef Kanczler. In this example, you have a build server that runs code analysis tools, those tools provide insights as DGML diagrams, and so then it is natural to want to visualize those results on a website for anyone to see \u2013 even folks who don\u2019t have Visual Studio handy. DgmlImage is a standalone command line tool that can run on any Windows machine (including those without Visual Studio). The only pre-requisite is .NET Frameworks version 4.6.1. Install To install this tool use \u201cnuget install DgmlImage\u201d like this: d:\\Temp>nuget install DgmlImage Feeds used: https://api.nuget.org/v3/index.json C:\\Program Files (x86)\\Microsoft SDKs\\NuGetPackages\\ Installing package 'DgmlImage' to 'd:\\Temp'. CACHE https://api.nuget.org/v3/registration5-gz-semver2/dgmlimage/index.json Attempting to gather dependency information for package 'DgmlImage.1.2.0.1' with respect to project 'd:\\Temp', targeting 'Any,Version=v0.0' Gathering dependency information took 26.21 ms Attempting to resolve dependencies for package 'DgmlImage.1.2.0.1' with DependencyBehavior 'Lowest' Resolving dependency information took 0 ms Resolving actions to install package 'DgmlImage.1.2.0.1' Resolved actions to install package 'DgmlImage.1.2.0.1' Retrieving package 'DgmlImage 1.2.0.1' from 'nuget.org'. Adding package 'DgmlImage.1.2.0.1' to folder 'd:\\Temp' Added package 'DgmlImage.1.2.0.1' to folder 'd:\\Temp' Successfully installed 'DgmlImage 1.2.0.1' to d:\\Temp Executing nuget actions took 256.55 ms Notice this has created a folder named DgmlImage.1.2.0.1 in your current directory and in that folder you will find the tool in the tools folder. To make it easy to run this command the command line you can edit your PATH environment accordingly: set PATH=%PATH%;d:\\Temp\\DgmlImage.1.2.0.1\\tools An example command line might look like this: DgmlImage test.dgml This will produce a file in the same directory as the DGML document called \u201ctest.png\u201d. You can provide other file formats by providing the -format option. One interesting image format for Web pages is the SVG format: DgmlImage -format svg test.dgml Now you should see a test.svg file. With SVG there is a fun trick you can do to make the diagram automatically scale to fit the web browser window. Open the .svg file in notepad and look for the width and height properties. You will find something like this: <svg width=\"2031.10719130029\" height=\"1662.5614805394789\" Then modify this using a viewbox as follows: <svg viewbox=\"0,0,2031,1662\" width=\"100%\" Now the diagram nicely stretches and shrinks as you resize the browser window. You will need to copy the <svg> element into an .html page to see this nice resizing behavior. When you do that, drop the XML declaration: <?xml version=\"1.0\" encoding=\"utf-8\"?> Usage: Type \u201cDgmlImage -?\u201d to see this help page: Usage: DgmlImage /format:png /zoom:level files... Converts given DGML documents to given image format Options: /format:name, supported formats are 'png', 'bmp', 'gif', 'tiff', 'jpg', 'xps', 'svg' (default png) /f:name, short hand for /format:name /zoom:level, default zoom is 1. /z:level, short hand for /zoom:level /width:n, width of the image (defaults to 100% of graph size) /legend, show the legend (default hidden) /out:directory, the directory in which to write the image files","title":"DgmlImage"},{"location":"posts/dgmlimage/#dgmlimage","text":"I\u2019m happy to announce the availability of a new command line tool for generating images from DGML graphs, called DgmlImage . While Visual Studio provides excellent support for viewing and editing DGML graphs, it is sometimes necessary to provide DGML graphs over the Web in HTML pages as static images so that the value of DGML visualizations can be shared with the entire world. An excellent example of this is the Reference Conflicts Analyzer by J\u00f3zsef Kanczler. In this example, you have a build server that runs code analysis tools, those tools provide insights as DGML diagrams, and so then it is natural to want to visualize those results on a website for anyone to see \u2013 even folks who don\u2019t have Visual Studio handy. DgmlImage is a standalone command line tool that can run on any Windows machine (including those without Visual Studio). The only pre-requisite is .NET Frameworks version 4.6.1.","title":"DgmlImage"},{"location":"posts/dgmlimage/#install","text":"To install this tool use \u201cnuget install DgmlImage\u201d like this: d:\\Temp>nuget install DgmlImage Feeds used: https://api.nuget.org/v3/index.json C:\\Program Files (x86)\\Microsoft SDKs\\NuGetPackages\\ Installing package 'DgmlImage' to 'd:\\Temp'. CACHE https://api.nuget.org/v3/registration5-gz-semver2/dgmlimage/index.json Attempting to gather dependency information for package 'DgmlImage.1.2.0.1' with respect to project 'd:\\Temp', targeting 'Any,Version=v0.0' Gathering dependency information took 26.21 ms Attempting to resolve dependencies for package 'DgmlImage.1.2.0.1' with DependencyBehavior 'Lowest' Resolving dependency information took 0 ms Resolving actions to install package 'DgmlImage.1.2.0.1' Resolved actions to install package 'DgmlImage.1.2.0.1' Retrieving package 'DgmlImage 1.2.0.1' from 'nuget.org'. Adding package 'DgmlImage.1.2.0.1' to folder 'd:\\Temp' Added package 'DgmlImage.1.2.0.1' to folder 'd:\\Temp' Successfully installed 'DgmlImage 1.2.0.1' to d:\\Temp Executing nuget actions took 256.55 ms Notice this has created a folder named DgmlImage.1.2.0.1 in your current directory and in that folder you will find the tool in the tools folder. To make it easy to run this command the command line you can edit your PATH environment accordingly: set PATH=%PATH%;d:\\Temp\\DgmlImage.1.2.0.1\\tools","title":"Install"},{"location":"posts/dgmlimage/#an-example","text":"command line might look like this: DgmlImage test.dgml This will produce a file in the same directory as the DGML document called \u201ctest.png\u201d. You can provide other file formats by providing the -format option. One interesting image format for Web pages is the SVG format: DgmlImage -format svg test.dgml Now you should see a test.svg file. With SVG there is a fun trick you can do to make the diagram automatically scale to fit the web browser window. Open the .svg file in notepad and look for the width and height properties. You will find something like this: <svg width=\"2031.10719130029\" height=\"1662.5614805394789\" Then modify this using a viewbox as follows: <svg viewbox=\"0,0,2031,1662\" width=\"100%\" Now the diagram nicely stretches and shrinks as you resize the browser window. You will need to copy the <svg> element into an .html page to see this nice resizing behavior. When you do that, drop the XML declaration: <?xml version=\"1.0\" encoding=\"utf-8\"?>","title":"An example"},{"location":"posts/dgmlimage/#usage","text":"Type \u201cDgmlImage -?\u201d to see this help page: Usage: DgmlImage /format:png /zoom:level files... Converts given DGML documents to given image format Options: /format:name, supported formats are 'png', 'bmp', 'gif', 'tiff', 'jpg', 'xps', 'svg' (default png) /f:name, short hand for /format:name /zoom:level, default zoom is 1. /z:level, short hand for /zoom:level /width:n, width of the image (defaults to 100% of graph size) /legend, show the legend (default hidden) /out:directory, the directory in which to write the image files","title":"Usage:"},{"location":"posts/efergy_power_monitor/","text":"Efergy Power Monitor Alex Kelly showed me this really cool project by Nathaniel Elijah where he used a software defined radio to decode the power data from an Efergy power monitor . So I had some fun adding an AllJoyn wrapper on that so that my Raspberry Pi can act as an Alljoyn sensor which I can then easily connect to using my PC where I can grab the data and have fun with it in C#.","title":"Efergy Power Monitor"},{"location":"posts/efergy_power_monitor/#efergy-power-monitor","text":"Alex Kelly showed me this really cool project by Nathaniel Elijah where he used a software defined radio to decode the power data from an Efergy power monitor . So I had some fun adding an AllJoyn wrapper on that so that my Raspberry Pi can act as an Alljoyn sensor which I can then easily connect to using my PC where I can grab the data and have fun with it in C#.","title":"Efergy Power Monitor"},{"location":"posts/first_event_planner/","text":"FIRST Event Planner Demo Video: mp4 (24mb) I received an email from a friend asking for help figuring out a fun math problem. He works for FIRST and the problem is figuring out how to match up over 400 teams in Washington State with 5 separate event locations, minimizing the driving distance for each of those teams. Each event was happening on the same day, and each team gets to compete at only one of these events. So I quickly cranked out a nice little Silverlight Application to do the job. And I hooked up to the BING Mapping API to calculate the actual driving distances from each team to each event location. Silverlight and BING worked beautifully together. So far so good, but now for the hard part. How do you calculate the optimal assignment of teams to events that results in minimal total driving distance? I hacked out a brute force solution that first assigned every team to their closest venue, but then there were additional constraints that got more interesting. Each event has a minimum and maximum capacity, so if an event was over populated, some teams had to move to the second or third closest venue. This wasn\u2019t too hard to code, but I quickly realized, the solution I was getting was not necessarily the best. For example, in the diagram below, let\u2019s say the maximum capacity for each event is 3 teams, which means team \u201ci\u201d needs drive all the way to \u201cC\u201d. Clearly this is silly. It is better to move \u201cc\u201d to \u201cB\u201d and \u201cf\u201d to \u201cC\u201d, making room for \u201ci\u201d to join \u201cA\u201d, like this: But this is a tricky \u201cripple\u201d effect that is hard to find programmatically without having to essentially search all combinations of teams to events, but then I quickly realized it would take about 100 years to execute that kind of exhaustive search on my machine because 400 factorial is a large number. So this is when I contacted Microsoft Research. Lev Nachmanson works there and is a good friend of mine and a powerful magician when it comes to mathematics. So I presented the problem to him, and he said he\u2019d think about it. In a short while I got an email back saying he had a solution. He explained it to me over the phone, I implemented it, and it worked, finding the solution in less than a second. I was very impressed, but I also a bit skeptical. I couldn\u2019t believe it could be so simple. I went to his office to get a better understanding of how it worked. This is how he explained it to me. The global task is to drive to the minimum the sum of the distances from teams to the events they are assigned to. To initialize a solution assign each team to their closest event, but then think of the remaining optimization problem as a type of traffic flow problem. We will be shifting the teams between the events, so we need to consider a graph for doing this. The edges of this graph are AB, AC, and BC. (It is called a complete graph.) For example, above we moved \u201cc\u201d along edge AB, \u201cf\u201d along BC and \u201ci\u201d along AC. To find a solution we need to consider all paths on the complete graph that don\u2019t repeat an edge. A path can be a cycle, like ABCA, but every edge in it should appear at most once. To run one iteration, take a path as described above, then take the first edge of the path and shift a team along it such that shifting it along this edge \u201cmakes the least damage\u201d. Here the total sum can even grow. Take the second edge and do the same, and do it for every edge of the path. When we are done with the path, look at the total sum. If we are lucky and it went down, we accept the move, otherwise, we discard it. When no path gives us a gain we are done! Then how many possible paths do we have? Well in this case with 3 events there is AB, AC, BA, BC, CA, CB, ABC, ACB, BAC, BCA, CBA, CAB plus all the cyclic versions of these: ABA, ACA, BAB, BCB, CAC, CBC, ABCA, ACBA, BACB, BCAB, CBAC, CABC, a total of 24. It is not a huge amount of paths. The last thing to do for running the algorithm fast is to know how efficiently to find a team which can be shifted along an edge with the minimal damage. The best data structure for this is a priority queue. The end result was that on my desktop machine I could use this algorithm to find the optimal solution in sub-second times, which is fantastic. Super thanks to Lev! I just love it when a nice elegant algorithm makes software work really well. As I like to say, \u201cthere\u2019s genius in simplicity\u201d.","title":"FIRST Event Planner"},{"location":"posts/first_event_planner/#first-event-planner","text":"Demo Video: mp4 (24mb) I received an email from a friend asking for help figuring out a fun math problem. He works for FIRST and the problem is figuring out how to match up over 400 teams in Washington State with 5 separate event locations, minimizing the driving distance for each of those teams. Each event was happening on the same day, and each team gets to compete at only one of these events. So I quickly cranked out a nice little Silverlight Application to do the job. And I hooked up to the BING Mapping API to calculate the actual driving distances from each team to each event location. Silverlight and BING worked beautifully together. So far so good, but now for the hard part. How do you calculate the optimal assignment of teams to events that results in minimal total driving distance? I hacked out a brute force solution that first assigned every team to their closest venue, but then there were additional constraints that got more interesting. Each event has a minimum and maximum capacity, so if an event was over populated, some teams had to move to the second or third closest venue. This wasn\u2019t too hard to code, but I quickly realized, the solution I was getting was not necessarily the best. For example, in the diagram below, let\u2019s say the maximum capacity for each event is 3 teams, which means team \u201ci\u201d needs drive all the way to \u201cC\u201d. Clearly this is silly. It is better to move \u201cc\u201d to \u201cB\u201d and \u201cf\u201d to \u201cC\u201d, making room for \u201ci\u201d to join \u201cA\u201d, like this: But this is a tricky \u201cripple\u201d effect that is hard to find programmatically without having to essentially search all combinations of teams to events, but then I quickly realized it would take about 100 years to execute that kind of exhaustive search on my machine because 400 factorial is a large number. So this is when I contacted Microsoft Research. Lev Nachmanson works there and is a good friend of mine and a powerful magician when it comes to mathematics. So I presented the problem to him, and he said he\u2019d think about it. In a short while I got an email back saying he had a solution. He explained it to me over the phone, I implemented it, and it worked, finding the solution in less than a second. I was very impressed, but I also a bit skeptical. I couldn\u2019t believe it could be so simple. I went to his office to get a better understanding of how it worked. This is how he explained it to me. The global task is to drive to the minimum the sum of the distances from teams to the events they are assigned to. To initialize a solution assign each team to their closest event, but then think of the remaining optimization problem as a type of traffic flow problem. We will be shifting the teams between the events, so we need to consider a graph for doing this. The edges of this graph are AB, AC, and BC. (It is called a complete graph.) For example, above we moved \u201cc\u201d along edge AB, \u201cf\u201d along BC and \u201ci\u201d along AC. To find a solution we need to consider all paths on the complete graph that don\u2019t repeat an edge. A path can be a cycle, like ABCA, but every edge in it should appear at most once. To run one iteration, take a path as described above, then take the first edge of the path and shift a team along it such that shifting it along this edge \u201cmakes the least damage\u201d. Here the total sum can even grow. Take the second edge and do the same, and do it for every edge of the path. When we are done with the path, look at the total sum. If we are lucky and it went down, we accept the move, otherwise, we discard it. When no path gives us a gain we are done! Then how many possible paths do we have? Well in this case with 3 events there is AB, AC, BA, BC, CA, CB, ABC, ACB, BAC, BCA, CBA, CAB plus all the cyclic versions of these: ABA, ACA, BAB, BCB, CAC, CBC, ABCA, ACBA, BACB, BCAB, CBAC, CABC, a total of 24. It is not a huge amount of paths. The last thing to do for running the algorithm fast is to know how efficiently to find a team which can be shifted along an edge with the minimal damage. The best data structure for this is a priority queue. The end result was that on my desktop machine I could use this algorithm to find the optimal solution in sub-second times, which is fantastic. Super thanks to Lev! I just love it when a nice elegant algorithm makes software work really well. As I like to say, \u201cthere\u2019s genius in simplicity\u201d.","title":"FIRST Event Planner"},{"location":"posts/flightsim/","text":"Microsoft Flight Simulator 2020 The new Microsoft Flight Simulator is nuts! Can you believe the screen shot below is simulated? I snapped this while flying over Woodinville in the simulator with max settings which I can do because I have a nice powerful desktop with NVidia 1080 GPU. So far I am super impressed that I can fly the entire planet. These guys have timed this perfectly what with all the covid-19 lockdowns and everything!","title":"Microsoft Flight Simulator 2020"},{"location":"posts/flightsim/#microsoft-flight-simulator-2020","text":"The new Microsoft Flight Simulator is nuts! Can you believe the screen shot below is simulated? I snapped this while flying over Woodinville in the simulator with max settings which I can do because I have a nice powerful desktop with NVidia 1080 GPU. So far I am super impressed that I can fly the entire planet. These guys have timed this perfectly what with all the covid-19 lockdowns and everything!","title":"Microsoft Flight Simulator 2020"},{"location":"posts/fun_with_ell/","text":"Having fun with ELL ELL is a new Open Source library from Microsoft Research. I\u2019m having lots of fun working on it and learning all about Convolutional Neural Networks. The first time you train one and try it out it definitely feels like magic. How can a bunch of numbers correctly classify the type of object in a photo? Granted we\u2019re talking millions of numbers, so it\u2019s not that magical, but it is still fun. Now, of course, I have to combine this with my love of DGML graphs . So in this post I will outline how I\u2019ve used ELL to execute neural networks trained on the MNist dataset. MNist is a classic benchmark for neural networks and it provides a dataset for \u201chand written digits\u201d. This dataset is small since each image is only 28\u00d728 pixels, which makes for a great \u201cfirst time developer experience\u201d with neural networks, since you don\u2019t have to wait for terabytes of images to be downloaded! For example, here\u2019s one of their test images which contains a hand written digit \u201c8\u201d: It turns out the Microsoft CNTK library is an excellent library for training Neural networks and there is a CNTK sample that can be used to train an MNist model. See install_mnist.py . After you run that you will have the MNist dataset and then you can run SimpleMNIST.py to train a CNTK model on that dataset. On my machine I get a file named mnist.cntk which is about 640kb. So the next thing I want to do is run this on a Raspberry Pi, so I used the ELL library to do that. If you follow the Getting Started tutorial you will see how easy it is to build ELL, import a model from CNTK and build a cross-compiled module that will run on the Raspberry Pi. So in my case I simply do this (after building the ELL repo): python d:\\git\\ell\\ell\\tools\\importers\\CNTK\\cntk_import.py mnist.cntk This gives me an \u201cmnist.ell\u201d model, so what is inside this model? You can use the ELL print tool with -dgml and get this picture: Of course, this is a very simple neural network. Try the DGML graph on some of the more complex deep neural networks. You can then compile this model using the ELL model compiler: python d:\\git\\ell\\ell\\tools\\wrap\\wrap.py mnist.ell --target pi3 This gives me a \u2018pi3\u2019 folder already setup with CMakeLists.txt for building on the pi. You can also copy Demo.py and DemoHelpers.py from ELL\\tools\\utilities\\pythonlibs to get a quick start in using this python module. Once on the pi do the using cmake build thing outlined in the ELL tutorials, and then we can test it out. To test it out we can run this python script: import cv2 import numpy as np import sys sys.path += [ \"d:/Temp/MNist/host\" ] sys.path += [ \"d:/Temp/MNist/host/build\" ] sys.path += [ \"d:/Temp/MNist/host/build/Release\" ] import mnist import requests r = requests.get(\"http://www.lovettsoftware.com/images/eight.jpg\") nparr = np.fromstring(r.content, np.uint8) image = cv2.imdecode(nparr, cv2.IMREAD_COLOR) plt.imshow(image) gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) output = mnist.predict(gray.ravel()) result = np.array(output) print(\"Prediction={}\".format(np.argmax(result))) which prints the correct output, namely \u201c8\u201d. If you want to get adventurous you can run the ELL model over all the tests images in the MNist test dataset using this python code: import sys import cv2 import numpy as np sys.path.append(\"host\") sys.path.append(\"host/build\") sys.path.append(\"host/build/Release\") import mnist input_shape = mnist.get_default_input_shape() input_size = input_shape.rows * input_shape.columns * input_shape.channels output_shape = MNist.get_default_output_shape() output_size = output_shape.rows * output_shape.columns * output_shape.channels nogui = False failed = 0 total = 0 args = sys.argv[1:] if len(args) == 1 and args[0] == \"nogui\": nogui = True def getLabel(labels): a = labels.split(' ') if a[0] == 'labels': for i in range(10): if a[i+1] == \"1\": return i return 0 def getImage(features): a = features.split(' ') data = [] if a[0] == 'features': for i in range(len(a) - 1): data.append(float(a[i+1])) return np.array(data).reshape((28,28)) def Test(index, line): global total, failed, output_buffer parts = line.split('|') passed = True if len(parts) == 3: labels = parts[1] features = parts[2] answer = getLabel(labels) image = getImage(features) if not nogui: cv2.imshow(\"test\", image) output = mnist.predict(image.ravel()) prediction = np.argmax(output) result = \"passed\" if prediction != answer: result = \"failed\" failed += 1 passed= False total += 1 print(\"%d: predicted %d, answer is %d, test %s\" % (index, prediction, answer, result)) return passed def WaitForKey(): key = cv2.waitKey(1) & 0xFF while key == 255: key = cv2.waitKey(1) & 0xFF return key def RunTest(filename): global total, failed index = 1 with open(filename) as f: for line in f.readlines(): line = line.strip() passed = Test(index, line) index += 1 if not nogui and not passed and WaitForKey() == 27: return print(\"\") print(\"Total tests %d, failed = %d, pass rate = %f\" % (total, failed, (total - failed) / total)) RunTest(\"Test-28x28_cntk_text.txt\") Then the output from this is: Total tests 10000, failed = 259, pass rate = 0.974100 Lots \u2018o fun!","title":"Fun with ELL"},{"location":"posts/fun_with_ell/#having-fun-with-ell","text":"ELL is a new Open Source library from Microsoft Research. I\u2019m having lots of fun working on it and learning all about Convolutional Neural Networks. The first time you train one and try it out it definitely feels like magic. How can a bunch of numbers correctly classify the type of object in a photo? Granted we\u2019re talking millions of numbers, so it\u2019s not that magical, but it is still fun. Now, of course, I have to combine this with my love of DGML graphs . So in this post I will outline how I\u2019ve used ELL to execute neural networks trained on the MNist dataset. MNist is a classic benchmark for neural networks and it provides a dataset for \u201chand written digits\u201d. This dataset is small since each image is only 28\u00d728 pixels, which makes for a great \u201cfirst time developer experience\u201d with neural networks, since you don\u2019t have to wait for terabytes of images to be downloaded! For example, here\u2019s one of their test images which contains a hand written digit \u201c8\u201d: It turns out the Microsoft CNTK library is an excellent library for training Neural networks and there is a CNTK sample that can be used to train an MNist model. See install_mnist.py . After you run that you will have the MNist dataset and then you can run SimpleMNIST.py to train a CNTK model on that dataset. On my machine I get a file named mnist.cntk which is about 640kb. So the next thing I want to do is run this on a Raspberry Pi, so I used the ELL library to do that. If you follow the Getting Started tutorial you will see how easy it is to build ELL, import a model from CNTK and build a cross-compiled module that will run on the Raspberry Pi. So in my case I simply do this (after building the ELL repo): python d:\\git\\ell\\ell\\tools\\importers\\CNTK\\cntk_import.py mnist.cntk This gives me an \u201cmnist.ell\u201d model, so what is inside this model? You can use the ELL print tool with -dgml and get this picture: Of course, this is a very simple neural network. Try the DGML graph on some of the more complex deep neural networks. You can then compile this model using the ELL model compiler: python d:\\git\\ell\\ell\\tools\\wrap\\wrap.py mnist.ell --target pi3 This gives me a \u2018pi3\u2019 folder already setup with CMakeLists.txt for building on the pi. You can also copy Demo.py and DemoHelpers.py from ELL\\tools\\utilities\\pythonlibs to get a quick start in using this python module. Once on the pi do the using cmake build thing outlined in the ELL tutorials, and then we can test it out. To test it out we can run this python script: import cv2 import numpy as np import sys sys.path += [ \"d:/Temp/MNist/host\" ] sys.path += [ \"d:/Temp/MNist/host/build\" ] sys.path += [ \"d:/Temp/MNist/host/build/Release\" ] import mnist import requests r = requests.get(\"http://www.lovettsoftware.com/images/eight.jpg\") nparr = np.fromstring(r.content, np.uint8) image = cv2.imdecode(nparr, cv2.IMREAD_COLOR) plt.imshow(image) gray = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY) output = mnist.predict(gray.ravel()) result = np.array(output) print(\"Prediction={}\".format(np.argmax(result))) which prints the correct output, namely \u201c8\u201d. If you want to get adventurous you can run the ELL model over all the tests images in the MNist test dataset using this python code: import sys import cv2 import numpy as np sys.path.append(\"host\") sys.path.append(\"host/build\") sys.path.append(\"host/build/Release\") import mnist input_shape = mnist.get_default_input_shape() input_size = input_shape.rows * input_shape.columns * input_shape.channels output_shape = MNist.get_default_output_shape() output_size = output_shape.rows * output_shape.columns * output_shape.channels nogui = False failed = 0 total = 0 args = sys.argv[1:] if len(args) == 1 and args[0] == \"nogui\": nogui = True def getLabel(labels): a = labels.split(' ') if a[0] == 'labels': for i in range(10): if a[i+1] == \"1\": return i return 0 def getImage(features): a = features.split(' ') data = [] if a[0] == 'features': for i in range(len(a) - 1): data.append(float(a[i+1])) return np.array(data).reshape((28,28)) def Test(index, line): global total, failed, output_buffer parts = line.split('|') passed = True if len(parts) == 3: labels = parts[1] features = parts[2] answer = getLabel(labels) image = getImage(features) if not nogui: cv2.imshow(\"test\", image) output = mnist.predict(image.ravel()) prediction = np.argmax(output) result = \"passed\" if prediction != answer: result = \"failed\" failed += 1 passed= False total += 1 print(\"%d: predicted %d, answer is %d, test %s\" % (index, prediction, answer, result)) return passed def WaitForKey(): key = cv2.waitKey(1) & 0xFF while key == 255: key = cv2.waitKey(1) & 0xFF return key def RunTest(filename): global total, failed index = 1 with open(filename) as f: for line in f.readlines(): line = line.strip() passed = Test(index, line) index += 1 if not nogui and not passed and WaitForKey() == 27: return print(\"\") print(\"Total tests %d, failed = %d, pass rate = %f\" % (total, failed, (total - failed) / total)) RunTest(\"Test-28x28_cntk_text.txt\") Then the output from this is: Total tests 10000, failed = 259, pass rate = 0.974100 Lots \u2018o fun!","title":"Having fun with ELL"},{"location":"posts/i_love_mylio/","text":"I love Mylio A good friend of mine named JP Duplessis joined a startup named Mylio and they built some really amazing photo management software. I\u2019ve been using it for over a year now and I have to say, I really like it. I was tired of the old Windows Photo Apps that are so, well, um, boring and feature limited and I was tired of my wife losing her MacBook and all her photos on it. You should have seen the moment when we set it up in my kitchen and I could finally sync photos off her MacBook onto my Windows PC for the first time. I thought I died and went to heaven !! I then added a bunch of photos from my son who is an avid photographer. He went on a hike in California (which is where he lives) and I would have never seen this photo, not in a million years of begging and pleading for photo backups. He works really hard in a startup and doesn\u2019t have time for facebook. But now, like magic using the Mylio Cloud Sync feature, it pops up on my machine and I can enjoy a whole series of amazing shots of this Tiger Swallowtail butterfly. So I\u2019m now using Mylio to sync over 90,000 photos across 9 machines (I have a PC, laptop, a PC at work, and a backup NAS drive, my wife has MacBook, iPad, and iPhone, and my son has Android phone and a MacBook running Windows). I hear some users have over 1 million photos and even more machines, and that makes me feel good about the scalability of this app. Nothing else came even close to \u201cmanaging\u201d this many photos, and Mylio is incredibly snappy. I can slice and dice and pivot through folders, albums, people, ratings, all to my heart\u2019s content and I\u2019m never waiting for a photo to load or for thumbnails to be generated. This snappiness is probably my favorite feature of the app. Who has time to wait for photos to load, like on all those \u201ccloud\u201d based photo sites? I don\u2019t. I\u2019ve also used the built in photo editing features, and I love that all edits are non-destructive (they are stored in a separate *.xmp file). So any user can go back and reset the edits and try again to get a better result and as the app improves, even existing edits can look better after a Mylio update. Of course, most of my photos are huge RAW files from a fancy Canon or Nikon camera and Mylio handles all those natively, no stupid OEM drivers necessary, which is fantastic. They must have done a ton of work to pull that off and I can \u201cshare\u201d these as smaller png files on Facebook with a single button click. So Mylio does everything I need with photos, in a fast, smooth and well-designed user interface.","title":"I love Mylio"},{"location":"posts/i_love_mylio/#i-love-mylio","text":"A good friend of mine named JP Duplessis joined a startup named Mylio and they built some really amazing photo management software. I\u2019ve been using it for over a year now and I have to say, I really like it. I was tired of the old Windows Photo Apps that are so, well, um, boring and feature limited and I was tired of my wife losing her MacBook and all her photos on it. You should have seen the moment when we set it up in my kitchen and I could finally sync photos off her MacBook onto my Windows PC for the first time. I thought I died and went to heaven !! I then added a bunch of photos from my son who is an avid photographer. He went on a hike in California (which is where he lives) and I would have never seen this photo, not in a million years of begging and pleading for photo backups. He works really hard in a startup and doesn\u2019t have time for facebook. But now, like magic using the Mylio Cloud Sync feature, it pops up on my machine and I can enjoy a whole series of amazing shots of this Tiger Swallowtail butterfly. So I\u2019m now using Mylio to sync over 90,000 photos across 9 machines (I have a PC, laptop, a PC at work, and a backup NAS drive, my wife has MacBook, iPad, and iPhone, and my son has Android phone and a MacBook running Windows). I hear some users have over 1 million photos and even more machines, and that makes me feel good about the scalability of this app. Nothing else came even close to \u201cmanaging\u201d this many photos, and Mylio is incredibly snappy. I can slice and dice and pivot through folders, albums, people, ratings, all to my heart\u2019s content and I\u2019m never waiting for a photo to load or for thumbnails to be generated. This snappiness is probably my favorite feature of the app. Who has time to wait for photos to load, like on all those \u201ccloud\u201d based photo sites? I don\u2019t. I\u2019ve also used the built in photo editing features, and I love that all edits are non-destructive (they are stored in a separate *.xmp file). So any user can go back and reset the edits and try again to get a better result and as the app improves, even existing edits can look better after a Mylio update. Of course, most of my photos are huge RAW files from a fancy Canon or Nikon camera and Mylio handles all those natively, no stupid OEM drivers necessary, which is fantastic. They must have done a ton of work to pull that off and I can \u201cshare\u201d these as smaller png files on Facebook with a single button click. So Mylio does everything I need with photos, in a fast, smooth and well-designed user interface.","title":"I love Mylio"},{"location":"posts/keyword_spotting/","text":"Fun with keyword spotting I\u2019ve had a lot of fun lately playing with Deep Neural Networks (DNNs), pytorch, RNN\u2019s and keyword spotting models. See my Channel 9 Video . This whole DNN thing is rather addictive. See my latest quick demo: This has turned into an official sample app for the Azure MXCHIP IOT DevKit which is a really fun little board that as a nice little ARM Cortex-M4f chip and a bunch of sensors including a nice microphone. You can run this puppy using only about 80 milliamps always listening for keywords. Doesn\u2019t have to be \u201cHey Siri\u201d or \u201cHey Google\u201d or \u201cHey Cortana\u201d, you could train your own model that listens to whatever you want. On my HP z840 dev box with NVidia 1080 I can train using pytorch in about 3 minutes, compile that using the ELL compiler in a second, and deploy that to the MXCHIP board using VS code in another few seconds and boom, I\u2019m up and running with an intelligent device! I\u2019m really liking pytorch these days, it has the flexibility you need to try all kinds of crazy things, and all the researchers seem to be adopting it, and that\u2019s important because the researchers are the ones coming up with all the good algorithms. So anyone can build an intelligent device, cross-platform apps to light it up, and cloud services on Azure that reach the entire planet. The opportunity here is enormous. I seriously think the opportunity for developers is larger than it has every been. Think about it, a guy starts ring.com because he was tired of his neighbor\u2019s dog pooping in his front yard, and a few years later Amazon buys it for $1 billion !! Granted, ring.com executed really well. But the number of intelligent devices and scenarios that can be imagined is limitless! Always listening scenarios\u2026 For example, there are so many things we can do with A.I. on audio streams: fun : simple interactive toys, \u201cSpot! roll over!\u201d safety : left the stove on, garage door is still open industrial : anomaly detection on machines (motor is dying) inclusive : help deaf people hear things that are going on around them neighborhood : dog is barking while I\u2019m at work relationships : my spouse is snoring too loud, here\u2019s the proof! health : detect the sound of sleep apnea, so people can get help It\u2019s so easy to do all this, let\u2019s just do it!!","title":"Keyword Spotting"},{"location":"posts/keyword_spotting/#fun-with-keyword-spotting","text":"I\u2019ve had a lot of fun lately playing with Deep Neural Networks (DNNs), pytorch, RNN\u2019s and keyword spotting models. See my Channel 9 Video . This whole DNN thing is rather addictive. See my latest quick demo: This has turned into an official sample app for the Azure MXCHIP IOT DevKit which is a really fun little board that as a nice little ARM Cortex-M4f chip and a bunch of sensors including a nice microphone. You can run this puppy using only about 80 milliamps always listening for keywords. Doesn\u2019t have to be \u201cHey Siri\u201d or \u201cHey Google\u201d or \u201cHey Cortana\u201d, you could train your own model that listens to whatever you want. On my HP z840 dev box with NVidia 1080 I can train using pytorch in about 3 minutes, compile that using the ELL compiler in a second, and deploy that to the MXCHIP board using VS code in another few seconds and boom, I\u2019m up and running with an intelligent device! I\u2019m really liking pytorch these days, it has the flexibility you need to try all kinds of crazy things, and all the researchers seem to be adopting it, and that\u2019s important because the researchers are the ones coming up with all the good algorithms. So anyone can build an intelligent device, cross-platform apps to light it up, and cloud services on Azure that reach the entire planet. The opportunity here is enormous. I seriously think the opportunity for developers is larger than it has every been. Think about it, a guy starts ring.com because he was tired of his neighbor\u2019s dog pooping in his front yard, and a few years later Amazon buys it for $1 billion !! Granted, ring.com executed really well. But the number of intelligent devices and scenarios that can be imagined is limitless!","title":"Fun with keyword spotting"},{"location":"posts/keyword_spotting/#always-listening-scenarios","text":"For example, there are so many things we can do with A.I. on audio streams: fun : simple interactive toys, \u201cSpot! roll over!\u201d safety : left the stove on, garage door is still open industrial : anomaly detection on machines (motor is dying) inclusive : help deaf people hear things that are going on around them neighborhood : dog is barking while I\u2019m at work relationships : my spouse is snoring too loud, here\u2019s the proof! health : detect the sound of sleep apnea, so people can get help It\u2019s so easy to do all this, let\u2019s just do it!!","title":"Always listening scenarios..."},{"location":"posts/magic_leds/","text":"Magic LED Lights Rock I had some fun over the Christmas holiday playing with my new toy, Magic LED Lights . These are controlled from your phone using Bluetooth Low Energy. But as is often the case there was no Windows Phone app for these, so hey, it was the holidays, I had some time, so I built one. Actually, I built a Windows app . It is implemented in C# and most of the code is shared between the two apps. So far the light bulb has worked perfectly! You can get more information from the manufacturer at www.ledmagical.com . Of course, this is just the beginning. Imagine the lights turn on when I walk into my office. Or the XBox controls the lights so they turn red when I get shot in Halo. There are many fun applications of this really simple but very cool new tool. See Demo Video of bluetooth lights and Demo Video of the wifi lights .","title":"Magic LED Lights Rock"},{"location":"posts/magic_leds/#magic-led-lights-rock","text":"I had some fun over the Christmas holiday playing with my new toy, Magic LED Lights . These are controlled from your phone using Bluetooth Low Energy. But as is often the case there was no Windows Phone app for these, so hey, it was the holidays, I had some time, so I built one. Actually, I built a Windows app . It is implemented in C# and most of the code is shared between the two apps. So far the light bulb has worked perfectly! You can get more information from the manufacturer at www.ledmagical.com . Of course, this is just the beginning. Imagine the lights turn on when I walk into my office. Or the XBox controls the lights so they turn red when I get shot in Halo. There are many fun applications of this really simple but very cool new tool. See Demo Video of bluetooth lights and Demo Video of the wifi lights .","title":"Magic LED Lights Rock"},{"location":"posts/model-based-ui-testing-using-dgml/","text":"Model Based UI Testing using DGML See demo video: (MP4 24mb) . Transcript : In this video I\u2019m going to explain how to use the DgmlTestMonitor that I published to the Visual Studio Gallery. I\u2019ve got a test project loaded here with some test methods and I have a DGML document. The Directed Graph Markup Language is supported by Visual Studio 2012 and it allows me to edit these diagrams. I created this diagram to model the user interface of an application that I\u2019m testing. Not only that, I have a way of executing this model and even setting breakpoints using the DgmlTestMonitor which you will find under View/Other Windows. Now I can come in here and set a breakpoint on this node. So whenever it gets into editing transactions and editing categories the model will stop executing. Alright, so let\u2019s run the test. Notice I don\u2019t actually have to debug the test to get these breakpoints. 1:00 : This is the application that I\u2019m testing, it\u2019s a simple financial management tool that allows me to create bank accounts and transactions and so forth, and right there it has edited a category and so the model has paused. So let\u2019s go back to the application and we see it sitting on that node and if we look at the DgmlTestMonitor output we can see everything that it has done up until that point. I can even select through here and watch what it did up until that point. 1:30 : If you put Visual Studio on another monitor you will be able to watch the model executing while it\u2019s actually testing the application. Now that\u2019s it\u2019s reached this point I\u2019m going to move the application to another monitor. Now we can watch the model executing. Maybe I want to stop it when it adds a transfer. I\u2019ll clear the previous breakpoint, tell it to resume, and off it goes. So the UI test is continuing, it\u2019s doing various different steps. Since I can watch the model executing I can get a feel for whether this is accurately modeling and end-user or not and I can edit the model, I can add links, I can add nodes and I can make the test do different things. 2:15 : Now in this case we hit a test bug because if we switch to the Test Explorer we see the test terminated when it was trying to set the date on a transaction. Now it turns out this is a product bug, sometimes setting the date is a little flakey. This is the kind of thing that model based testing is really good at, finding edge conditions that are really hard to find any other way, which is why I\u2019m a big fan of model based testing. I\u2019m not saying this is going to replace all static testing, but I think this is a very interesting thing to add to your suite of test tools. 2:45 : Alright, a lot of magic to explain here. How does this actually work? Let\u2019s take a look at the test code. The way you do this is with in normal MSTest [TestMethod] you create a new DgmlTestModel , you give it the filename of the DGML document that you want to load and then you tell the model to run until you\u2019re happy. I\u2019ve provided a Predicate that says run until 500 states have been executed. All right, now you pass in an object to the DgmlTestModel constructor which is the target object that implements the states - so the test model is connected to my code. If I double click this node it will take me to that method and this is the implementation of editing a category. Notice that there\u2019s lots of random number generation going on, some keystrokes to tab through various fields until it finds the category and so on. 3:43 : This framework doesn\u2019t change how you build test wrappers, you could use the CodedUI, I created these wrappers so I could automate, using System.Automation, the user interface of my application. What\u2019s new here is the way you can actually visually define the states that you want to travel through and the links that connect the states. So when I edit a category I can go over here or I can go down there and the test model execution decides randomly which of these paths to take that have multiple choices. 4:15 : When you create a group you can encapsulate the complexity of editing transactions and you can define an entrypoint, so a node that has the EntryPoint Category which you can define using the property window, you can add the entry points. You can also have entry points that are mutually exclusive, so if you choose this one, don\u2019t choose that one and so that has a category on it saying it is a singleton. You can define predicates on a link, so you can add link labels \u201cIsSecuritySelected\u201d we see that\u2019s just a implemented as a Boolean property. You can implement all kinds of state machinery in your Boolean properties which will then guide the test in the right way. For example, IsAccountSelected, or IsEditable and so forth. So all of these things can encode various state about what your application is doing to make sure your test model doesn\u2019t get stuck in a weird state and try to do something that\u2019s invalid. 5:16 : Now since it is random, you\u2019ll want to also be able to reproduce a failure and if you scroll to the bottom of the test output and you will see the \u201cModel Seed = 3122235\u201d. This number is the seed to the random number generator. If I plug this number in I will get the exactly the same test sequence that I got before. So basically you can create a static test by just copying down these seeds, which is a pretty low maintenance way of creating static regression tests. 5:43 : Ok, let\u2019s edit this model and see if we can make some changes here. So when we edit the payee we can go to SalesTax, or Deposit or Payment. Well maybe I always want to have salestax, so I just delete those links and maybe I want to have the memo field be optional, so instead of always going from EditCategory to EditMemo, I\u2019ll give it one more route from there to SelectTransaction and now I will only have EditMemo sometimes. That\u2019s it, that\u2019s all you have to do, save the document and re-run the test. Ok, we see it now adding a new transaction, that time it added a memo, this time it didn\u2019t, this time it did, and now it added a transfer and it stopped, so let\u2019s see what happened. 6:43 : Ah, that\u2019s because we have a breakpoint on AddTransfer, remember? So I can go to the DgmlTestMonitor and we can see that it hit a breakpoint on that node and I can tell it to resume running the test. You can also pause the test at any time, using the pause button, which is handy for a UI test because often interrupting a UI test is kind of tricky but when you tell the model to pause it\u2019s usually in a pretty good place. 7:18 : Alright, so, one more thing and that is you can modify the thickness of these links. If you go to the Property Window this link has a priority of 10 which means it\u2019s going to pick that link more often than this link with Priority 1. This way you can weight the model so that it\u2019s doing various things in a way that\u2019s similar to the way a real user would use your product. 7:40 : Lastly, when the model enters a group, like View Categories, notice there\u2019s no exit links from SelectCategory. Just to make it simple to create these models what happens when it hits a leaf node that has no exit, it will jump back up to the parent group and it will use any exit links that the parent has, and if the parent doesn\u2019t have any exit links then it will go back to the root and look for an entry point there, and re-entry the model at the root and keep executing from there. So that makes it easy, you don\u2019t have to specify all possible exit routes and it makes your model a little bit simpler. 8:18 : That\u2019s it! I hope you like it. I\u2019ve posted a blog on my website, and in there you\u2019ll see a readme that points to the source code that you can download so you can play with it, including sample code on how to wire it up and also documentation on this class, DgmlTestModel. You will find DgmlTestModel and also the NamedPipeReader that listens to the model while it\u2019s executing in case you want to build your own user interface. Thanks for watching!","title":"Model Based UI Testing using DGML"},{"location":"posts/model-based-ui-testing-using-dgml/#model-based-ui-testing-using-dgml","text":"See demo video: (MP4 24mb) . Transcript : In this video I\u2019m going to explain how to use the DgmlTestMonitor that I published to the Visual Studio Gallery. I\u2019ve got a test project loaded here with some test methods and I have a DGML document. The Directed Graph Markup Language is supported by Visual Studio 2012 and it allows me to edit these diagrams. I created this diagram to model the user interface of an application that I\u2019m testing. Not only that, I have a way of executing this model and even setting breakpoints using the DgmlTestMonitor which you will find under View/Other Windows. Now I can come in here and set a breakpoint on this node. So whenever it gets into editing transactions and editing categories the model will stop executing. Alright, so let\u2019s run the test. Notice I don\u2019t actually have to debug the test to get these breakpoints. 1:00 : This is the application that I\u2019m testing, it\u2019s a simple financial management tool that allows me to create bank accounts and transactions and so forth, and right there it has edited a category and so the model has paused. So let\u2019s go back to the application and we see it sitting on that node and if we look at the DgmlTestMonitor output we can see everything that it has done up until that point. I can even select through here and watch what it did up until that point. 1:30 : If you put Visual Studio on another monitor you will be able to watch the model executing while it\u2019s actually testing the application. Now that\u2019s it\u2019s reached this point I\u2019m going to move the application to another monitor. Now we can watch the model executing. Maybe I want to stop it when it adds a transfer. I\u2019ll clear the previous breakpoint, tell it to resume, and off it goes. So the UI test is continuing, it\u2019s doing various different steps. Since I can watch the model executing I can get a feel for whether this is accurately modeling and end-user or not and I can edit the model, I can add links, I can add nodes and I can make the test do different things. 2:15 : Now in this case we hit a test bug because if we switch to the Test Explorer we see the test terminated when it was trying to set the date on a transaction. Now it turns out this is a product bug, sometimes setting the date is a little flakey. This is the kind of thing that model based testing is really good at, finding edge conditions that are really hard to find any other way, which is why I\u2019m a big fan of model based testing. I\u2019m not saying this is going to replace all static testing, but I think this is a very interesting thing to add to your suite of test tools. 2:45 : Alright, a lot of magic to explain here. How does this actually work? Let\u2019s take a look at the test code. The way you do this is with in normal MSTest [TestMethod] you create a new DgmlTestModel , you give it the filename of the DGML document that you want to load and then you tell the model to run until you\u2019re happy. I\u2019ve provided a Predicate that says run until 500 states have been executed. All right, now you pass in an object to the DgmlTestModel constructor which is the target object that implements the states - so the test model is connected to my code. If I double click this node it will take me to that method and this is the implementation of editing a category. Notice that there\u2019s lots of random number generation going on, some keystrokes to tab through various fields until it finds the category and so on. 3:43 : This framework doesn\u2019t change how you build test wrappers, you could use the CodedUI, I created these wrappers so I could automate, using System.Automation, the user interface of my application. What\u2019s new here is the way you can actually visually define the states that you want to travel through and the links that connect the states. So when I edit a category I can go over here or I can go down there and the test model execution decides randomly which of these paths to take that have multiple choices. 4:15 : When you create a group you can encapsulate the complexity of editing transactions and you can define an entrypoint, so a node that has the EntryPoint Category which you can define using the property window, you can add the entry points. You can also have entry points that are mutually exclusive, so if you choose this one, don\u2019t choose that one and so that has a category on it saying it is a singleton. You can define predicates on a link, so you can add link labels \u201cIsSecuritySelected\u201d we see that\u2019s just a implemented as a Boolean property. You can implement all kinds of state machinery in your Boolean properties which will then guide the test in the right way. For example, IsAccountSelected, or IsEditable and so forth. So all of these things can encode various state about what your application is doing to make sure your test model doesn\u2019t get stuck in a weird state and try to do something that\u2019s invalid. 5:16 : Now since it is random, you\u2019ll want to also be able to reproduce a failure and if you scroll to the bottom of the test output and you will see the \u201cModel Seed = 3122235\u201d. This number is the seed to the random number generator. If I plug this number in I will get the exactly the same test sequence that I got before. So basically you can create a static test by just copying down these seeds, which is a pretty low maintenance way of creating static regression tests. 5:43 : Ok, let\u2019s edit this model and see if we can make some changes here. So when we edit the payee we can go to SalesTax, or Deposit or Payment. Well maybe I always want to have salestax, so I just delete those links and maybe I want to have the memo field be optional, so instead of always going from EditCategory to EditMemo, I\u2019ll give it one more route from there to SelectTransaction and now I will only have EditMemo sometimes. That\u2019s it, that\u2019s all you have to do, save the document and re-run the test. Ok, we see it now adding a new transaction, that time it added a memo, this time it didn\u2019t, this time it did, and now it added a transfer and it stopped, so let\u2019s see what happened. 6:43 : Ah, that\u2019s because we have a breakpoint on AddTransfer, remember? So I can go to the DgmlTestMonitor and we can see that it hit a breakpoint on that node and I can tell it to resume running the test. You can also pause the test at any time, using the pause button, which is handy for a UI test because often interrupting a UI test is kind of tricky but when you tell the model to pause it\u2019s usually in a pretty good place. 7:18 : Alright, so, one more thing and that is you can modify the thickness of these links. If you go to the Property Window this link has a priority of 10 which means it\u2019s going to pick that link more often than this link with Priority 1. This way you can weight the model so that it\u2019s doing various things in a way that\u2019s similar to the way a real user would use your product. 7:40 : Lastly, when the model enters a group, like View Categories, notice there\u2019s no exit links from SelectCategory. Just to make it simple to create these models what happens when it hits a leaf node that has no exit, it will jump back up to the parent group and it will use any exit links that the parent has, and if the parent doesn\u2019t have any exit links then it will go back to the root and look for an entry point there, and re-entry the model at the root and keep executing from there. So that makes it easy, you don\u2019t have to specify all possible exit routes and it makes your model a little bit simpler. 8:18 : That\u2019s it! I hope you like it. I\u2019ve posted a blog on my website, and in there you\u2019ll see a readme that points to the source code that you can download so you can play with it, including sample code on how to wire it up and also documentation on this class, DgmlTestModel. You will find DgmlTestModel and also the NamedPipeReader that listens to the model while it\u2019s executing in case you want to build your own user interface. Thanks for watching!","title":"Model Based UI Testing using DGML"},{"location":"posts/mymoney.net/","text":"MyMoney.Net is now open source\u2026 A good friend of mine, JP Duplessis and I have been tinkering away on an app for the last 10 years or more, it started out as a replacement for the then cancelled Microsoft Money app. We built it entirely in C#, it started out as WinForms, we ported it to WPF and XAML and then fixed bugs. We wanted to open source it but I finally got around to doing it today on GitHub. See https://github.com/clovett/MyMoney.net/wiki . The app is really designed for programmers who want to tinker and add stuff. JP added a whole module to help deal with rental properties. The data is stored in sqllite, so it is super easy to extend and add whatever you want. The surprising thing is how small financial data really is. For a family of 5 with data all the way back to 1997 (which I exported in QFX format from Microsoft Money and my wife\u2019s data from Quicken) the entire database is just over 6 megabytes. In today\u2019s hard drive world, this is miniscule. So MyMoney.Net loads up the entire database into memory, which means it is super snappy to pivot, slice and dice and jump around your accounts. You might wonder how long it takes to load, ooh, about 1.2 seconds ?? So anyway, I hope a few other people can enjoy the app, and contribute on GitHub. I look forward to many interesting pull requests. -Cheers, Chris.","title":"MyMoney.Net is now open source..."},{"location":"posts/mymoney.net/#mymoneynet-is-now-open-source","text":"A good friend of mine, JP Duplessis and I have been tinkering away on an app for the last 10 years or more, it started out as a replacement for the then cancelled Microsoft Money app. We built it entirely in C#, it started out as WinForms, we ported it to WPF and XAML and then fixed bugs. We wanted to open source it but I finally got around to doing it today on GitHub. See https://github.com/clovett/MyMoney.net/wiki . The app is really designed for programmers who want to tinker and add stuff. JP added a whole module to help deal with rental properties. The data is stored in sqllite, so it is super easy to extend and add whatever you want. The surprising thing is how small financial data really is. For a family of 5 with data all the way back to 1997 (which I exported in QFX format from Microsoft Money and my wife\u2019s data from Quicken) the entire database is just over 6 megabytes. In today\u2019s hard drive world, this is miniscule. So MyMoney.Net loads up the entire database into memory, which means it is super snappy to pivot, slice and dice and jump around your accounts. You might wonder how long it takes to load, ooh, about 1.2 seconds ?? So anyway, I hope a few other people can enjoy the app, and contribute on GitHub. I look forward to many interesting pull requests. -Cheers, Chris.","title":"MyMoney.Net is now open source..."},{"location":"posts/password_vault/","text":"PasswordVault See demo video (mp4 13mb) Password Vault is my latest little ClickOnce app, built on the .NET Framework 4.0. NEW: I\u2019ve also added a windows store app, see Secure Password Vault app and associated new demo video . Managing online accounts is a real hassle these days. I have 180 separate userids and passwords to manage. Who can remember all that? And it\u2019s not just userids and passwords any more, it\u2019s also secret questions, password images, secure credit card numbers, links to specific URLs, license keys, and all sorts of other miscellaneous information associated with my online accounts. The temptation of course is to get sloppy and use the same user id and password on every site and use real \u201csecret\u201d questions that I can remember but a wise person once said \u201cdon\u2019t put all your eggs in one basket\u201d. If a hacker breaks into one site I don\u2019t want them to be able to steal my entire identity across all my other accounts, so I\u2019ve diligently kept separate unique userids and passwords on every site and fake random unique secret questions. I also use strong passwords, combinations of digits, letters, and other special characters. But managing all this unique secure information for every account is a big hassle. Up till now I\u2019ve used a password encrypted Microsoft Word file. Being a free-form text editor Word lets me paste anything I want, including all those annoying \u201csecret questions\u201d, even password image keys that some sites are now using, like Bank of America. But I want these passwords to be readily available on every machine that I use. Since the Word document is itself password encrypted, I can store it on my OneDrive folder which is automatically copied to all my machines. But then if I edit the password file on one machine while it is offline then edit the file on another machine before it syncs then I have a conflict and will have to manually merge the two slightly different Word documents which is a real hassle. So I wanted something that is a bit more structured that can handle automatic merging for me, but also without losing the flexibility of free form text editing for all that other random information besides the core web site, userid and password fields. So I built Password Vault . The screen shot below shows a typical password file. Highlighted in various shades of green are the most recent changes. This green highlight fades over time, disappearing after one month. When you select a row the 5th field appears containing a full rich text editor where you can paste any other details like secret questions or even an image key. You can cut & paste anything you want into this field and and it can be as big as you want. This field is also searchable. When the program first starts the focus will be on the search field since you typically have some place in mind already before you launch the app. After you type in your search term (which is not case sensitive) the view will automatically filter down to show any matching rows: From there you can select the row you want and press F12 to open that URL, and then you can copy the user name and password into the web site login page. Implementation I realize there\u2019s a million similar apps out there, I just wanted to see how easy it would be to build one. The following is the solution I came up with. Design.dgml (276.06 kb) PasswordVault is about 1000 lines of code and shows the power of .NET Framework. It uses the .NET Cryptography api to encrypt/decrypt your password files using 256 bit encryption, and it uses WPF for the User Interface including a RichTextBox for the free form text editing part. PasswordVault also uses the Microsoft Credential Manager to safely store your master password so you don\u2019t have to keep entering the master password every time you open your password file.","title":"Secure Password Vault"},{"location":"posts/password_vault/#passwordvault","text":"See demo video (mp4 13mb) Password Vault is my latest little ClickOnce app, built on the .NET Framework 4.0. NEW: I\u2019ve also added a windows store app, see Secure Password Vault app and associated new demo video . Managing online accounts is a real hassle these days. I have 180 separate userids and passwords to manage. Who can remember all that? And it\u2019s not just userids and passwords any more, it\u2019s also secret questions, password images, secure credit card numbers, links to specific URLs, license keys, and all sorts of other miscellaneous information associated with my online accounts. The temptation of course is to get sloppy and use the same user id and password on every site and use real \u201csecret\u201d questions that I can remember but a wise person once said \u201cdon\u2019t put all your eggs in one basket\u201d. If a hacker breaks into one site I don\u2019t want them to be able to steal my entire identity across all my other accounts, so I\u2019ve diligently kept separate unique userids and passwords on every site and fake random unique secret questions. I also use strong passwords, combinations of digits, letters, and other special characters. But managing all this unique secure information for every account is a big hassle. Up till now I\u2019ve used a password encrypted Microsoft Word file. Being a free-form text editor Word lets me paste anything I want, including all those annoying \u201csecret questions\u201d, even password image keys that some sites are now using, like Bank of America. But I want these passwords to be readily available on every machine that I use. Since the Word document is itself password encrypted, I can store it on my OneDrive folder which is automatically copied to all my machines. But then if I edit the password file on one machine while it is offline then edit the file on another machine before it syncs then I have a conflict and will have to manually merge the two slightly different Word documents which is a real hassle. So I wanted something that is a bit more structured that can handle automatic merging for me, but also without losing the flexibility of free form text editing for all that other random information besides the core web site, userid and password fields. So I built Password Vault . The screen shot below shows a typical password file. Highlighted in various shades of green are the most recent changes. This green highlight fades over time, disappearing after one month. When you select a row the 5th field appears containing a full rich text editor where you can paste any other details like secret questions or even an image key. You can cut & paste anything you want into this field and and it can be as big as you want. This field is also searchable. When the program first starts the focus will be on the search field since you typically have some place in mind already before you launch the app. After you type in your search term (which is not case sensitive) the view will automatically filter down to show any matching rows: From there you can select the row you want and press F12 to open that URL, and then you can copy the user name and password into the web site login page.","title":"PasswordVault"},{"location":"posts/password_vault/#implementation","text":"I realize there\u2019s a million similar apps out there, I just wanted to see how easy it would be to build one. The following is the solution I came up with. Design.dgml (276.06 kb) PasswordVault is about 1000 lines of code and shows the power of .NET Framework. It uses the .NET Cryptography api to encrypt/decrypt your password files using 256 bit encryption, and it uses WPF for the User Interface including a RichTextBox for the free form text editing part. PasswordVault also uses the Microsoft Credential Manager to safely store your master password so you don\u2019t have to keep entering the master password every time you open your password file.","title":"Implementation"},{"location":"posts/px4_topics/","text":"Using DGML to understand PX4 As you may know I have a soft spot for Directed Graphs and I enjoy showing off what you can do with DGML diagrams and Visual Studio . I was recently struggling to debug a new problem that showed up in the PX4 Firmware with regards to Hardware in the loop (HITL) simulation and the AirSim simulator . Then I remembered I have this great tool\u2026 See demo video: Here\u2019s something fun for PX4 developers. If you look in the modules/uORB folder you\u2019ll see the pub/sub infrastructure called the \u201cmicro-orb\u201d which is used for pub/sub messaging throughout the PX4 firmware. But knowing where messages are coming from and where they are going to can end up being quite a maze to figure out. So if we search for every instance of ORB_ID in the PX4 source code using this command: grep -r . -e 'ORB_ID(' you\u2019ll see lots of different uses. You\u2019ll see orb_publish calls and you\u2019ll see orb_subscribe calls. So if we capture all this output of this grep in a text file orbids.txt then we can process that file with my graph_orbids.py python script. This script builds a graph of Nodes and Links which it can then save in a .dot or .dgml file format. For the orb_publish calls it will create a node representing the module that is publishing with a link to another node representing the orb topic. For the orb_subscribe calls it will create a node representing the module that is subscribing, with a link from another node representing the orb topic. When you run the tool it will output anything it didn\u2019t understand, so check that output to make sure it didn\u2019t miss anything important. Now you have a graph.dgml file which you can load up in Visual Studio. You will see a large complex graph of all the pub/sub stuff going on. You can use the Legend to make the topic nodes green. But the graph is pretty big an horrendous to look at which is kind of why its so hard to debug the PX4 until you fully understand this picture. But if you install my DgmlPowerTools extension for Visual Studio then you can slice and dice this graph a little more easily. For example, I was investigating a problem with actuator_outputs . So I can search for this topic, then select the Neighborhood Mode button in the toolbar to hide everything that is not 1 link away from this topic and you get this nice clean sub-graph: . This subgraph helped me fix the bug I was hunting. I found that version 1.7 of the PX4 firmware contains the pwm_out_sim module, but version 1.8 does not. Adding it back fixed my bug and HILT mode simulation works again in AirSim. From here it\u2019s fun to pivot around the graph recentering each subgraph on a new module or topic. For example, if you look a the commander 1 link away you see all the various topics the commander subscribes to, but you can see it is also publishing a bunch of stuff, like vehicle_status . You can recenter the graph on vehicle_status and see what it connects to: From there you can see position control module (mc_pos_control) uses this, and you can easily pivot to see that node\u2019s local neighborhood: The position controller subscribes to a bunch of things and produces one output which is used to move the drone. Following that output we find that the land_detector uses this message as follows: Who uses land_detected? Let\u2019s find out: Interesting eh? Here we see ekf2 which is the fancy new position estimator And you can see from this picture that it is doing something pretty complicated fusing together lots of inputs to figure out where the drone is headed next. One of the outputs is vehicle_attitude, which is an estimated attitude (or angle) of the drone. Let\u2019s see who uses that: Whoah, lots of people. So you can see this is a handy way to slice and dice a complex graph. In Visual Studio you can choose different layouts like \u2018left-to-right\u2019 and find what you like best. Anyway, I found this useful so I hope you do too.","title":"Using DGML to understand PX4"},{"location":"posts/px4_topics/#using-dgml-to-understand-px4","text":"As you may know I have a soft spot for Directed Graphs and I enjoy showing off what you can do with DGML diagrams and Visual Studio . I was recently struggling to debug a new problem that showed up in the PX4 Firmware with regards to Hardware in the loop (HITL) simulation and the AirSim simulator . Then I remembered I have this great tool\u2026 See demo video: Here\u2019s something fun for PX4 developers. If you look in the modules/uORB folder you\u2019ll see the pub/sub infrastructure called the \u201cmicro-orb\u201d which is used for pub/sub messaging throughout the PX4 firmware. But knowing where messages are coming from and where they are going to can end up being quite a maze to figure out. So if we search for every instance of ORB_ID in the PX4 source code using this command: grep -r . -e 'ORB_ID(' you\u2019ll see lots of different uses. You\u2019ll see orb_publish calls and you\u2019ll see orb_subscribe calls. So if we capture all this output of this grep in a text file orbids.txt then we can process that file with my graph_orbids.py python script. This script builds a graph of Nodes and Links which it can then save in a .dot or .dgml file format. For the orb_publish calls it will create a node representing the module that is publishing with a link to another node representing the orb topic. For the orb_subscribe calls it will create a node representing the module that is subscribing, with a link from another node representing the orb topic. When you run the tool it will output anything it didn\u2019t understand, so check that output to make sure it didn\u2019t miss anything important. Now you have a graph.dgml file which you can load up in Visual Studio. You will see a large complex graph of all the pub/sub stuff going on. You can use the Legend to make the topic nodes green. But the graph is pretty big an horrendous to look at which is kind of why its so hard to debug the PX4 until you fully understand this picture. But if you install my DgmlPowerTools extension for Visual Studio then you can slice and dice this graph a little more easily. For example, I was investigating a problem with actuator_outputs . So I can search for this topic, then select the Neighborhood Mode button in the toolbar to hide everything that is not 1 link away from this topic and you get this nice clean sub-graph: . This subgraph helped me fix the bug I was hunting. I found that version 1.7 of the PX4 firmware contains the pwm_out_sim module, but version 1.8 does not. Adding it back fixed my bug and HILT mode simulation works again in AirSim. From here it\u2019s fun to pivot around the graph recentering each subgraph on a new module or topic. For example, if you look a the commander 1 link away you see all the various topics the commander subscribes to, but you can see it is also publishing a bunch of stuff, like vehicle_status . You can recenter the graph on vehicle_status and see what it connects to: From there you can see position control module (mc_pos_control) uses this, and you can easily pivot to see that node\u2019s local neighborhood: The position controller subscribes to a bunch of things and produces one output which is used to move the drone. Following that output we find that the land_detector uses this message as follows: Who uses land_detected? Let\u2019s find out: Interesting eh? Here we see ekf2 which is the fancy new position estimator And you can see from this picture that it is doing something pretty complicated fusing together lots of inputs to figure out where the drone is headed next. One of the outputs is vehicle_attitude, which is an estimated attitude (or angle) of the drone. Let\u2019s see who uses that: Whoah, lots of people. So you can see this is a handy way to slice and dice a complex graph. In Visual Studio you can choose different layouts like \u2018left-to-right\u2019 and find what you like best. Anyway, I found this useful so I hope you do too.","title":"Using DGML to understand PX4"},{"location":"posts/remote_control_phone/","text":"Remote Control Phone Have you ever wanted to control your PC using your Windows Phone? Well it turns out to be surprisingly simple to do. I found some sample code on MSDN that plays tic-tac-toe and so I took that and made some simple changes. See mp4 Video (12mb) Download Source Code: RemoteControl.zip","title":"Remote Control Phone"},{"location":"posts/remote_control_phone/#remote-control-phone","text":"Have you ever wanted to control your PC using your Windows Phone? Well it turns out to be surprisingly simple to do. I found some sample code on MSDN that plays tic-tac-toe and so I took that and made some simple changes. See mp4 Video (12mb) Download Source Code: RemoteControl.zip","title":"Remote Control Phone"},{"location":"posts/seismograph/","text":"Seismograph App I built a simple app called Seismograph to visualize the accelerometer data on my phone. The reason I built this is because I wanted a simple way to check the vibration of the motors on my quadrocopter . I saw some really nice apps for android, but all the windows phone accelerometer apps were crap. So I built my own :-) I then ported this Seismograph for Windows RT so I could also run it on my Surface device. When I did that port I discovered that the same approach to graphing the data didn\u2019t work well on a bigger screen, it slowed down way too much. So I had to re-implement the scrolling graph control. Previously I was building a new PathFigure with the new points scaled to fit the screen, and so each frame was a new Path object and that\u2019s how it would scroll across the screen. Turns out the performance is a lot better if I reuse the PathFigure and only add to the Path object and never remove any points, and rarely re-scale the points. But in order to scroll then I needed to adjust the canvas position of the path to the left, well turns out I can do the scrolling at a higher rate than the point adding which results in a very smooth scroll which looks great. The problem is I would run out of memory if I never removed points, so what I do is cycle two Path objects, when one is completely offscreen on the left, I recycle it and use it on the right, and this is how I get really nice performance on the Surface. So I back ported that to the phone and it looks great there too. Privacy Policy The app records the accelerometer sensor data so that you can choose to save it locally on your device either in a bitmap image or in an XML file. The app does not send your data anywhere else, so the data is not shared with anyone. You can choose to send the bitmap image or the XML file to someone else, but that is up to you. The app does not even know if you have shared your data with anyone.","title":"Seismograph App"},{"location":"posts/seismograph/#seismograph-app","text":"I built a simple app called Seismograph to visualize the accelerometer data on my phone. The reason I built this is because I wanted a simple way to check the vibration of the motors on my quadrocopter . I saw some really nice apps for android, but all the windows phone accelerometer apps were crap. So I built my own :-) I then ported this Seismograph for Windows RT so I could also run it on my Surface device. When I did that port I discovered that the same approach to graphing the data didn\u2019t work well on a bigger screen, it slowed down way too much. So I had to re-implement the scrolling graph control. Previously I was building a new PathFigure with the new points scaled to fit the screen, and so each frame was a new Path object and that\u2019s how it would scroll across the screen. Turns out the performance is a lot better if I reuse the PathFigure and only add to the Path object and never remove any points, and rarely re-scale the points. But in order to scroll then I needed to adjust the canvas position of the path to the left, well turns out I can do the scrolling at a higher rate than the point adding which results in a very smooth scroll which looks great. The problem is I would run out of memory if I never removed points, so what I do is cycle two Path objects, when one is completely offscreen on the left, I recycle it and use it on the right, and this is how I get really nice performance on the Surface. So I back ported that to the phone and it looks great there too.","title":"Seismograph App"},{"location":"posts/seismograph/#privacy-policy","text":"The app records the accelerometer sensor data so that you can choose to save it locally on your device either in a bitmap image or in an XML file. The app does not send your data anywhere else, so the data is not shared with anyone. You can choose to send the bitmap image or the XML file to someone else, but that is up to you. The app does not even know if you have shared your data with anyone.","title":"Privacy Policy"},{"location":"posts/software_trails/","text":"Software Trails See demo video: (MP4 30mb) Download Tool: SoftwareTrails.application Transcript : Hi, Have you ever wanted to see what is going on in your program in real time? I built a light weight profiling tool that shows you exactly that. Let me show you how it works. To get started you click the Launch button and find the application you want to profile and immediately we see a bunch of activity showing what\u2019s happening as the app launches. This dashboard is showing a roll up across the top level Namespaces and the counters are showing the total number of function calls in each area. You can scroll down and see everything that is going on. We can see that there are some Microsoft namespaces, but there\u2019s also a Walkabout namespace which happens to be the code for this application. So I can take a look at startup again without the .NET frameworks by drilling down into the Walkabout namespace - this shows me the drill down path and the green blocks represent classes and namespaces and the white blocks represent method calls. So we can now see that we\u2019re getting down to the method call level - maybe we\u2019re interested in seeing what happens during LoadConfig and we can click that method and it will search the call information and build a conglomerate call stack graph basically showing a combination of all call stacks that it has seen involving that method Loadconfig. And from this you can actually explore down into WPF or you can explore upwards and see what those function calls are doing. You can also try and expand the entire graph but in this case it\u2019s not recommended because the graph is huge. When you\u2019re done exploring the call stack you can close that and go back to the dashboard. You can also Filter this information - so maybe I care about anything involving the word \u201cTransaction\u201d and I can see that during the launching of the application that there\u2019s some Transactions Namespaces and I can also see that it shows up over here in the View namespace. Let\u2019s drill down into some controls and we see a class named TransactionView. At any point you can clear the buffer and start over and go back to and remember to clear the filter. When I do that I can see that there\u2019s actually a heart-beat going on with this application and the reason for that if I drill into the MainWindow is that there\u2019s an OnTick method that is being fired by a DispatcherTimer. Ok, let\u2019s go back over here and let me show you more about this application that I\u2019m profiling. Let me just disconnect for a second (you can disconnect at any time if you want to just pause the profiling). I\u2019m going to load some sample data into this application. It\u2019s basically a personal finance application like Quicken and I\u2019m going to show you the real scenario that I\u2019d like to debug, so now I have some sample data, the scenario that I want to debug is drag/drop - I want to find out why drag drop isn\u2019t working in this window here. Alright, so I can now reconnect back to that application, the profiler is ready for work, probably want to go back home, and let\u2019s run the drag/drop scenario. We see a lot of activity, 16 million function calls already, even after clearing the buffer, I see some stuff in the Walkabout namespace, and the System namespace, so let me apply a filter again and just search for anything containing the word \u201cDrag\u201d. Now I could look at the Walkabout code, but first I want to take a look at the .NET frameworks. So in the history of calls that we have in the buffer, this is everything that WPF does to implement Drag/Drop. This gives me a really great place to start looking up documentation on MSDN to find out what these methods do, OnDragOver, OnDragEnter, OnDragLeave and so on, and also I see a method called DoDragDrop which sound like an interesting place to start, let\u2019s take a look at that method, and if I look at the caller, well it\u2019s this class called MoneyDataGrid. So now we know the class over here in the UI is called MoneyDataGrid. So now if we go back to the Walkabout namespace, there I can see the Controls namespace and the Views namespace and I can see the classed called MoneyDataGrid. This is the guy that starts the drag/drop operation - so let\u2019s remove the filter and take a closer look at everything he\u2019s doing. He\u2019s getting the mouse move which begins the drag/drop operation and here we see a flag called \u201cget_SupportDragDrop\u201d and we see the OnQueryContinueDrag method which the MSDN documentation tells us is used by WPF to figure out whether the drag/drop operation should continue. So let\u2019s select OnQueryContinueDrag and see what it calls. Now I have an excellent place to go and look in the code - it\u2019s in MoneyDataGrid, to find out why when I drag this window nothing happens. Now if I clear the buffer and do it again, now I can see in real time a lot of these mouse moves come in, I see the call to get_SupportDragDrop and so on. So being able to see in real time what\u2019s happening, for example, when I do mouse moves, it\u2019s is a really useful way to see what\u2019s going on in my code. I can also see that when I wiggle the mouse there are lots and lots of function calls, so if I\u2019m worried about performance at all, that counter down there, plus the rollup for each Namespace is going to be a great way to figure out where I need to optimize and see if I can remove some of those calls and get better performance. Profiling Very Large Applications Ok, enough of that application. Now what about a bigger application? I\u2019m going to launch Visual Studio - Visual Studio consists of a huge amount of code. I want to see what the overhead then is of the profiler in launching Visual Studio. Already we can see all the .NET framework stuff that\u2019s happening, and Visual Studio is already up and running in about 10 seconds. So we can also see here that in order to launch Visual Studio it takes about 46 million function calls, but there\u2019s only about 15 thousand unique functions. Again, here\u2019s the top level view, I can see the Microsoft.VisualStudio namespace, which is where all the Visual Studio code lives so I can drill down and re-run the launch scenario and I can see everything that happens in the Microsoft.VisualStudio namespace when it launches. I can see stuff in the Platform, in the Shell, there\u2019s some Packages, let\u2019s see what package is doing, and drill down, and so on. The breadcrumb toolbar allows you to go jump back up to any level that I want. Let\u2019s go back to VisualStudio. Now the same thing can be done - let\u2019s say I want to explore a drag/drop scenario inside Visual Studio with the \u201cDrag\u201d filter. First let\u2019s clear the 50 million function call history, that was quick, and let\u2019s load a DGML graph so we can explore drag/drop in DGML. First off when I load the graph I can already see a bunch of classes, \u201cGraphDragDrop\u201d, and \u201cDragSourceGesture\u201d and these are getting fired up inside Visual Studio, so that\u2019s promising. Those things will probably add drag/drop support. Let\u2019s zoom in and grab one of these nodes, and do a drag/drop. Just as before I\u2019m able to see in real-time everything that\u2019s happening - the DragSourceGesture did a lot of work, let\u2019s drill into that and take a look at that again, ok, I\u2019ve got too much stuff in my buffer, let\u2019s clear that and do the drag/drop again, and instantly we see exactly what\u2019s happening deep down inside Visual Studio to support that Drag/Drop operation and now I know where to find the code and set breakpoints and continue my debugging. So I think you\u2019ll find that this profiler scales up to some pretty big software. Testing I think this tool will also make a great testing companion. For example, if you own a document editor then there\u2019s a special call deep down in the VS shell called \u201cReleaseDocument\u201d that needs to happen when your document window is closed. Bang, all right, so deep inside this Visual Studio namespace, inside WindowManagement, there should be a call to ReleaseDocument. If that doesn\u2019t happen you have a pretty bad memory leak in your editor. So this tool is a great way to do an ad hoc test that certain things are happening when they are supposed to. That\u2019s it, I hope you enjoy it, please send your comments to my blog. Download Tool: SoftwareTrails.application","title":"Software Trails"},{"location":"posts/software_trails/#software-trails","text":"See demo video: (MP4 30mb) Download Tool: SoftwareTrails.application Transcript : Hi, Have you ever wanted to see what is going on in your program in real time? I built a light weight profiling tool that shows you exactly that. Let me show you how it works. To get started you click the Launch button and find the application you want to profile and immediately we see a bunch of activity showing what\u2019s happening as the app launches. This dashboard is showing a roll up across the top level Namespaces and the counters are showing the total number of function calls in each area. You can scroll down and see everything that is going on. We can see that there are some Microsoft namespaces, but there\u2019s also a Walkabout namespace which happens to be the code for this application. So I can take a look at startup again without the .NET frameworks by drilling down into the Walkabout namespace - this shows me the drill down path and the green blocks represent classes and namespaces and the white blocks represent method calls. So we can now see that we\u2019re getting down to the method call level - maybe we\u2019re interested in seeing what happens during LoadConfig and we can click that method and it will search the call information and build a conglomerate call stack graph basically showing a combination of all call stacks that it has seen involving that method Loadconfig. And from this you can actually explore down into WPF or you can explore upwards and see what those function calls are doing. You can also try and expand the entire graph but in this case it\u2019s not recommended because the graph is huge. When you\u2019re done exploring the call stack you can close that and go back to the dashboard. You can also Filter this information - so maybe I care about anything involving the word \u201cTransaction\u201d and I can see that during the launching of the application that there\u2019s some Transactions Namespaces and I can also see that it shows up over here in the View namespace. Let\u2019s drill down into some controls and we see a class named TransactionView. At any point you can clear the buffer and start over and go back to and remember to clear the filter. When I do that I can see that there\u2019s actually a heart-beat going on with this application and the reason for that if I drill into the MainWindow is that there\u2019s an OnTick method that is being fired by a DispatcherTimer. Ok, let\u2019s go back over here and let me show you more about this application that I\u2019m profiling. Let me just disconnect for a second (you can disconnect at any time if you want to just pause the profiling). I\u2019m going to load some sample data into this application. It\u2019s basically a personal finance application like Quicken and I\u2019m going to show you the real scenario that I\u2019d like to debug, so now I have some sample data, the scenario that I want to debug is drag/drop - I want to find out why drag drop isn\u2019t working in this window here. Alright, so I can now reconnect back to that application, the profiler is ready for work, probably want to go back home, and let\u2019s run the drag/drop scenario. We see a lot of activity, 16 million function calls already, even after clearing the buffer, I see some stuff in the Walkabout namespace, and the System namespace, so let me apply a filter again and just search for anything containing the word \u201cDrag\u201d. Now I could look at the Walkabout code, but first I want to take a look at the .NET frameworks. So in the history of calls that we have in the buffer, this is everything that WPF does to implement Drag/Drop. This gives me a really great place to start looking up documentation on MSDN to find out what these methods do, OnDragOver, OnDragEnter, OnDragLeave and so on, and also I see a method called DoDragDrop which sound like an interesting place to start, let\u2019s take a look at that method, and if I look at the caller, well it\u2019s this class called MoneyDataGrid. So now we know the class over here in the UI is called MoneyDataGrid. So now if we go back to the Walkabout namespace, there I can see the Controls namespace and the Views namespace and I can see the classed called MoneyDataGrid. This is the guy that starts the drag/drop operation - so let\u2019s remove the filter and take a closer look at everything he\u2019s doing. He\u2019s getting the mouse move which begins the drag/drop operation and here we see a flag called \u201cget_SupportDragDrop\u201d and we see the OnQueryContinueDrag method which the MSDN documentation tells us is used by WPF to figure out whether the drag/drop operation should continue. So let\u2019s select OnQueryContinueDrag and see what it calls. Now I have an excellent place to go and look in the code - it\u2019s in MoneyDataGrid, to find out why when I drag this window nothing happens. Now if I clear the buffer and do it again, now I can see in real time a lot of these mouse moves come in, I see the call to get_SupportDragDrop and so on. So being able to see in real time what\u2019s happening, for example, when I do mouse moves, it\u2019s is a really useful way to see what\u2019s going on in my code. I can also see that when I wiggle the mouse there are lots and lots of function calls, so if I\u2019m worried about performance at all, that counter down there, plus the rollup for each Namespace is going to be a great way to figure out where I need to optimize and see if I can remove some of those calls and get better performance.","title":"Software Trails"},{"location":"posts/software_trails/#profiling-very-large-applications","text":"Ok, enough of that application. Now what about a bigger application? I\u2019m going to launch Visual Studio - Visual Studio consists of a huge amount of code. I want to see what the overhead then is of the profiler in launching Visual Studio. Already we can see all the .NET framework stuff that\u2019s happening, and Visual Studio is already up and running in about 10 seconds. So we can also see here that in order to launch Visual Studio it takes about 46 million function calls, but there\u2019s only about 15 thousand unique functions. Again, here\u2019s the top level view, I can see the Microsoft.VisualStudio namespace, which is where all the Visual Studio code lives so I can drill down and re-run the launch scenario and I can see everything that happens in the Microsoft.VisualStudio namespace when it launches. I can see stuff in the Platform, in the Shell, there\u2019s some Packages, let\u2019s see what package is doing, and drill down, and so on. The breadcrumb toolbar allows you to go jump back up to any level that I want. Let\u2019s go back to VisualStudio. Now the same thing can be done - let\u2019s say I want to explore a drag/drop scenario inside Visual Studio with the \u201cDrag\u201d filter. First let\u2019s clear the 50 million function call history, that was quick, and let\u2019s load a DGML graph so we can explore drag/drop in DGML. First off when I load the graph I can already see a bunch of classes, \u201cGraphDragDrop\u201d, and \u201cDragSourceGesture\u201d and these are getting fired up inside Visual Studio, so that\u2019s promising. Those things will probably add drag/drop support. Let\u2019s zoom in and grab one of these nodes, and do a drag/drop. Just as before I\u2019m able to see in real-time everything that\u2019s happening - the DragSourceGesture did a lot of work, let\u2019s drill into that and take a look at that again, ok, I\u2019ve got too much stuff in my buffer, let\u2019s clear that and do the drag/drop again, and instantly we see exactly what\u2019s happening deep down inside Visual Studio to support that Drag/Drop operation and now I know where to find the code and set breakpoints and continue my debugging. So I think you\u2019ll find that this profiler scales up to some pretty big software.","title":"Profiling Very Large Applications"},{"location":"posts/software_trails/#testing","text":"I think this tool will also make a great testing companion. For example, if you own a document editor then there\u2019s a special call deep down in the VS shell called \u201cReleaseDocument\u201d that needs to happen when your document window is closed. Bang, all right, so deep inside this Visual Studio namespace, inside WindowManagement, there should be a call to ReleaseDocument. If that doesn\u2019t happen you have a pretty bad memory leak in your editor. So this tool is a great way to do an ad hoc test that certain things are happening when they are supposed to. That\u2019s it, I hope you enjoy it, please send your comments to my blog. Download Tool: SoftwareTrails.application","title":"Testing"},{"location":"posts/tesla/","text":"My Tesla Model S Ok, it has been over 2 years now that I have been the proud owner of a Tesla Model S. I held off raving about it because I wanted to make sure it wasn\u2019t just the honey moon phase that had me gushing about all the wonderful features. 2 1/2 years is long enough, I should know all the dirt by now, meaning I can now write a balanced review from my real day to day usage. While I will be the first to admit that Tesla has not achieved any huge breakthroughs in build quality, they have achieved a new level of customer delight because of their end-to-end customer experience . The best analogy I can think of is that Tesla is to cars what Apple is to phones. A revolution in user experience. But before I get into that, let me list all the problems I have had with this car. Paint While driving the car home from California to Seattle, I got stuck in a blizzard behind a salt truck in Oregon and the truck was dumping giant 1 inch round salt rocks on the road which promptly bounced off the road and right onto my car. This left some nasty marks on the hood. Then not long after I had it home I dropped the charging cable down the side of the car which left a scratch on my driver\u2019s door. So I found out the hard way that Tesla puts on a pretty thin paint job. So I decided to get a Vinyl Wrap for my entire car. It was expensive, but it has kept the car in pristine condition as you can see in the photo. Doors & Trim Early on the plastic clips holding the passenger side interior door together came off when someone slammed the door too hard. I took it in to get repaired, which they did quickly and for free. No more problems in this area. One piece of chrome trim wasn\u2019t aligned very well and they promptly fixed this when I pointed it out. Sensors The vinyl wrap interfered with my parking sensors, but I didn\u2019t know that for a while. I took it in for service, the service department was fantastic and did everything including replacing the entire sensor module, and then advised that I remove a dot over each sensor location. Bingo everything is great. So this was entirely my fault (and the fault of the company that did the wrap - they should have known better). So lesson learned, if you get a vinyl wrap make sure they do not cover the sensors. So what do I like about it? Everything. The car greets me by extending the door handles as I approach. This seems silly, but it forms a bond over time, it makes the car seem alive, anticipating my every need. The seats are extremely comfortable. I used to own a Volvo and I thought they had the best seats. This one is better. I\u2019ve driven around 15,000 miles, mostly commuting about 10 miles to work and back every day, but I\u2019ve also done some road trips to Oregon and Vancouver B.C. The car and all the electronics have worked perfectly. I use all the auto-pilot features, adaptive cruise control; auto-steering to keep me in my lane; summon, to get the car out of a tight parking spot, and more. But for some reason the NTSB is picking on Tesla because of a few idiots that chose to ignore all of Tesla\u2019s warnings about paying attention while driving. The car is not autonomous . Any sane driver will know this. Those that choose to believe otherwise are just idiots. But blaming Tesla for these fatalities is like blaming Ford for making a car that someone fell asleep in. Where are all the NTSB reports covering the other 37133 fatalities that happened in 2017? I have a completely different view than the NTSB. Adaptive Cruise Control Rocks This is not your average crappy cruise control. Because of regenerative breaking the first thing you will notice is that the car nails the speed you set and just sticks there. It\u2019s like a gymnast sticking the landing every time. It is flawless. Remember those old gas powered cars that would run away down hill and your cruise control was useless? A thing of the past. This feature is super useful in mind numbing bumper-to-bumper traffic because it can stay engaged all the way to stopped and then back to moving again. Regenerative Braking Speaking of regenerative braking, I absolutely love it. Not only do I get the thrill of seeing 50,000 Watts get pumped back into my battery but I also get the lovely green line of greenness on my dashboard power usage display reminds me that my car is making the world a better place. When I drive by a gas station my thumb always ends up on my nose, and my fingers start wiggling. Every now and then my tongue also makes a funny raspberry sound. It never gets old. It takes some getting used to, because when you lift your foot off the pedal, the regenerative braking kicks in. This is configurable, but the standard setting has really grown on me. I love the sense of control this gives me now. When I get into an old car and lift my foot the car just wanders off on it\u2019s own, rolling away until I put my foot on the brake. This now freaks me out, it\u2019s like the old car has a mind of it\u2019s own, it is not doing what I told it and I have to punish it with a slap on the brakes. The regenerative braking is also saving my brake pads big time. When I got back home California, an 855 mile drive, I still had factory paint on the inside of the brake pads because I hardly ever use the brakes. Super Charging On my way home from California I used 3 super charging stations. Getting back to 80 % full in 20 minutes is amazing. I love how new stations keep popping up everywhere. On my trip to Vancouver the super charger was right in the down town area so I could walk from there to my business appointment. By the time I got back the car was full and ready for my trip home. So I spent absolutely no time standing around picking my nose while getting high on gas fumes! Electric charging is actually saving me time. This is such an amazing user experience. At home I have the high power wall charger which has also worked flawlessly, keeping my car topped up at all times. I love how you can schedule when the car charges, and reduce the top limit so Tesla can keep all battery cells balanced and in good condition. I have not seen any noticeable drop in battery capacity since the day I bought the car. Auto-steering On roads with clear lane markings the car allows me to enter an auto-pilot mode where the car will keep itself in the lane. It\u2019s not perfect, and that is ok. What I have found is that it allows me to better keep tabs on the big picture of what is happening around me rather than the mind numbing problem of micro-steering. I know for sure this has helped me avoid some dangerous situations because I was looking down a side street, or way down the road at something going on ahead of me. One time I also noticed someone behind me was not going to stop, so I pulled into a different lane. I also found that I feel much more relaxed when I get to work because the car has taken over all the mind numbing parts of driving. Recently they added a new feature which is auto-lane changing when I turn on the indicator. Nice! Show me any other car that \u201ckeeps getting better\u201d over time. Navigation The huge navigation screen is awesome, and the smaller turn-by-turn directions behind the steering wheel is a really nice touch. They have also shipped several updates that have greatly improved the navigation system. What do people do a lot in cars? They try to get someplace. It just makes so much sense to nail this scenario. I think Tesla has the worlds best car navigation experience, and probably will continue to for a long time to come. Software Updates A car that gets regular software updates, it is hilarious how far ahead of the competition they are on this front. I was nervous at first thinking they would one day push it too far and brick the car with a bad update. But each update has been flawless. Knock on wood. When I get the update notification my heart skips and it\u2019s like Christmas all over again as I read up on all the new coolness they are packing into my car. Every other car company wants to chalk up your purchase in the black column and never hear from you again, lest you cost them more money. Not Tesla. Tesla wants to build a lasting relationship, raving fans, and it\u2019s working. Entertainment All the multi-media features are state of the art. Integration with my iPhone is great. Being able to heat up my car from my office on those cold winter nights is delectable. I use the radio, and the built in music channels, PBS radio and so on. All work perfectly every time. But the feature that really brought a lot of chuckles in my family was the \u201cFart on demand\u201d feature. Yes, I kid you not. I can press a button on the screen and make the seat under any unsuspecting passenger make a juicy 9.0 fart sound. My wife also loves the \u201cRomantic mode\u201d that turns the big screen into a fire place perfect for us to snuggle by. What other car company in the world would have dared to ship such crazy easter eggs? Conclusion The thing I keep coming back to is that Tesla has nailed end-to-end user experience. The way the car greets me, interior comfort, world class navigation, auto-pilot keeping me relaxed and happy on the road, high power charging, even the purchasing experience was more fun than previous cars I\u2019ve bought. It was about as easy as buying a new flashlight from Amazon. So while they have not nailed build quality, I think everything else Tesla has done is game changing. I\u2019m sure they will also revolutionize build quality one of these days as their manufacturing processes mature. Tesla has survived despite all the nay sayers. I think they know what they are doing. Tesla is a fast moving, innovative company. They are willing to play and have fun while they work their asses off making the world\u2019s best cars. I can\u2019t wait to see what they come up with next.","title":"My Telsa Model S"},{"location":"posts/tesla/#my-tesla-model-s","text":"Ok, it has been over 2 years now that I have been the proud owner of a Tesla Model S. I held off raving about it because I wanted to make sure it wasn\u2019t just the honey moon phase that had me gushing about all the wonderful features. 2 1/2 years is long enough, I should know all the dirt by now, meaning I can now write a balanced review from my real day to day usage. While I will be the first to admit that Tesla has not achieved any huge breakthroughs in build quality, they have achieved a new level of customer delight because of their end-to-end customer experience . The best analogy I can think of is that Tesla is to cars what Apple is to phones. A revolution in user experience. But before I get into that, let me list all the problems I have had with this car.","title":"My Tesla Model S"},{"location":"posts/tesla/#paint","text":"While driving the car home from California to Seattle, I got stuck in a blizzard behind a salt truck in Oregon and the truck was dumping giant 1 inch round salt rocks on the road which promptly bounced off the road and right onto my car. This left some nasty marks on the hood. Then not long after I had it home I dropped the charging cable down the side of the car which left a scratch on my driver\u2019s door. So I found out the hard way that Tesla puts on a pretty thin paint job. So I decided to get a Vinyl Wrap for my entire car. It was expensive, but it has kept the car in pristine condition as you can see in the photo.","title":"Paint"},{"location":"posts/tesla/#doors-trim","text":"Early on the plastic clips holding the passenger side interior door together came off when someone slammed the door too hard. I took it in to get repaired, which they did quickly and for free. No more problems in this area. One piece of chrome trim wasn\u2019t aligned very well and they promptly fixed this when I pointed it out.","title":"Doors &amp; Trim"},{"location":"posts/tesla/#sensors","text":"The vinyl wrap interfered with my parking sensors, but I didn\u2019t know that for a while. I took it in for service, the service department was fantastic and did everything including replacing the entire sensor module, and then advised that I remove a dot over each sensor location. Bingo everything is great. So this was entirely my fault (and the fault of the company that did the wrap - they should have known better). So lesson learned, if you get a vinyl wrap make sure they do not cover the sensors.","title":"Sensors"},{"location":"posts/tesla/#so-what-do-i-like-about-it","text":"Everything. The car greets me by extending the door handles as I approach. This seems silly, but it forms a bond over time, it makes the car seem alive, anticipating my every need. The seats are extremely comfortable. I used to own a Volvo and I thought they had the best seats. This one is better. I\u2019ve driven around 15,000 miles, mostly commuting about 10 miles to work and back every day, but I\u2019ve also done some road trips to Oregon and Vancouver B.C. The car and all the electronics have worked perfectly. I use all the auto-pilot features, adaptive cruise control; auto-steering to keep me in my lane; summon, to get the car out of a tight parking spot, and more. But for some reason the NTSB is picking on Tesla because of a few idiots that chose to ignore all of Tesla\u2019s warnings about paying attention while driving. The car is not autonomous . Any sane driver will know this. Those that choose to believe otherwise are just idiots. But blaming Tesla for these fatalities is like blaming Ford for making a car that someone fell asleep in. Where are all the NTSB reports covering the other 37133 fatalities that happened in 2017? I have a completely different view than the NTSB.","title":"So what do I like about it?"},{"location":"posts/tesla/#adaptive-cruise-control-rocks","text":"This is not your average crappy cruise control. Because of regenerative breaking the first thing you will notice is that the car nails the speed you set and just sticks there. It\u2019s like a gymnast sticking the landing every time. It is flawless. Remember those old gas powered cars that would run away down hill and your cruise control was useless? A thing of the past. This feature is super useful in mind numbing bumper-to-bumper traffic because it can stay engaged all the way to stopped and then back to moving again.","title":"Adaptive Cruise Control Rocks"},{"location":"posts/tesla/#regenerative-braking","text":"Speaking of regenerative braking, I absolutely love it. Not only do I get the thrill of seeing 50,000 Watts get pumped back into my battery but I also get the lovely green line of greenness on my dashboard power usage display reminds me that my car is making the world a better place. When I drive by a gas station my thumb always ends up on my nose, and my fingers start wiggling. Every now and then my tongue also makes a funny raspberry sound. It never gets old. It takes some getting used to, because when you lift your foot off the pedal, the regenerative braking kicks in. This is configurable, but the standard setting has really grown on me. I love the sense of control this gives me now. When I get into an old car and lift my foot the car just wanders off on it\u2019s own, rolling away until I put my foot on the brake. This now freaks me out, it\u2019s like the old car has a mind of it\u2019s own, it is not doing what I told it and I have to punish it with a slap on the brakes. The regenerative braking is also saving my brake pads big time. When I got back home California, an 855 mile drive, I still had factory paint on the inside of the brake pads because I hardly ever use the brakes.","title":"Regenerative Braking"},{"location":"posts/tesla/#super-charging","text":"On my way home from California I used 3 super charging stations. Getting back to 80 % full in 20 minutes is amazing. I love how new stations keep popping up everywhere. On my trip to Vancouver the super charger was right in the down town area so I could walk from there to my business appointment. By the time I got back the car was full and ready for my trip home. So I spent absolutely no time standing around picking my nose while getting high on gas fumes! Electric charging is actually saving me time. This is such an amazing user experience. At home I have the high power wall charger which has also worked flawlessly, keeping my car topped up at all times. I love how you can schedule when the car charges, and reduce the top limit so Tesla can keep all battery cells balanced and in good condition. I have not seen any noticeable drop in battery capacity since the day I bought the car.","title":"Super Charging"},{"location":"posts/tesla/#auto-steering","text":"On roads with clear lane markings the car allows me to enter an auto-pilot mode where the car will keep itself in the lane. It\u2019s not perfect, and that is ok. What I have found is that it allows me to better keep tabs on the big picture of what is happening around me rather than the mind numbing problem of micro-steering. I know for sure this has helped me avoid some dangerous situations because I was looking down a side street, or way down the road at something going on ahead of me. One time I also noticed someone behind me was not going to stop, so I pulled into a different lane. I also found that I feel much more relaxed when I get to work because the car has taken over all the mind numbing parts of driving. Recently they added a new feature which is auto-lane changing when I turn on the indicator. Nice! Show me any other car that \u201ckeeps getting better\u201d over time.","title":"Auto-steering"},{"location":"posts/tesla/#navigation","text":"The huge navigation screen is awesome, and the smaller turn-by-turn directions behind the steering wheel is a really nice touch. They have also shipped several updates that have greatly improved the navigation system. What do people do a lot in cars? They try to get someplace. It just makes so much sense to nail this scenario. I think Tesla has the worlds best car navigation experience, and probably will continue to for a long time to come.","title":"Navigation"},{"location":"posts/tesla/#software-updates","text":"A car that gets regular software updates, it is hilarious how far ahead of the competition they are on this front. I was nervous at first thinking they would one day push it too far and brick the car with a bad update. But each update has been flawless. Knock on wood. When I get the update notification my heart skips and it\u2019s like Christmas all over again as I read up on all the new coolness they are packing into my car. Every other car company wants to chalk up your purchase in the black column and never hear from you again, lest you cost them more money. Not Tesla. Tesla wants to build a lasting relationship, raving fans, and it\u2019s working.","title":"Software Updates"},{"location":"posts/tesla/#entertainment","text":"All the multi-media features are state of the art. Integration with my iPhone is great. Being able to heat up my car from my office on those cold winter nights is delectable. I use the radio, and the built in music channels, PBS radio and so on. All work perfectly every time. But the feature that really brought a lot of chuckles in my family was the \u201cFart on demand\u201d feature. Yes, I kid you not. I can press a button on the screen and make the seat under any unsuspecting passenger make a juicy 9.0 fart sound. My wife also loves the \u201cRomantic mode\u201d that turns the big screen into a fire place perfect for us to snuggle by. What other car company in the world would have dared to ship such crazy easter eggs?","title":"Entertainment"},{"location":"posts/tesla/#conclusion","text":"The thing I keep coming back to is that Tesla has nailed end-to-end user experience. The way the car greets me, interior comfort, world class navigation, auto-pilot keeping me relaxed and happy on the road, high power charging, even the purchasing experience was more fun than previous cars I\u2019ve bought. It was about as easy as buying a new flashlight from Amazon. So while they have not nailed build quality, I think everything else Tesla has done is game changing. I\u2019m sure they will also revolutionize build quality one of these days as their manufacturing processes mature. Tesla has survived despite all the nay sayers. I think they know what they are doing. Tesla is a fast moving, innovative company. They are willing to play and have fun while they work their asses off making the world\u2019s best cars. I can\u2019t wait to see what they come up with next.","title":"Conclusion"},{"location":"posts/vs_xml_schemas/","text":"Visual Studio\u2019s lesser-known Xml Schema features John Tasler made me write this blog. There I was quietly responding to various emails when John said to me, he said \u201chey, that would make a great blog\u201d. So don\u2019t blame me, it was his idea \ud83d\ude42 What was the question you ask? Well Ming wanted to know how do you make Visual Studio automatically apply an xsd schema to a newly created XML file ? Answer : You have lots of options. If your schema lives in %DevEnvDir%....\\Xml\\Schemas, or anywhere in your currently loaded \u201cSolution\u201d, then all you need to do is reference the target namespace of your schema like this: But if your schema needs to live some place else (like in the cloud) then you can reference it using xsi namespace trick like this: But for this to work you have to enable downloads in the XML editor tools options miscellaneous tab (it is off by default): And you should be sure the owner of the site that publishes this schema is happy with you doing that. Especially if you are going to encourage lots of users to do the same.Lastly if you have a totally ad-hoc XML and schema location elsewhere you can set one or more schemas to use on a per-document basis using the document Properties windows like this: If you are building a project item wizard then, you could automate this step if you want using VS automation api. SchemaCatalogs : But what a lot of people never think to ask is what if I have multiple schemas of different versions that use the same target namespace? Well for functional completion on this topic, this is where the SchemaCatalog file comes in: <?xml version=\u201c1.0\u201c encoding=\u201cutf-8\u201c?> <SchemaCatalog xmlns=\u201chttp://schemas.microsoft.com/xsd/catalog\u201c> \u2026 </SchemaCatalog> See %DevEnvDir%....\\Xml\\Schemas\\catalog.xml for an example. It can \u201cassociate\u201d schemas from other VS directories using %InstallRoot%, and it can associate by file type with conditional expressions.","title":"Visual Studio\u2019s lesser-known Xml Schema features"},{"location":"posts/vs_xml_schemas/#visual-studios-lesser-known-xml-schema-features","text":"John Tasler made me write this blog. There I was quietly responding to various emails when John said to me, he said \u201chey, that would make a great blog\u201d. So don\u2019t blame me, it was his idea \ud83d\ude42 What was the question you ask? Well Ming wanted to know how do you make Visual Studio automatically apply an xsd schema to a newly created XML file ? Answer : You have lots of options. If your schema lives in %DevEnvDir%....\\Xml\\Schemas, or anywhere in your currently loaded \u201cSolution\u201d, then all you need to do is reference the target namespace of your schema like this: But if your schema needs to live some place else (like in the cloud) then you can reference it using xsi namespace trick like this: But for this to work you have to enable downloads in the XML editor tools options miscellaneous tab (it is off by default): And you should be sure the owner of the site that publishes this schema is happy with you doing that. Especially if you are going to encourage lots of users to do the same.Lastly if you have a totally ad-hoc XML and schema location elsewhere you can set one or more schemas to use on a per-document basis using the document Properties windows like this: If you are building a project item wizard then, you could automate this step if you want using VS automation api. SchemaCatalogs : But what a lot of people never think to ask is what if I have multiple schemas of different versions that use the same target namespace? Well for functional completion on this topic, this is where the SchemaCatalog file comes in: <?xml version=\u201c1.0\u201c encoding=\u201cutf-8\u201c?> <SchemaCatalog xmlns=\u201chttp://schemas.microsoft.com/xsd/catalog\u201c> \u2026 </SchemaCatalog> See %DevEnvDir%....\\Xml\\Schemas\\catalog.xml for an example. It can \u201cassociate\u201d schemas from other VS directories using %InstallRoot%, and it can associate by file type with conditional expressions.","title":"Visual Studio's lesser-known Xml Schema features"},{"location":"posts/winrt_broker/","text":"WinRT Extensions using RuntimeBroker Have you ever wanted to do something naughty from your lovely well behaved sand-boxed WinRT application? Do you need to call some Win32 API that you don\u2019t have permission to do from WinRT? Well WinRT itself does this using a separate service called the RuntimeBroker. Many WinRT objects use RPC to call into this broker process and do those things that need elevated privileges. I built a sample application that shows how to do this. Essentially it goes something like this: - Create a static C++ library containing a MIDL interface and compile it using /winrt to make it a windows runtime (WinRT) interface. - This generates RPC proxy stuff needed to marshal the interface across processes. Compile this into a new C++ DLL called \u201cYourInterface.ProxyStub.dll\u201d. You will register this dll using regsvr32 and this is needed for RPC to work. This proxy stub and the implementing broker dll will need to live in a location your WinRT app can access, like c:\\windows\\system32. - Next create a Universal C++ DLL called \u201cYourInterfaceBroker.dll\u201d \u2013 this will contain the implementation of the interface and is designed to run in the RuntimeBroker process. This DLL will be able to call out to Win32 and do interesting things. - Register the broker using a custom registry script. - Lastly create a C# Blank Universal WinRT application to test out your new interface, referencing the *.winmd that was generated by step 1. When you instantiate your new runtime class it is loaded into the RuntimeBroker process, and your C# app gets back the client proxy to it so each call to that object is marshalled automatically to the RuntimeBroker. See the sample code: WinRTServiceSample.zip . MIDL Interface Library In my sample I started with this static C++ library, I added a MIDL file called Microsoft.Service.Sample.idl, this defines the name of the .winmd so its namespace has to match the filename. I then used the MIDL Tab in the C++ properties to turn on \u201cEnable Windows Runtime\u201d /winrt compile option. The .winmd file is placed in the project output directory. I built it once and this also generates a dlldata.c and _i.c and _p.c files. I added those files to the project. To compile them it is easier if you just turn off the C++ option for precompiled headers. I also added the C++ preprocessor defines: WIN32;_WINDOWS;. So now you have a static library containing the RPC stubs needed later. For the purposes of this sample app I defined the following simple WinRT interface and runtime class: import \"inspectable.idl\"; import \"Windows.Foundation.idl\"; #ifndef NTDDI_WIN8 #define NTDDI_WIN8 0x06020000 #endif namespace Microsoft { namespace Service { namespace Sample { [uuid(C595230E-CB68-49EB-ACD1-70EE35B41D01)] [version(NTDDI_WIN8)] interface IMyService : IInspectable { HRESULT DoSomethingFun(); }; [ version(NTDDI_WIN8), activatable(NTDDI_WIN8), marshaling_behavior(agile), threading(both), ] runtimeclass MyService { [default] interface IMyService; } } } } ProxyStub I then added a C++ Win32 DLL project called MyService.ProxyStub. This dll has to include the above files again, but this time with the C++ preprocessor definition \u201cREGISTER_PROXY_DLL\u201d, and you need to generate a new GUID for your runtime class id (different from the one in the MIDL file) in a new ProxyEntry.c file as follows: // {xxxxxxxx-4CCC-4D4E-9C8C-A842DB7182E6} #define PROXY_CLSID_IS { 0xxxxxxxxx, 0x4ccc, 0x4d4e,{ 0x9c, 0x8c, 0xa8, 0x42, 0xdb, 0x71, 0x82, 0xe6 } }; #define USE_STUBLESS_PROXY #define PROXY_DELEGATION #include <rpcproxy.h> #include <ObjIdl.h> #include \"dlldata.c\" #include \"Microsoft.Service.Sample_i.c\" #include \"Microsoft.Service.Sample_p.c\" This is also easier to compile if you turn off precompiled headers. You also need to add a Module Definition file for the DLL containing: EXPORTS DllGetClassObject PRIVATE DllCanUnloadNow PRIVATE DllRegisterServer PRIVATE DllUnregisterServer PRIVATE You\u2019ll also need to add a VC++ Include Directory pointing at your interface static lib directory where the dlldata.c and _i.c and _p.c files got generated. You will also need to add the linker input \u201crpcrt4.lib\u201d. This generates the proxy stub needed for RPC to work. This dll will be registered using regsvr32. Broker Next I added a Universal C++ DLL project called \u201cMyServiceBroker\u201d. I added a reference to the static library project, I included #include <ObjIdl.h> in the pch.h file and again added the VC++ include directory where the _h.h file was generated. I wanted this DLL to work on the IoT SKU of Windows 10, which is why I used Universal DLL, but I want to run this outside an app container so I removed the following from the .vcxproj file: <AppContainerApplication>true</AppContainerApplication> . I also added the following linker instructions to each <Link> section: <IgnoreSpecificDefaultLibraries>comsuppwd.lib; comsuppw.lib; kernel32.lib; ole32.lib; user32.lib</IgnoreSpecificDefaultLibraries> <AdditionalDependencies>Wlanapi.lib;mincore.lib;onecoreuap.lib; WindowsApp.lib;</AdditionalDependencies> Lastly I added the a class that implements my new interface as follows: #pragma once #include <windows.h> #include <wrl.h> #include <MyInterface_h.h> namespace Microsoft { namespace Service { namespace Sample { class CMyService : public Microsoft::WRL::RuntimeClass<ABI::Microsoft::Service::Sample::IMyService, Microsoft::WRL::FtmBase> { InspectableClass(RuntimeClass_Microsoft_Service_Sample_MyService, PartialTrust); public: CMyService(); ~CMyService(); IFACEMETHOD(DoSomethingFun)(); private: CMyService(const CMyService&); const CMyService& operator = (const CMyService&); }; ActivatableClass(CMyService); } } } Then I added an empty implementation the the .cpp file. I also replaced the contents of the dllmain.cpp file with the following: #include \"pch.h\" #include <windows.h> #include <wrl.h> #include <wrl/module.h> using namespace Microsoft::WRL; STDAPI DllGetActivationFactory(_In_ HSTRING activatableClassId, _COM_Outptr_ IActivationFactory **factory) { return Module<ModuleType::InProcDisableCaching>::GetModule().GetActivationFactory(activatableClassId, factory); } _Check_return_ STDAPI DllGetClassObject(_In_ REFCLSID rclsid, _In_ REFIID riid, _Outptr_ LPVOID FAR* ppv) { return Module<ModuleType::InProcDisableCaching>::GetModule().GetClassObject(rclsid, riid, ppv); } STDAPI DllCanUnloadNow() { HRESULT hr = S_FALSE; if (Module<ModuleType::InProcDisableCaching>::GetModule().GetObjectCount() == 0) { hr = S_OK; } return hr; } STDAPI_(void) DllAddRef() { Module<ModuleType::InProcDisableCaching>::GetModule().IncrementObjectCount(); } STDAPI_(void) DllRelease() { Module<ModuleType::InProcDisableCaching>::GetModule().DecrementObjectCount(); } STDAPI_(BOOL) DllMain(_In_opt_ HINSTANCE hinst, DWORD reason, _In_opt_ void*) { if (reason == DLL_PROCESS_ATTACH) { DisableThreadLibraryCalls(hinst); } return TRUE; } Setup First you need to copy your *ProxyStub.dll and your *Broker.dll to a place that the WinRT app can access (like c:\\windows\\system32) otherwise you will get E_ACCESSDENIED when trying to call object from WinRT. To register the broker I created a custom registry script containing the following. Notice the GUID used here matches the one I generated for the ProxyEntry.c file earlier. Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\WindowsRuntime\\ActivatableClassId\\Microsoft.Service.Sample.MyService] \"ActivationType\"=dword:00000000 \"CLSID\"=\"xxxxxxxx-4CCC-4D4E-9C8C-A842DB7182E6\" \"Threading\"=dword:00000000 \"TrustLevel\"=dword:00000001 \"DllPath\"=\"c:\\\\Windows\\\\System32\\\\MyServiceBroker.dll\" [HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\WindowsRuntime\\CLSID\\{xxxxxxxx-4CCC-4D4E-9C8C-A842DB7182E6}] \"ActivatableClassId\"=\"Microsoft.Service.Sample.MyService\" Running this from administrator command prompt makes it possible for WinRT to construct your runtime class. You may need to take ownership of the WindowsRuntime part of the registry in order to do this. There is a tool called TakeRegistryAdminOwnership.exe included in the above download that can help with this. C# App To test out my new brokered service I created a blank C# windows application and added a reference to the generated Microsoft.Service.Sample.winmd file, then added the following lines: var service = new Microsoft.Service.Sample.MyService(); service.DoSomethingFun(); When you run these lines the MyServiceBroker.dll is loaded into the RuntimeBroker.exe process (you can attach to that process using your VS debugger and watch it happen and you can debug your broker that way also). You will see RPC stuff on the stack when the DoSomethingFun call comes in. Don\u2019t worry about terminating the RuntimeBroker.exe process, it will auto-restart. Callbacks If you need to have your broker do something async and call back to your C# application later you can easily define a new interface, implement that in C# and pass it to your broker as an argument, then the broker can call that interface. This RPC interface will \u201ctimeout\u201d after a minute, so you may need to repeat that process periodically or do a heartbeat kind of thing to keep it alive. You could build a WinRT component project that wraps all this and exposes a new \u201cClient\u201d interface that turns all this callback stuff into C++/CX events so that it is easier to consume in your C# applications. Your \u201cClient\u201d interface could also expose C++/CX properties and events so you have a nice modern interface to your new broker. Happy Brokering!","title":"WinRT Extensions using RuntimeBroker"},{"location":"posts/winrt_broker/#winrt-extensions-using-runtimebroker","text":"Have you ever wanted to do something naughty from your lovely well behaved sand-boxed WinRT application? Do you need to call some Win32 API that you don\u2019t have permission to do from WinRT? Well WinRT itself does this using a separate service called the RuntimeBroker. Many WinRT objects use RPC to call into this broker process and do those things that need elevated privileges. I built a sample application that shows how to do this. Essentially it goes something like this: - Create a static C++ library containing a MIDL interface and compile it using /winrt to make it a windows runtime (WinRT) interface. - This generates RPC proxy stuff needed to marshal the interface across processes. Compile this into a new C++ DLL called \u201cYourInterface.ProxyStub.dll\u201d. You will register this dll using regsvr32 and this is needed for RPC to work. This proxy stub and the implementing broker dll will need to live in a location your WinRT app can access, like c:\\windows\\system32. - Next create a Universal C++ DLL called \u201cYourInterfaceBroker.dll\u201d \u2013 this will contain the implementation of the interface and is designed to run in the RuntimeBroker process. This DLL will be able to call out to Win32 and do interesting things. - Register the broker using a custom registry script. - Lastly create a C# Blank Universal WinRT application to test out your new interface, referencing the *.winmd that was generated by step 1. When you instantiate your new runtime class it is loaded into the RuntimeBroker process, and your C# app gets back the client proxy to it so each call to that object is marshalled automatically to the RuntimeBroker. See the sample code: WinRTServiceSample.zip .","title":"WinRT Extensions using RuntimeBroker"},{"location":"posts/winrt_broker/#midl-interface-library","text":"In my sample I started with this static C++ library, I added a MIDL file called Microsoft.Service.Sample.idl, this defines the name of the .winmd so its namespace has to match the filename. I then used the MIDL Tab in the C++ properties to turn on \u201cEnable Windows Runtime\u201d /winrt compile option. The .winmd file is placed in the project output directory. I built it once and this also generates a dlldata.c and _i.c and _p.c files. I added those files to the project. To compile them it is easier if you just turn off the C++ option for precompiled headers. I also added the C++ preprocessor defines: WIN32;_WINDOWS;. So now you have a static library containing the RPC stubs needed later. For the purposes of this sample app I defined the following simple WinRT interface and runtime class: import \"inspectable.idl\"; import \"Windows.Foundation.idl\"; #ifndef NTDDI_WIN8 #define NTDDI_WIN8 0x06020000 #endif namespace Microsoft { namespace Service { namespace Sample { [uuid(C595230E-CB68-49EB-ACD1-70EE35B41D01)] [version(NTDDI_WIN8)] interface IMyService : IInspectable { HRESULT DoSomethingFun(); }; [ version(NTDDI_WIN8), activatable(NTDDI_WIN8), marshaling_behavior(agile), threading(both), ] runtimeclass MyService { [default] interface IMyService; } } } }","title":"MIDL Interface Library"},{"location":"posts/winrt_broker/#proxystub","text":"I then added a C++ Win32 DLL project called MyService.ProxyStub. This dll has to include the above files again, but this time with the C++ preprocessor definition \u201cREGISTER_PROXY_DLL\u201d, and you need to generate a new GUID for your runtime class id (different from the one in the MIDL file) in a new ProxyEntry.c file as follows: // {xxxxxxxx-4CCC-4D4E-9C8C-A842DB7182E6} #define PROXY_CLSID_IS { 0xxxxxxxxx, 0x4ccc, 0x4d4e,{ 0x9c, 0x8c, 0xa8, 0x42, 0xdb, 0x71, 0x82, 0xe6 } }; #define USE_STUBLESS_PROXY #define PROXY_DELEGATION #include <rpcproxy.h> #include <ObjIdl.h> #include \"dlldata.c\" #include \"Microsoft.Service.Sample_i.c\" #include \"Microsoft.Service.Sample_p.c\" This is also easier to compile if you turn off precompiled headers. You also need to add a Module Definition file for the DLL containing: EXPORTS DllGetClassObject PRIVATE DllCanUnloadNow PRIVATE DllRegisterServer PRIVATE DllUnregisterServer PRIVATE You\u2019ll also need to add a VC++ Include Directory pointing at your interface static lib directory where the dlldata.c and _i.c and _p.c files got generated. You will also need to add the linker input \u201crpcrt4.lib\u201d. This generates the proxy stub needed for RPC to work. This dll will be registered using regsvr32.","title":"ProxyStub"},{"location":"posts/winrt_broker/#broker","text":"Next I added a Universal C++ DLL project called \u201cMyServiceBroker\u201d. I added a reference to the static library project, I included #include <ObjIdl.h> in the pch.h file and again added the VC++ include directory where the _h.h file was generated. I wanted this DLL to work on the IoT SKU of Windows 10, which is why I used Universal DLL, but I want to run this outside an app container so I removed the following from the .vcxproj file: <AppContainerApplication>true</AppContainerApplication> . I also added the following linker instructions to each <Link> section: <IgnoreSpecificDefaultLibraries>comsuppwd.lib; comsuppw.lib; kernel32.lib; ole32.lib; user32.lib</IgnoreSpecificDefaultLibraries> <AdditionalDependencies>Wlanapi.lib;mincore.lib;onecoreuap.lib; WindowsApp.lib;</AdditionalDependencies> Lastly I added the a class that implements my new interface as follows: #pragma once #include <windows.h> #include <wrl.h> #include <MyInterface_h.h> namespace Microsoft { namespace Service { namespace Sample { class CMyService : public Microsoft::WRL::RuntimeClass<ABI::Microsoft::Service::Sample::IMyService, Microsoft::WRL::FtmBase> { InspectableClass(RuntimeClass_Microsoft_Service_Sample_MyService, PartialTrust); public: CMyService(); ~CMyService(); IFACEMETHOD(DoSomethingFun)(); private: CMyService(const CMyService&); const CMyService& operator = (const CMyService&); }; ActivatableClass(CMyService); } } } Then I added an empty implementation the the .cpp file. I also replaced the contents of the dllmain.cpp file with the following: #include \"pch.h\" #include <windows.h> #include <wrl.h> #include <wrl/module.h> using namespace Microsoft::WRL; STDAPI DllGetActivationFactory(_In_ HSTRING activatableClassId, _COM_Outptr_ IActivationFactory **factory) { return Module<ModuleType::InProcDisableCaching>::GetModule().GetActivationFactory(activatableClassId, factory); } _Check_return_ STDAPI DllGetClassObject(_In_ REFCLSID rclsid, _In_ REFIID riid, _Outptr_ LPVOID FAR* ppv) { return Module<ModuleType::InProcDisableCaching>::GetModule().GetClassObject(rclsid, riid, ppv); } STDAPI DllCanUnloadNow() { HRESULT hr = S_FALSE; if (Module<ModuleType::InProcDisableCaching>::GetModule().GetObjectCount() == 0) { hr = S_OK; } return hr; } STDAPI_(void) DllAddRef() { Module<ModuleType::InProcDisableCaching>::GetModule().IncrementObjectCount(); } STDAPI_(void) DllRelease() { Module<ModuleType::InProcDisableCaching>::GetModule().DecrementObjectCount(); } STDAPI_(BOOL) DllMain(_In_opt_ HINSTANCE hinst, DWORD reason, _In_opt_ void*) { if (reason == DLL_PROCESS_ATTACH) { DisableThreadLibraryCalls(hinst); } return TRUE; }","title":"Broker"},{"location":"posts/winrt_broker/#setup","text":"First you need to copy your *ProxyStub.dll and your *Broker.dll to a place that the WinRT app can access (like c:\\windows\\system32) otherwise you will get E_ACCESSDENIED when trying to call object from WinRT. To register the broker I created a custom registry script containing the following. Notice the GUID used here matches the one I generated for the ProxyEntry.c file earlier. Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\WindowsRuntime\\ActivatableClassId\\Microsoft.Service.Sample.MyService] \"ActivationType\"=dword:00000000 \"CLSID\"=\"xxxxxxxx-4CCC-4D4E-9C8C-A842DB7182E6\" \"Threading\"=dword:00000000 \"TrustLevel\"=dword:00000001 \"DllPath\"=\"c:\\\\Windows\\\\System32\\\\MyServiceBroker.dll\" [HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\WindowsRuntime\\CLSID\\{xxxxxxxx-4CCC-4D4E-9C8C-A842DB7182E6}] \"ActivatableClassId\"=\"Microsoft.Service.Sample.MyService\" Running this from administrator command prompt makes it possible for WinRT to construct your runtime class. You may need to take ownership of the WindowsRuntime part of the registry in order to do this. There is a tool called TakeRegistryAdminOwnership.exe included in the above download that can help with this.","title":"Setup"},{"location":"posts/winrt_broker/#c-app","text":"To test out my new brokered service I created a blank C# windows application and added a reference to the generated Microsoft.Service.Sample.winmd file, then added the following lines: var service = new Microsoft.Service.Sample.MyService(); service.DoSomethingFun(); When you run these lines the MyServiceBroker.dll is loaded into the RuntimeBroker.exe process (you can attach to that process using your VS debugger and watch it happen and you can debug your broker that way also). You will see RPC stuff on the stack when the DoSomethingFun call comes in. Don\u2019t worry about terminating the RuntimeBroker.exe process, it will auto-restart.","title":"C# App"},{"location":"posts/winrt_broker/#callbacks","text":"If you need to have your broker do something async and call back to your C# application later you can easily define a new interface, implement that in C# and pass it to your broker as an argument, then the broker can call that interface. This RPC interface will \u201ctimeout\u201d after a minute, so you may need to repeat that process periodically or do a heartbeat kind of thing to keep it alive. You could build a WinRT component project that wraps all this and exposes a new \u201cClient\u201d interface that turns all this callback stuff into C++/CX events so that it is easier to consume in your C# applications. Your \u201cClient\u201d interface could also expose C++/CX properties and events so you have a nice modern interface to your new broker. Happy Brokering!","title":"Callbacks"},{"location":"posts/wireless_remote/","text":"Wireless Remote Hack An Arduino hack on a cheap Wireless Remote Light Switch from Home Depot. So I bought this remote control switch from Home Depot a couple years ago: And the battery died in the remote, so I could go find a replacement A53G 12V battery, or I could hack it and control the remote using Arduino. That way I can turn the lights on and off by computer, based on time of sunset, etc, which is even better than the remote and exactly what I want. How hard could it be right? When you open up the remote it looks like a nice simple circuit, unfortunately no one seems to be able to find a datasheet for that IC labelled AUT980202-B1. But the transmitter is a common 315 MHz transmitter that you can even get from sparkfun , so that\u2019s promising. But since I don\u2019t know how the IC is driving the transmitter, it is time to break out the logic analyzer and take a look at the signal coming from the IC. The IC pin 2 seems to be the pin connected to the transmitter. There\u2019s a couple 0 ohm resistors connected to that trace, so let\u2019s probe there. Pretty soon you will see a set of simple signals at around 20 kHz, and it looks like there is an initial preamble, then the Off and On buttons produce the sequence 0x6814 and 0x6824. I had 3 of these remotes and when I looked at all of them I could see 0x68 prefix was in common, the next nibble 0x1 or 0x2 was the on off switch and the last nibble 0x0 to 0xF was the address of the remote switch, so you can do up to 16 unique remotes with this I guess. Ok, then I grabbed my trusty Arduino Leonardo and bit-banged out a similar signal until the logic analyzer matched as closely as possible. Here\u2019s the Arduino version: I noticed the original signal did the preamble, then the on or off sequence about 4 times with about 4 ms between each, then repeated with the preamble again. So I coded up a similar pattern and tried it out. It didn\u2019t work the first time, so I adjusted the timing to be as close as possible, then bingo, it worked as shown in this demo video: : I severed the link from the AUT980202 chip by removing a diode from the signal pin. This way I could use the Arduino to drive the signal instead. The next step was to bypass the buttons on the remote by soldering a wire to the transitor that controls the transmitter directly so the Arduino can decide when to turn the lights on or off, you can also hard wire the 5 volt output from the Arduino and remove the battery. Turns out 5 volts is enough and it still works. Lastly, I found that the older version of the remote, that I bought a couple years ago, was essentially the same but it runs the signal at about 2.7 times slower. Perhaps they change the signal speed every now and then to stop the devices from clashing, so no guarentee this code will work on your remote. But if you find the right scaling factor then you might get lucky. We need to use two GPIO pins on the Arduino, one to turn on or off the transmitter and another to drive the transmitted signal. #define SIGNAL_PIN 12 #define POWER_PIN 3 void setup() { // initialize digital pin SIGNAL_PIN as an output. pinMode(SIGNAL_PIN, OUTPUT); pinMode(POWER_PIN, OUTPUT); } My loop then turns the switch on then off, with a 1 second delay between each using this: void loop() { //float scale = 2.77; // old remote is slower. //uint8_t addr = 0x4; // south lights //uint8_t addr = 0xC; // north lights float scale = 1; uint8_t addr = 0x0; // new switch turnOn(addr, scale); delay(1000); turnOff(addr, scale); delay(1000); } The cool thing is this hacked remote can now turn on any of my remote switches simply by changing the 16 bit address, and/or the scale on the speed depending on whether I\u2019m controlling old or new switches. The turnOn and turnOff functions look similar: void turnOn(uint8_t addr, float scale) { digitalWrite(POWER_PIN, TOGGLE_ON); delay(1); uint16_t onSignal = makeSignal(true, addr); sendSignal(onSignal, scale); digitalWrite(POWER_PIN, TOGGLE_OFF); } void turnOff(uint8_t addr, float scale) { digitalWrite(POWER_PIN, TOGGLE_ON); delay(1); uint16_t offSignal = makeSignal(false, addr); sendSignal(offSignal, scale); digitalWrite(POWER_PIN, TOGGLE_OFF); } where the helper function makeSignal combines the prefix 0x68 with the on/off nibble and the address nibble: uint16_t makeSignal(bool on, uint8_t addr) { uint16_t signal = 0x68; signal <<= 4; if (on) { signal += 0x2; } else { signal += 0x1; } signal <<= 4; signal += (0xF & addr); return signal; } and the sendSignal function writes the preamble, and 4 repetitions of the signal, just to be sure. This seems reliable enough, but you could increase this repetition to whatever number you need to get 100% reliability. void sendSignal(uint16_t signal, float scale) { writePreamble(48, scale); delay(4); for (int i = 0; i < 4; i++) { writeBits(signal, scale); delay((int)(4.0 * scale)); } } Ok, now down to the actual bit banging on the output line, simply raising it HIGH and LOW at the right time, the writePreamble does 48 fast pulses, at 200 microseconds: void writePreamble(int len, float scale) { for (int i = 0; i < len ; i++) { digitalWrite(SIGNAL_PIN, HIGH); delayMicroseconds((int)(200.0 * scale)); digitalWrite(SIGNAL_PIN, LOW); delayMicroseconds((int)(200.0 * scale)); } } And writeBits writes out our sequence (like 0x671C) by bit shifting over that signal. Each bit starts with a rising edge then for a 1 bit, it keeps the pulse high for 600 microseconds, for a 0 bit, it drops that after 200 microseconds and leaves it low for the remaining 400 microseconds, then there\u2019s a 200 microsecond low until the next bit. void writeBits(uint16_t signal, float scale) { for (int i = 0; i < 16 ; i++) { int bit = (signal & 0x8000); digitalWrite(SIGNAL_PIN, HIGH); if (bit) { delayMicroseconds((int)(610.0 * scale)); } else { delayMicroseconds((int)(200.0 * scale)); digitalWrite(SIGNAL_PIN, LOW); delayMicroseconds((int)(410.0 * scale)); } digitalWrite(SIGNAL_PIN, LOW); delayMicroseconds((int)(210.0 * scale)); signal <<= 1; } } The exact numbers used in these delayMicroseconds calls is needed to match the signal from the IC chip, and the lack of neat round numbers here is probably because the internal oscillators on the IC versus the Arduino are slightly different. But this seems to work. The scale factor in the code is just so that I can control old and new remote switches with the same code. See Arduino Source Code . Now hook that up to a nice little Python script to toggle the lights at sunrise and sunset: Python Source Code . Fun!","title":"Arduino controlled Remote Light Switch"},{"location":"posts/wireless_remote/#wireless-remote-hack","text":"An Arduino hack on a cheap Wireless Remote Light Switch from Home Depot. So I bought this remote control switch from Home Depot a couple years ago: And the battery died in the remote, so I could go find a replacement A53G 12V battery, or I could hack it and control the remote using Arduino. That way I can turn the lights on and off by computer, based on time of sunset, etc, which is even better than the remote and exactly what I want. How hard could it be right? When you open up the remote it looks like a nice simple circuit, unfortunately no one seems to be able to find a datasheet for that IC labelled AUT980202-B1. But the transmitter is a common 315 MHz transmitter that you can even get from sparkfun , so that\u2019s promising. But since I don\u2019t know how the IC is driving the transmitter, it is time to break out the logic analyzer and take a look at the signal coming from the IC. The IC pin 2 seems to be the pin connected to the transmitter. There\u2019s a couple 0 ohm resistors connected to that trace, so let\u2019s probe there. Pretty soon you will see a set of simple signals at around 20 kHz, and it looks like there is an initial preamble, then the Off and On buttons produce the sequence 0x6814 and 0x6824. I had 3 of these remotes and when I looked at all of them I could see 0x68 prefix was in common, the next nibble 0x1 or 0x2 was the on off switch and the last nibble 0x0 to 0xF was the address of the remote switch, so you can do up to 16 unique remotes with this I guess. Ok, then I grabbed my trusty Arduino Leonardo and bit-banged out a similar signal until the logic analyzer matched as closely as possible. Here\u2019s the Arduino version: I noticed the original signal did the preamble, then the on or off sequence about 4 times with about 4 ms between each, then repeated with the preamble again. So I coded up a similar pattern and tried it out. It didn\u2019t work the first time, so I adjusted the timing to be as close as possible, then bingo, it worked as shown in this demo video: : I severed the link from the AUT980202 chip by removing a diode from the signal pin. This way I could use the Arduino to drive the signal instead. The next step was to bypass the buttons on the remote by soldering a wire to the transitor that controls the transmitter directly so the Arduino can decide when to turn the lights on or off, you can also hard wire the 5 volt output from the Arduino and remove the battery. Turns out 5 volts is enough and it still works. Lastly, I found that the older version of the remote, that I bought a couple years ago, was essentially the same but it runs the signal at about 2.7 times slower. Perhaps they change the signal speed every now and then to stop the devices from clashing, so no guarentee this code will work on your remote. But if you find the right scaling factor then you might get lucky. We need to use two GPIO pins on the Arduino, one to turn on or off the transmitter and another to drive the transmitted signal. #define SIGNAL_PIN 12 #define POWER_PIN 3 void setup() { // initialize digital pin SIGNAL_PIN as an output. pinMode(SIGNAL_PIN, OUTPUT); pinMode(POWER_PIN, OUTPUT); } My loop then turns the switch on then off, with a 1 second delay between each using this: void loop() { //float scale = 2.77; // old remote is slower. //uint8_t addr = 0x4; // south lights //uint8_t addr = 0xC; // north lights float scale = 1; uint8_t addr = 0x0; // new switch turnOn(addr, scale); delay(1000); turnOff(addr, scale); delay(1000); } The cool thing is this hacked remote can now turn on any of my remote switches simply by changing the 16 bit address, and/or the scale on the speed depending on whether I\u2019m controlling old or new switches. The turnOn and turnOff functions look similar: void turnOn(uint8_t addr, float scale) { digitalWrite(POWER_PIN, TOGGLE_ON); delay(1); uint16_t onSignal = makeSignal(true, addr); sendSignal(onSignal, scale); digitalWrite(POWER_PIN, TOGGLE_OFF); } void turnOff(uint8_t addr, float scale) { digitalWrite(POWER_PIN, TOGGLE_ON); delay(1); uint16_t offSignal = makeSignal(false, addr); sendSignal(offSignal, scale); digitalWrite(POWER_PIN, TOGGLE_OFF); } where the helper function makeSignal combines the prefix 0x68 with the on/off nibble and the address nibble: uint16_t makeSignal(bool on, uint8_t addr) { uint16_t signal = 0x68; signal <<= 4; if (on) { signal += 0x2; } else { signal += 0x1; } signal <<= 4; signal += (0xF & addr); return signal; } and the sendSignal function writes the preamble, and 4 repetitions of the signal, just to be sure. This seems reliable enough, but you could increase this repetition to whatever number you need to get 100% reliability. void sendSignal(uint16_t signal, float scale) { writePreamble(48, scale); delay(4); for (int i = 0; i < 4; i++) { writeBits(signal, scale); delay((int)(4.0 * scale)); } } Ok, now down to the actual bit banging on the output line, simply raising it HIGH and LOW at the right time, the writePreamble does 48 fast pulses, at 200 microseconds: void writePreamble(int len, float scale) { for (int i = 0; i < len ; i++) { digitalWrite(SIGNAL_PIN, HIGH); delayMicroseconds((int)(200.0 * scale)); digitalWrite(SIGNAL_PIN, LOW); delayMicroseconds((int)(200.0 * scale)); } } And writeBits writes out our sequence (like 0x671C) by bit shifting over that signal. Each bit starts with a rising edge then for a 1 bit, it keeps the pulse high for 600 microseconds, for a 0 bit, it drops that after 200 microseconds and leaves it low for the remaining 400 microseconds, then there\u2019s a 200 microsecond low until the next bit. void writeBits(uint16_t signal, float scale) { for (int i = 0; i < 16 ; i++) { int bit = (signal & 0x8000); digitalWrite(SIGNAL_PIN, HIGH); if (bit) { delayMicroseconds((int)(610.0 * scale)); } else { delayMicroseconds((int)(200.0 * scale)); digitalWrite(SIGNAL_PIN, LOW); delayMicroseconds((int)(410.0 * scale)); } digitalWrite(SIGNAL_PIN, LOW); delayMicroseconds((int)(210.0 * scale)); signal <<= 1; } } The exact numbers used in these delayMicroseconds calls is needed to match the signal from the IC chip, and the lack of neat round numbers here is probably because the internal oscillators on the IC versus the Arduino are slightly different. But this seems to work. The scale factor in the code is just so that I can control old and new remote switches with the same code. See Arduino Source Code . Now hook that up to a nice little Python script to toggle the lights at sunrise and sunset: Python Source Code . Fun!","title":"Wireless Remote Hack"},{"location":"posts/xml_notepad/","text":"Update to XML Notepad As XML has exploded across the planet I continue to get many requests for improvements to my XML Notepad of 2007. The tool has been downloaded over a million times, so I figured it\u2019s time to show it some love and fix some bugs. In the process I updated it to NET 4.0 using VS 2013. I was amazed how everything from back then still works, including the Unit Tests. That is pretty amazing platform compatibility. Windows is a great platform and Visual Studio is still best of breed for software development, and I still love C#. I also posted the source code on github.com/microsoft.xmlnotepad . See Install Page .","title":"Update to XML Notepad"},{"location":"posts/xml_notepad/#update-to-xml-notepad","text":"As XML has exploded across the planet I continue to get many requests for improvements to my XML Notepad of 2007. The tool has been downloaded over a million times, so I figured it\u2019s time to show it some love and fix some bugs. In the process I updated it to NET 4.0 using VS 2013. I was amazed how everything from back then still works, including the Unit Tests. That is pretty amazing platform compatibility. Windows is a great platform and Visual Studio is still best of breed for software development, and I still love C#. I also posted the source code on github.com/microsoft.xmlnotepad . See Install Page .","title":"Update to XML Notepad"},{"location":"resume/","text":"PM, 2000 Incubation, 2003 side project Dev/Architect State City City City Dev Lead on Database Integration join Startup, 1992 Dev, 1997 Dev, 1998 Dev on Communication Protocols City near Moved to Dev on UI Frameworks Founder of startup, 1996 Graduated top of class 1987 State State Architect, 2008-2011 Aquired 1997 City Dev Influenced also built grew up study Computer Science WebData 21 patents filed, 16 patents granted so far. We built the equivalent of HTML 5 in 1996, including equivalent of integrated scalable vector graphics which was actually more integrated than SVG is today because we could put any HTML inside any SVG tag. AirSim Apple/IBM Joint Venture Australia California CommonPoint Cupertino Dev Mgr, 2006,2007 ELL IBM XML Java XML Parser Linq Logica Los Altos Managed Language Service Framework MSXML in C++ Microsoft Microsoft Research NSW OS/2 Over 3 million downloads Patents Directed Graph Markup Language Generated Dependency Graphs Visualization and Modeling Platform San Jose Seattle Springwood Sydney System.Xml Taligent University NSW USA Visual Studio Walkabout Software Washington Ships in Windows, used in hundreds of MSFT products. We also built XMLHTTPRequest which inspired AJAX and is now a w3c standard Web Browser for kids Mobile Labs X# XML Notepad XML Editor Chris Lovett an incubation team, prototyped an xbox game streaming to windows phone Interactive HTML Coyote Ada LEGEND Incubation Patent Work Person Technology Place Team Product Company Comment","title":"Index"},{"location":"videos/","text":"Videos MyMoney Refactoring code the fun way [ Using DGML to understand PX4 [ AirSim with PX4 in HITL mode using Firmware version 1.9.0 [ Runing AI on IoT microcontroller devices with ELL [ Ble Lights [ Wifi Lights [ Outlook Sync [ Password Vault [ Pinweight Devices [ Dgml Test Modeling [ Software Trails [ Energy Hub [ FIRST Event Planner [ GC Root Demo [ Large Graphs [ What\u2019s new with DGML [ Architecture Explorer [ Standard Graphs [ Graph Documents","title":"Videos"},{"location":"videos/#videos","text":"MyMoney Refactoring code the fun way [ Using DGML to understand PX4 [ AirSim with PX4 in HITL mode using Firmware version 1.9.0 [ Runing AI on IoT microcontroller devices with ELL [ Ble Lights [ Wifi Lights [ Outlook Sync [ Password Vault [ Pinweight Devices [ Dgml Test Modeling [ Software Trails [ Energy Hub [ FIRST Event Planner [ GC Root Demo [ Large Graphs [ What\u2019s new with DGML [ Architecture Explorer [ Standard Graphs [ Graph Documents","title":"Videos"}]}